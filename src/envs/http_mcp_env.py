# src/envs/http_mcp_env.py
import sys
import os
import json
import logging
import asyncio
import time
import re
from typing import Dict, Any, Union, Optional, List, Tuple
from datetime import datetime
from dataclasses import dataclass

# å¼•å…¥ MCP SDK
from mcp.types import CallToolResult
# å¼•å…¥ MCP SSE å®¢æˆ·ç«¯
from utils.mcp_sse_client import MCPSSEClient

# å¼•å…¥ä»»åŠ¡è¶…æ—¶ç›‘æ§å·¥å…·
from utils.task_timeout import TaskTimeoutMonitor, TaskTimeoutError, check_execution_timeout

# å¼•å…¥ system prompt å‡½æ•°
from prompts.system_prompts import get_system_prompt

import openai
from openai.types.chat import ChatCompletionMessageParam, ChatCompletionToolParam

logger = logging.getLogger(__name__)

@dataclass
class ToolMetadata:
    """ç”¨äºé€‚é… GenericTrajectorySampler çš„ç®€å•å·¥å…·åŒ…è£…ç±»"""
    name: str
    description: str
    parameters: List[Dict[str, Any]]

class HttpMCPEnv:
    """
    é…ç½®é©±åŠ¨çš„ MCP ç¯å¢ƒé€‚é…å™¨ (MCP çº¯å‡€ç‰ˆ)
    
    å®Œå…¨åŸºäº Model Context Protocol (MCP) ä¸è¿œç¨‹ Gateway/Server äº¤äº’ã€‚
    è´Ÿè´£ Agent æ‰§è¡Œå¾ªç¯ã€å·¥å…·è°ƒç”¨è½¬å‘ä»¥åŠé€šè¿‡ MCP å·¥å…·è¿›è¡Œèµ„æºç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚
    """
    
    # å¼€å¯é‡å‹èµ„æºæ¨¡å¼ï¼Œé€šçŸ¥æ¡†æ¶åœ¨ run_task å‰åè°ƒç”¨ allocate/release
    has_heavy_resource = True 

    def __init__(self,
                 model_name: str = "gpt-4.1-2025-04-14",
                 parallel_degree=1,
                 **kwargs):
        
        self.model_name = model_name
        self.config = kwargs
        
        # å·¥å…·å…ƒæ•°æ®ç¼“å­˜
        self.tool_schemas: List[Dict[str, Any]] = []
        self.tool_descriptions: str = ""
        # [æ–°å¢] æœ¬åœ°å·¥å…·ç¼“å­˜ï¼Œç”¨äºæ”¯æŒ get_tool
        self.local_tools: Dict[str, ToolMetadata] = {}

        # 1. åŸºç¡€é…ç½®
        self.server_url = kwargs.get("mcp_server_url", "http://localhost:8080")
        
        # 2. è·å– worker_id
        if "worker_id" in kwargs:
            self.worker_id = kwargs["worker_id"]
        else:
            import multiprocessing
            self.worker_id = multiprocessing.current_process().name

        # 3. å®ä¾‹åŒ– MCP å®¢æˆ·ç«¯
        self.mcp_client = MCPSSEClient(f"{self.server_url}/sse")

        # 4. åŠ è½½ Gateway é…ç½® (ç¡®å®šéœ€è¦ç”³è¯·å“ªäº›èµ„æº)
        config_path = kwargs.get("gateway_config_path", "gateway_config.json")
        self.modules_config = self._load_gateway_config(config_path)

        # [ä¿®å¤] è§£ææ´»åŠ¨èµ„æºç±»å‹æ—¶ï¼Œè¿‡æ»¤æ‰ä¸éœ€è¦åç«¯åˆ†é…çš„ 'system' ç±»å‹
        # 'system' é€šå¸¸æŒ‡ä»£æ— çŠ¶æ€çš„ç³»ç»Ÿå·¥å…·é›†ï¼Œä¸éœ€è¦å‘ Resource API ç”³è¯·é”å®š
        self.active_resources = [
            m.get("resource_type")
            for m in self.modules_config.get("modules", [])
            if m.get("resource_type") and m.get("resource_type") != "system"
        ]
        
        # åˆå§‹åŒ–çŠ¶æ€å˜é‡
        self.initial_observation = None
        self.allocated_resources = {}
        self._tools_initialized = False
        # é¡ºåºç¼–å·ï¼šç”¨äºä¸ºå·¥å…·äº§ç”Ÿçš„å›¾ç‰‡ç”Ÿæˆè¿ç»­çš„ <obs_i> token
        self._obs_counter = 0

        # 5. å·¥å…·ç™½åå•ï¼ˆä¼˜å…ˆç­–ç•¥ï¼‰
        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ tool_whitelistï¼›å¦åˆ™å°è¯•ä»ç¯å¢ƒå˜é‡ MCP_TOOL_WHITELIST è¯»å–ï¼ˆé€—å·åˆ†éš”ï¼‰
        whitelist_arg = kwargs.get("tool_whitelist")
        if isinstance(whitelist_arg, (list, tuple, set)):
            self._tool_whitelist = {str(x).strip() for x in whitelist_arg if str(x).strip()}
        elif isinstance(whitelist_arg, str):
            self._tool_whitelist = {x.strip() for x in whitelist_arg.split(',') if x.strip()}
        else:
            env_wl = os.environ.get("MCP_TOOL_WHITELIST", "")
            self._tool_whitelist = {x.strip() for x in env_wl.split(',') if x.strip()} if env_wl else set()

        # åˆå§‹åŒ–æŒä¹…äº‹ä»¶å¾ªç¯
        self._loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self._loop)

        logger.info(f"HttpMCPEnv initialized: {self.worker_id} -> {self.server_url}, resources: {self.active_resources}")
        
        # åˆå§‹åŒ–è¿œç¨‹å·¥å…·åˆ—è¡¨
        self._initialize_tools()

    @property
    def mode(self) -> str:
        return "http_mcp"

    # =========================================================================
    # [æ–°å¢/ä¿®å¤] æ ¸å¿ƒé€‚é…æ¥å£ï¼šget_tool å’Œ list_tools
    # =========================================================================

    def list_tools(self) -> List[str]:
        """è¿”å›æ‰€æœ‰å¯ç”¨å·¥å…·çš„åç§°åˆ—è¡¨"""
        return list(self.local_tools.keys())

    def get_tool(self, tool_name: str) -> Optional[ToolMetadata]:
        """
        è·å–å·¥å…·å¯¹è±¡ï¼ˆé€‚é…å™¨æ¨¡å¼ï¼‰ã€‚
        GenericTrajectorySampler éœ€è¦è®¿é—® tool.name, tool.description, tool.parameters
        """
        return self.local_tools.get(tool_name)

    # =========================================================================
    # æ ¸å¿ƒ Agent æ‰§è¡Œé€»è¾‘
    # =========================================================================

    def run_task(self, task: Dict[str, Any], agent_config: Dict[str, Any], logger: logging.Logger) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ Agent ä»»åŠ¡å¾ªç¯
        """
        task_id = task.get("id", "unknown")
        question = task.get("question", "")

        model_name = agent_config.get("model_name", self.model_name)
        max_turns = agent_config.get("max_turns", 3)
        max_retries = agent_config.get("max_retries", 3)

        # è·å–ä»»åŠ¡è¶…æ—¶é…ç½®
        task_timeout = float(
            agent_config.get("task_timeout",
            os.environ.get("TASK_EXECUTION_TIMEOUT", "600"))
        )

        task_output_dir = None
        if hasattr(self, "get_task_output_dir") and callable(self.get_task_output_dir):
            task_output_dir = self.get_task_output_dir(
                agent_config.get("output_dir", "results"),
                task_id,
                model_name
            )

        monitor = TaskTimeoutMonitor(task_timeout, task_id, self.worker_id)

        try:
            monitor.start()

            messages = self._run_conversation(
                question, model_name, max_turns, max_retries, logger,
                task_timeout=task_timeout,
                task_start_time=time.time()
            )

            final_answer = self._extract_final_answer(messages)

            result = {
                "task_id": task_id,
                "question": question,
                "answer": final_answer,
                "messages": messages,
                "success": True,
                "error": None,
            }

            if task_output_dir:
                self._save_conversation_log(
                    task_output_dir,
                    task_id,
                    question,
                    model_name,
                    messages,
                    result
                )

            return result

        except TaskTimeoutError as e:
            logger.error(f"âŒ [TaskTimeout] Task {task_id} timeout: {e}")
            return {
                "task_id": task_id,
                "question": question,
                "answer": "",
                "messages": [],
                "success": False,
                "error": f"Task execution timeout: {e}",
            }

        except Exception as e:
            logger.error(f"âŒ [TaskError] Task {task_id} failed: {e}")
            raise

        finally:
            monitor.cancel()

    def _run_conversation(self,
                         question: str,
                         model_name: str,
                         max_turns: int,
                         max_retries: int,
                         logger: logging.Logger,
                         task_timeout: Optional[float] = None,
                         task_start_time: Optional[float] = None
    ) -> List[Dict[str, Any]]:
        
        system_prompt = self.get_system_prompt(question)
        messages: List[ChatCompletionMessageParam] = [
            {"role": "system", "content": system_prompt},
        ]

        user_content: List[Dict[str, Any]] = [{"type": "text", "text": f"Question: {question}\n"}]

        # æ³¨å…¥åˆå§‹è§‚å¯Ÿ
        initial_obs = getattr(self, "initial_observation", None)
        
        # === å‡å°‘æ—¥å¿—ï¼šç§»é™¤åˆå§‹è§‚å¯ŸçŠ¶æ€æ£€æŸ¥ ===
        # if initial_obs:
        #     logger.info(f"[{self.worker_id}] [LLM_INJECT_LOG] Initial Observation Status: Present for injection.")
        # else:
        #     logger.info(f"[{self.worker_id}] [LLM_INJECT_LOG] Initial Observation Status: Not present for injection.")

        if initial_obs and isinstance(initial_obs, dict):
            if initial_obs.get("screenshot"):
                user_content.append({
                    "type": "text",
                    "text": "Here is the initial screen state of the computer:"
                })
                user_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{initial_obs['screenshot']}",
                        "detail": "high"
                    }
                })

            if initial_obs.get("accessibility_tree"):
                user_content.append({
                    "type": "text",
                    "text": f"Accessibility Tree:\n{initial_obs['accessibility_tree']}"
                })

        # [æ–°å¢] æ³¨å…¥ä»»åŠ¡è¾“å…¥å›¾ç‰‡ï¼ˆå¦‚ç”±å­ç±»è®¾ç½®çš„ self.input_imagesï¼‰
        # æ”¯æŒä¸¤ç§å½¢å¼ï¼š
        # - base64 æ•°æ®ï¼š{"b64": "..."}
        # - è¿œç¨‹ URLï¼š{"url": "https://..."}
        # è‹¥åŒæ—¶å­˜åœ¨ï¼Œåˆ™éƒ½æ³¨å…¥ï¼Œä¾¿äºæ¨¡å‹é¢„è§ˆä¸å·¥å…·è°ƒç”¨ï¼ˆä¾‹å¦‚åå‘å›¾æœéœ€è¦ URLï¼‰
        # æ³¨æ„ï¼šå›¾ç‰‡æ ‡è®°ä½¿ç”¨æˆå¯¹æ ‡ç­¾ï¼Œä¾‹å¦‚ <image_1> ... </image_1>
        input_images = getattr(self, "input_images", None)
        if isinstance(input_images, list) and input_images:
            for idx, img in enumerate(input_images, start=1):
                open_token = f"<image_{idx}>"
                close_token = f"</image_{idx}>"
                if isinstance(img, dict):
                    b64 = img.get("b64")
                    url = img.get("url")
                    # å§‹ç»ˆå…ˆè¾“å‡ºçº¯ Token è¡Œï¼Œç¡®ä¿åŒ¹é…æå–é€»è¾‘ (<token> å¿…é¡»æ˜¯æ–‡æœ¬é¡¹æœ€å)
                    user_content.append({"type": "text", "text": open_token})
                    if b64:
                        user_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{b64}",
                                "detail": "high"
                            }
                        })
                    elif url:
                        user_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": url,
                                "detail": "high"
                            }
                        })
                    # ç»“å°¾å…³é—­ Tokenï¼ˆä¾›å¯è¯»æ€§ï¼›è£åˆ‡ç´¢å¼•ä¸ä¾èµ–è¯¥è¡Œï¼‰
                    user_content.append({"type": "text", "text": close_token})

        messages.append({"role": "user", "content": user_content})

        # === å‡å°‘æ—¥å¿—ï¼šç§»é™¤ç”¨æˆ·æ¶ˆæ¯å†…å®¹æ£€æŸ¥ ===
        # safe_msg = self._truncate_data(messages[1], max_len=200)
        # logger.info(f"[{self.worker_id}] [LLM_INJECT_LOG] First User Message Content (Check Injection): {json.dumps(safe_msg, indent=2, ensure_ascii=False)}")

        client = self._get_openai_client()
        turn_count = 0

        while turn_count < max_turns:
            if task_timeout and task_start_time:
                if check_execution_timeout(task_start_time, task_timeout, "current_task", self.worker_id):
                    raise TaskTimeoutError(
                        f"Task timeout after {time.time() - task_start_time:.1f}s "
                        f"(limit: {task_timeout}s) at turn {turn_count}"
                    )

            retry = 0
            while retry < max_retries:
                try:
                    # å‡å°‘æ—¥å¿—ï¼šä»…åœ¨éœ€è¦æ—¶è¾“å‡º
                    # logger.info(f"Turn {turn_count}: Calling LLM...")
                    response = client.chat.completions.create(
                        model=model_name,
                        messages=messages,
                        tools=self.get_tool_schemas(),
                    )

                    if not hasattr(response, "choices") or not response.choices:
                        raise ValueError("OpenAI API returned empty response")

                    assistant_message = response.choices[0].message
                    messages.append(assistant_message.model_dump())

                    if assistant_message.tool_calls:
                        if messages[-1]['content'] is None:
                             messages[-1]['content'] = ""

                        for tool_call in assistant_message.tool_calls:
                            tool_name = tool_call.function.name
                            tool_args = json.loads(tool_call.function.arguments)

                            # å‡å°‘æ—¥å¿—ï¼šä»…è¾“å‡ºå·¥å…·åç§°
                            logger.info(f"ğŸ”§ {tool_name}")

                            # ä»£ç†åˆ° MCP æ‰§è¡Œ
                            tool_output = self.execute_tool(tool_name, tool_args)

                            if isinstance(tool_output, dict) and "images" in tool_output:
                                content_str = tool_output.get("text", "")
                                image_list = tool_output.get("images", [])
                            else:
                                content_str = str(tool_output)
                                image_list = []

                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "name": tool_name,
                                "content": content_str
                            })

                            if image_list:
                                # å°†å·¥å…·è¿”å›çš„å›¾ç‰‡ç»Ÿä¸€åŒ…è£¹ä¸º <obs_i> ... </obs_i>
                                obs_blocks = []
                                for img_b64 in image_list:
                                    self._obs_counter += 1
                                    open_obs = f"<obs_{self._obs_counter}>"
                                    close_obs = f"</obs_{self._obs_counter}>"
                                    # å¼€æ ‡ç­¾
                                    obs_blocks.append({"type": "text", "text": open_obs})
                                    # å›¾ç‰‡
                                    obs_blocks.append({
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:image/png;base64,{img_b64}",
                                            "detail": "high"
                                        }
                                    })
                                    # é—­æ ‡ç­¾ï¼ˆå¯è¯»æ€§ï¼‰
                                    obs_blocks.append({"type": "text", "text": close_obs})
                                messages.append({"role": "user", "content": obs_blocks})

                    else:
                        # å‡å°‘æ—¥å¿—ï¼šæœ€ç»ˆç­”æ¡ˆäº§ç”Ÿæ—¶ä¸å†è¾“å‡º
                        # logger.info(f"Turn {turn_count}: final answer produced")
                        return messages
                    
                    break # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯

                except Exception as exc:
                    retry += 1
                    logger.warning(f"Retry {retry}/{max_retries} due to error: {exc}")
                    if retry >= max_retries:
                        raise
            turn_count += 1
            
        logger.warning("Max turns reached without final answer")
        return messages

    def _extract_final_answer(self, messages: List[Dict[str, Any]]) -> Optional[str]:
        """
        Extract final answer from messages.
        First tries to extract content within <FINAL_ANSWER> tags.
        Falls back to returning the last assistant message if tags not found.
        """
        if not messages:
            return None

        # Search for messages with FINAL_ANSWER tags (from newest to oldest)
        for msg in reversed(messages):
            if msg.get("role") == "assistant":
                content = msg.get("content")
                if isinstance(content, str):
                    # Try to extract answer from special tokens
                    match = re.search(r'<FINAL_ANSWER>(.*?)</FINAL_ANSWER>', content, re.DOTALL)
                    if match:
                        answer = match.group(1).strip()
                        if answer:
                            return answer

        # Fallback: return last assistant message if no tags found
        for msg in reversed(messages):
            if msg.get("role") == "assistant":
                content = msg.get("content")
                if isinstance(content, str) and content.strip():
                    return content
                if content is not None:
                    return str(content)

        return None
    
    def _save_conversation_log(self, output_dir, task_id, question, model, messages, result):
        import os
        import json
        try:
            os.makedirs(output_dir, exist_ok=True)
            safe_task_id = "".join([c if c.isalnum() or c in "-_." else "_" for c in str(task_id)])
            file_path = os.path.join(output_dir, f"{safe_task_id}.json")
            assistant_turns = sum(1 for m in messages if m.get("role") == "assistant")
            log_content = {
                "meta": {
                    "task_id": task_id,
                    "model_name": model,
                    "timestamp": datetime.now().isoformat(),
                    "output_file": file_path
                },
                "task": {
                    "question": question,
                    "status": "success" if result.get("success") else "failed",
                    "final_answer": result.get("answer"),
                    "total_turns": assistant_turns
                },
                "raw_result": result,
            }
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(log_content, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"[{self.worker_id}] âœ… Conversation log saved to: {file_path}")
        except Exception as e:
            logger.error(f"[{self.worker_id}] âŒ Failed to save conversation log: {e}")

    # =========================================================================
    # OpenAI Client ç®¡ç†
    # =========================================================================

    def _get_openai_client(self) -> openai.OpenAI:
        if not hasattr(self, '_openai_client') or self._openai_client is None:
            api_key = self.config.get("openai_api_key") or os.environ.get("OPENAI_API_KEY", "")
            base_url = self.config.get("openai_api_url") or os.environ.get("OPENAI_API_URL") or os.environ.get("OPENAI_API_BASE")
            timeout = float(self.config.get("openai_timeout", os.environ.get("OPENAI_TIMEOUT", "30")))
            max_retries = int(self.config.get("openai_max_retries", os.environ.get("OPENAI_MAX_RETRIES", "2")))

            # å‡å°‘æ—¥å¿—ï¼šç§»é™¤OpenAI clientåˆå§‹åŒ–æ—¥å¿—
            # logger.info(f"[{self.worker_id}] Initializing OpenAI client...")

            openai.api_key = api_key
            if base_url:
                openai.base_url = base_url
                self._openai_client = openai.OpenAI(
                    api_key=api_key, base_url=base_url, timeout=timeout, max_retries=max_retries
                )
            else:
                self._openai_client = openai.OpenAI(
                    api_key=api_key, timeout=timeout, max_retries=max_retries
                )
        return self._openai_client

    # =========================================================================
    # å·¥å…·ç®¡ç†ä¸æ‰§è¡Œ (é€‚é… MCP)
    # =========================================================================

    def execute_tool(self, tool_name: str, params: Union[str, dict], **kwargs) -> Union[str, Dict[str, Any]]:
        """æ‰§è¡Œå·¥å…·ï¼šç›´æ¥ä»£ç†åˆ° MCP"""
        if isinstance(params, str):
            try:
                params = json.loads(params)
            except:
                pass
        return self._call_tool_sync(tool_name, params)

    def get_tool_schemas(self) -> List[ChatCompletionToolParam]:
        return self.tool_schemas  # type: ignore

    def get_tool_descriptions(self) -> str:
        return self.tool_descriptions

    # =========================================================================
    # Prompt å·¥ç¨‹
    # =========================================================================

    def get_action_space(self) -> Optional[str]:
        mode_config = self.config.get(self.mode)
        if isinstance(mode_config, dict) and "action_space" in mode_config:
            return mode_config.get("action_space")
        return self.config.get("action_space")

    def get_system_prompt(self, task_question: Optional[str] = None, **kwargs) -> str:
        action_space = self.get_action_space()
        if action_space is None:
            prompt_template = get_system_prompt(environment_mode=self.mode)
        else:
            prompt_template = get_system_prompt(
                environment_mode=self.mode, action_space=action_space
            )

        prompt = prompt_template.replace("{tool_descriptions}", self.get_tool_descriptions())

        if task_question:
            prompt += f"\nYou are asked to complete the following task: {task_question}"
        
        return prompt

    # =========================================================================
    # MCP ä¸“ç”¨é€»è¾‘
    # =========================================================================

    def _load_gateway_config(self, config_path: str) -> Dict[str, Any]:
        if not os.path.exists(config_path):
            return {"modules": []}
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {"modules": []}

    def _initialize_tools(self):
        """ä» MCP Server è·å–å·¥å…·åˆ—è¡¨å¹¶è¿›è¡Œæœ¬åœ°é€‚é…"""
        if not self._tools_initialized:
            return

        try:
            # å‡å°‘æ—¥å¿—ï¼šç§»é™¤å·¥å…·è·å–æ—¥å¿—
            # logger.info(f"[{self.worker_id}] Fetching tools from MCP Server...")
            mcp_tools = self._list_tools_sync()

            # 1. é»˜è®¤ä¸ºç™½åå•ä¼˜å…ˆï¼ˆå¦‚æœªé…ç½®ç™½åå•ï¼Œåˆ™å›é€€åˆ°é»‘åå•ä¸éšè—æ ‡è®°è¿‡æ»¤ï¼‰
            default_blacklist = {
                "get_observation", "evaluate_task",
                "allocate_batch_resources", "setup_batch_resources",
                "get_batch_initial_observations", "setup_vm_session",
                "setup_rag_session", "teardown_rag_session", "teardown_environment", "release_rag_session",
            }

            valid_tools = []
            self.local_tools = {}

            for t in mcp_tools:
                # 1) ç™½åå•ä¼˜å…ˆï¼šè‹¥é…ç½®äº†ç™½åå•ï¼Œåˆ™ä»…å…è®¸ç™½åå•å†…çš„å·¥å…·
                if self._tool_whitelist:
                    if t.name not in self._tool_whitelist:
                        continue
                else:
                    # 2) æœªè®¾ç½®ç™½åå•æ—¶ï¼Œä½¿ç”¨é»‘åå• + [HIDDEN] è¿‡æ»¤ä½œä¸ºå…œåº•ç­–ç•¥
                    if t.name in default_blacklist:
                        continue
                    description = t.description or ""
                    if description.startswith("[HIDDEN]"):
                        continue
                
                valid_tools.append(t)
                
                # [æ ¸å¿ƒé€‚é…] å°† MCP Schema è½¬æ¢ä¸º ToolMetadata (List[Dict] æ ¼å¼)
                # è¿™å…è®¸ GenericTrajectorySampler èƒ½å¤Ÿè¯»å– tool.parameters
                converted_params = self._convert_schema_to_params(t.inputSchema)
                self.local_tools[t.name] = ToolMetadata(
                    name=t.name,
                    description=t.description or "",
                    parameters=converted_params
                )

            # ç”Ÿæˆ Schema å’Œæè¿°å­—ç¬¦ä¸²ç»™ LLM
            self.tool_schemas = [self._convert_mcp_tool_to_openai(t) for t in valid_tools]

            descriptions = [f"- {t.name}: {t.description or 'No description.'}" for t in valid_tools]
            self.tool_descriptions = "\n".join(descriptions)

            # å‡å°‘æ—¥å¿—ï¼šç§»é™¤å·¥å…·æ•°é‡æ—¥å¿—
            # logger.info(f"[{self.worker_id}] {len(valid_tools)} tools initialized")

        except Exception as e:
            logger.error(f"[{self.worker_id}] Failed to initialize tools: {e}")

    def _convert_schema_to_params(self, schema: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å°† JSON Schema properties è½¬æ¢ä¸ºå‚æ•°åˆ—è¡¨æ ¼å¼"""
        params = []
        if not schema or "properties" not in schema:
            return params
            
        required_set = set(schema.get("required", []))
        properties = schema.get("properties", {})
        
        for name, prop in properties.items():
            if name == "worker_id": 
                continue
            
            param_def = {
                "name": name,
                "type": prop.get("type", "string"),
                "description": prop.get("description", ""),
                "required": name in required_set
            }
            if param_def["type"] == "array" and "items" in prop:
                 param_def["array_type"] = prop["items"].get("type", "string")
                 
            params.append(param_def)
        return params

    def _convert_mcp_tool_to_openai(self, mcp_tool) -> ChatCompletionToolParam:
        """
        å°† MCP å·¥å…·å®šä¹‰è½¬æ¢ä¸º OpenAI å·¥å…·æ ¼å¼ã€‚
        è‡ªåŠ¨ç§»é™¤ worker_id å‚æ•°ï¼Œå› ä¸ºå®ƒç”±ç¯å¢ƒè‡ªåŠ¨æ³¨å…¥ã€‚
        """
        # æ·±æ‹·è´é¿å…ä¿®æ”¹åŸå§‹ schema
        parameters = {}
        if hasattr(mcp_tool, "inputSchema") and mcp_tool.inputSchema:
            parameters = mcp_tool.inputSchema.copy()
        
        # ç§»é™¤ worker_id å‚æ•°ï¼ˆç¯å¢ƒè‡ªåŠ¨æ³¨å…¥ï¼‰
        if "properties" in parameters and "worker_id" in parameters["properties"]:
            del parameters["properties"]["worker_id"]
        if "required" in parameters and "worker_id" in parameters["required"]:
            parameters["required"] = [p for p in parameters["required"] if p != "worker_id"]

        return {
            "type": "function",
            "function": {
                "name": mcp_tool.name,
                "description": mcp_tool.description or "No description provided.",
                "parameters": parameters
            }
        }

    def env_start(self):
        logger.info(f"Worker [{self.worker_id}] connecting to MCP...")
        self._run_sync(self.mcp_client.connect())
        self._tools_initialized = True
        self._initialize_tools()

    def env_close(self):
        if hasattr(self, '_loop') and not self._loop.is_closed():
            self._loop.close()

    def _run_sync(self, awaitable):
        return self._loop.run_until_complete(awaitable)

    def _list_tools_sync(self):
        return self._run_sync(self.mcp_client.list_tools())

    def _call_tool_sync(self, name: str, arguments: Union[Dict[str, Any], str]):
        """
        åŒæ­¥è°ƒç”¨ MCP å·¥å…·
        
        è‡ªåŠ¨æ³¨å…¥ worker_id å‚æ•°ï¼ˆå¦‚æœç¼ºå¤±ï¼‰ä»¥ç¡®ä¿å·¥å…·è°ƒç”¨çš„ä¸€è‡´æ€§ã€‚
        ç‰¹æ®Šå¤„ç†èµ„æºç®¡ç†ç±»å·¥å…·çš„è¿”å›å€¼ã€‚
        """
        # ç¡®ä¿å‚æ•°æ˜¯å­—å…¸æ ¼å¼
        if isinstance(arguments, str):
            try:
                arguments = json.loads(arguments)
            except json.JSONDecodeError:
                logger.error(f"Invalid JSON arguments for tool {name}: {arguments}")
                raise ValueError(f"Invalid JSON arguments for tool {name}")

        # è‡ªåŠ¨æ³¨å…¥ worker_idï¼ˆå¦‚æœç¼ºå¤±ï¼‰
        if isinstance(arguments, dict) and "worker_id" not in arguments:
            arguments["worker_id"] = self.worker_id

        # è®°å½•è°ƒç”¨æ—¥å¿—ï¼ˆæˆªæ–­é•¿å‚æ•°ï¼‰
        try:
            if isinstance(arguments, dict):
                safe_args = dict(arguments)
                if "messages" in safe_args:
                    msgs = safe_args["messages"]
                    safe_args["messages"] = f"[len={len(msgs)}]"
            else:
                safe_args = arguments
            logger.info(f"[{self.worker_id}] ğŸ”§ Tool call -> {name} args={safe_args}")
        except Exception:
            pass

        # å‘èµ·åŒæ­¥å·¥å…·è°ƒç”¨
        try:
            res: CallToolResult = self._run_sync(self.mcp_client.call_tool(name, arguments))
        except Exception as e:
            logger.error(f"[{self.worker_id}] âŒ Tool call failed -> {name}: {e}")
            # è¿”å›æ ‡å‡†åŒ–é”™è¯¯ç»“æ„ï¼Œé¿å…ä¸Šå±‚å´©æºƒ
            return {"text": json.dumps({"status": "error", "tool": name, "message": str(e)}, ensure_ascii=False), "images": []}

        # ç‰¹æ®Šå¤„ç†èµ„æºç®¡ç†ç±»å·¥å…·ï¼ˆç›´æ¥è¿”å›åŸå§‹ç»“æœï¼‰
        resource_management_tools = {
            "allocate_batch_resources", "setup_batch_resources",
            "get_batch_initial_observations", "teardown_environment",
            "release_batch_resources"
        }
        if name in resource_management_tools:
            return res

        # æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰
        output = {
            "text": "",
            "images": []
        }

        # è§£æ MCP å“åº”å†…å®¹
        texts = []
        if hasattr(res, 'content') and res.content:
            for item in res.content:
                # æ–‡æœ¬å†…å®¹ç´¯ç§¯
                if item.type == 'text':
                    texts.append(item.text)
                # å›¾åƒå†…å®¹æ”¶é›†
                elif item.type == 'image':
                    # æ”¯æŒ Data URI å’Œçº¯ Base64 ä¸¤ç§æ ¼å¼
                    image_data = item.data
                    if ',' in image_data:
                        # Data URI æ ¼å¼: data:image/png;base64,...
                        image_data = image_data.split(',', 1)[1]
                    output["images"].append(image_data)
        else:
            # æ— å†…å®¹æ—¶è¿”å›é»˜è®¤æˆåŠŸæ¶ˆæ¯
            texts.append(str(res) if res else "Success")

        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬å†…å®¹
        output_text = "\n".join(texts)
        output["text"] = output_text

        # è®°å½•è¿”å›æ‘˜è¦ï¼ˆæˆªæ–­ï¼‰
        try:
            preview = output_text[:200].replace("\n", " ") if output_text else ""
            logger.info(f"[{self.worker_id}] âœ… Tool result <- {name} text='{preview}' images={len(output['images'])}")
            # æ£€æµ‹ç»“æ„åŒ–é”™è¯¯å¹¶æ‰“å°
            try:
                data = json.loads(output_text)
                if isinstance(data, dict) and data.get("status") == "error":
                    logger.error(f"[{self.worker_id}] â— Tool error <- {name}: {data.get('message')}")
            except Exception:
                pass
        except Exception:
            pass
        return output

    def _parse_mcp_response(self, response: CallToolResult) -> Dict[str, Any]:
        try:
            if response.content and len(response.content) > 0:
                content_item = response.content[0]
                text_content = getattr(content_item, 'text', None)
                if not text_content and hasattr(content_item, 'resource'):
                    text_content = getattr(content_item.resource, 'text', None)
                
                if text_content:
                    try:
                        data = json.loads(text_content)
                        if isinstance(data, dict) and data.get("status") == "error":
                            logger.error(f"[{self.worker_id}] Tool returned error payload: {data}")
                        return data
                    except Exception as e:
                        logger.error(f"[{self.worker_id}] Failed to parse MCP response JSON: {e}")
                        return {"status": "error", "message": str(e), "raw": text_content}
            return {"status": "unknown"}
        except Exception as e:
            logger.error(f"[{self.worker_id}] Exception parsing MCP response: {e}")
            return {"status": "error", "message": str(e)}

    def get_inital_obs(self) -> Dict[str, Any]:
        """è°ƒç”¨ MCP è·å–åˆå§‹è§‚å¯Ÿï¼Œå¹¶åº”ç”¨é»‘åå•è¿‡æ»¤"""
        # å‡å°‘æ—¥å¿—ï¼šç§»é™¤åˆå§‹è§‚å¯Ÿè·å–æ—¥å¿—
        # logger.info(f"[{self.worker_id}] Fetching initial observations...")

        combined_obs = {}
        self.initial_observation = None # é‡ç½®ä¸»è§‚å¯Ÿ

        # 1. ä» self.config (å·²åˆå¹¶ä»»åŠ¡ metadata) è·å–é»‘åå•è®¾ç½®
        # resource_blacklist: èµ„æºç±»å‹é»‘åå•åˆ—è¡¨ï¼Œä¾‹å¦‚ ['rag', 'vm_pyautogui']
        resource_blacklist = self.config.get("observation_blacklist", [])
        # content_blacklist: èµ„æºå†…å®¹ç»†ç²’åº¦é»‘åå•ï¼Œä¾‹å¦‚ {'vm_computer_13': ['accessibility_tree']}
        content_blacklist = self.config.get("observation_content_blacklist", {})

        try:
            # è°ƒç”¨ç³»ç»Ÿå·¥å…·è·å–æ‰€æœ‰èµ„æºçš„åˆå§‹è§‚å¯Ÿ
            res = self._call_tool_sync("get_batch_initial_observations", {"worker_id": self.worker_id})
            data = self._parse_mcp_response(res)

            # === å‡å°‘æ—¥å¿—ï¼šç§»é™¤åŸå§‹è§‚å¯Ÿæ•°æ®å’Œè¿‡æ»¤åè§‚å¯Ÿæ•°æ®çš„è¯¦ç»†æ—¥å¿— ===
            # safe_data = self._truncate_data(data, max_len=100)
            # logger.info(f"[{self.worker_id}] [OBS_LOG] Raw observation data from MCP (Truncated): {json.dumps(safe_data, indent=2, ensure_ascii=False)}")

            if isinstance(data, dict) and "error" not in data:
                # 2. éå†å¹¶åº”ç”¨é»‘åå•è¿‡æ»¤
                for resource_type, obs_content in data.items():
                    # A. èµ„æºç±»å‹é»‘åå•è¿‡æ»¤
                    if resource_type in resource_blacklist:
                        # å‡å°‘æ—¥å¿—ï¼šç§»é™¤é»‘åå•è·³è¿‡æ—¥å¿—
                        # logger.info(f"[{self.worker_id}] Blacklisted resource observation skipped: {resource_type}")
                        continue
                        
                    # B. è§‚å¯Ÿå†…å®¹ç»†ç²’åº¦è¿‡æ»¤
                    filtered_obs_content = obs_content
                    if resource_type in content_blacklist and isinstance(obs_content, dict):
                        # å¯¹èµ„æºå†…å®¹è¿›è¡Œæ‹·è´ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                        filtered_obs_content = obs_content.copy()
                        keys_to_remove = content_blacklist[resource_type]
                        
                        for key in keys_to_remove:
                            if key in filtered_obs_content:
                                del filtered_obs_content[key]
                                # å‡å°‘æ—¥å¿—ï¼šç§»é™¤é»‘åå•å†…å®¹ç§»é™¤æ—¥å¿—
                                # logger.info(f"[{self.worker_id}] Blacklisted observation content removed: {resource_type}.{key}")

                    combined_obs[resource_type] = filtered_obs_content

                    # 3. åŠ¨æ€ç¡®å®šä¸»è¦è§‚å¯Ÿ (ç”¨äº LLM æ³¨å…¥)
                    # ä¼˜å…ˆå°†è§†è§‰ç¯å¢ƒï¼ˆvm/desktopç›¸å…³çš„ï¼‰ä¸”éç©ºçš„è§‚å¯Ÿè®¾ä¸ºä¸»è§‚å¯Ÿ
                    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨å¯å‘å¼æ£€æŸ¥ï¼ŒåŒæ—¶è¿‡æ»¤æ‰å†…å®¹ä¸ºç©ºæˆ–åªå‰©å°‘é‡é”®çš„è§‚å¯Ÿ
                    if self.initial_observation is None and ("vm" in resource_type.lower() or "desktop" in resource_type.lower()):
                         # ç¡®ä¿è¿‡æ»¤åä»åŒ…å«ç”¨äºä¸»è§‚å¯Ÿçš„å¿…è¦å†…å®¹ (å¦‚ screenshot)
                         if filtered_obs_content and any(key in filtered_obs_content for key in ["screenshot", "accessibility_tree", "text"]):
                            self.initial_observation = filtered_obs_content
                         
            else:
                logger.warning(f"[{self.worker_id}] Failed to fetch obs: {data.get('error')}")

            # === å‡å°‘æ—¥å¿—ï¼šç§»é™¤æœ€ç»ˆè§‚å¯Ÿå’Œä¸»è§‚å¯Ÿçš„è¯¦ç»†æ—¥å¿— ===
            # safe_obs = self._truncate_data(combined_obs, max_len=100)
            # logger.info(f"[{self.worker_id}] [OBS_LOG] Final combined observations (Filtered & Truncated): {json.dumps(safe_obs, indent=2, ensure_ascii=False)}")
            # if self.initial_observation:
            #     logger.info(f"[{self.worker_id}] [OBS_LOG] Primary initial_observation SET. Keys: {list(self.initial_observation.keys())}")
            # else:
            #     logger.info(f"[{self.worker_id}] [OBS_LOG] Primary initial_observation is None.")

            return combined_obs
        except Exception as e:
            logger.error(f"[{self.worker_id}] Obs fetch error: {e}")
            # å³ä½¿å¤±è´¥ï¼Œä¹Ÿè¦è¿”å›å·²æ”¶é›†çš„éƒ¨åˆ†è§‚å¯Ÿç»“æœ
            return combined_obs

    def allocate_resource(self, worker_id: str, resource_init_data: Optional[Dict[str, Any]] = None) -> bool:
        """
        ç»Ÿä¸€çš„èµ„æºåˆ†é…å…¥å£å‡½æ•° (MCP æ¨¡å¼)
        """
        resource_init_data = resource_init_data or {}
        # å‡å°‘æ—¥å¿—ï¼šç®€åŒ–èµ„æºåˆ†é…å¼€å§‹æ—¥å¿—
        logger.info(f"[{worker_id}] Allocating resources...")
        self.initial_observation = None

        try:
            if not self.active_resources:
                 logger.info(f"[{self.worker_id}] Running in stateless mode (no heavy resources required). Initializing tools only.")
                 # å³ä½¿æ²¡æœ‰éœ€è¦åˆ†é…çš„èµ„æºï¼Œä¹Ÿè°ƒç”¨è·å–è§‚å¯Ÿå€¼ï¼Œå› ä¸ºå¯èƒ½æœ‰æ— çŠ¶æ€å·¥å…·å¯ç”¨
                 self.get_inital_obs()
                 return True

            # 1. ç”³è¯·èµ„æº
            # å‡å°‘æ—¥å¿—ï¼šç§»é™¤æ‰¹é‡èµ„æºåˆ†é…è¯¦ç»†æ—¥å¿—
            # logger.info(f"[{self.worker_id}] Allocating batch resources: {self.active_resources}...")
            res = self._call_tool_sync("allocate_batch_resources", {
                "resource_types": self.active_resources,
                "timeout": 600
            })
            data = self._parse_mcp_response(res)
            if isinstance(data, dict) and data.get("status") == "error":
                 logger.error(f"Alloc failed: {data.get('message')}")
                 return False

            self.allocated_resources = data

            # 2. åˆå§‹åŒ–èµ„æºï¼ˆæ€»æ˜¯è°ƒç”¨ä»¥ç¡®ä¿ä¼šè¯åŒæ­¥ï¼‰
            # å³ä½¿æ²¡æœ‰ resource_init_dataï¼Œä¹Ÿéœ€è¦è°ƒç”¨ setup_batch_resources æ¥åŒæ­¥ä¼šè¯
            # å‡å°‘æ—¥å¿—ï¼šç§»é™¤èµ„æºè®¾ç½®æ—¥å¿—
            # logger.info(f"[{self.worker_id}] Setting up resources...")
            setup_res = self._call_tool_sync("setup_batch_resources", {
                "resource_init_configs": resource_init_data,  # å¯ä»¥ä¸ºç©º dictï¼Œä¸å½±å“ä¼šè¯åŒæ­¥
                "allocated_resources": data  # å…³é”®ï¼šä¼ é€’å·²åˆ†é…çš„èµ„æºä¿¡æ¯ç”¨äº _sync_resource_sessions
            })
            setup_result = self._parse_mcp_response(setup_res)
            if setup_result.get("status") not in ["success", "partial_error"]:
                logger.error(f"Setup failed: {setup_result}")
                self.release_resource(self.worker_id)
                return False

            # 3. è·å–åˆå§‹è§‚å¯Ÿ
            self.get_inital_obs()
            return True

        except Exception as e:
            logger.error(f"Allocate resource exception: {e}")
            return False

    def release_resource(self, worker_id: str, reset: bool = True) -> None:
        """
        ç»Ÿä¸€é‡Šæ”¾æ‰€æœ‰å·²åˆ†é…çš„èµ„æº (MCP æ¨¡å¼)
        è°ƒç”¨ system_resource ç»„çš„ release_batch_resources å·¥å…·
        """
        # å‡å°‘æ—¥å¿—ï¼šç®€åŒ–èµ„æºé‡Šæ”¾å¼€å§‹æ—¥å¿—
        logger.info(f"[{worker_id}] Releasing resources...")
        
        # æ”¶é›†æ‰€æœ‰å·²åˆ†é…èµ„æºçš„ ID
        resource_ids = []
        for res_type, res_data in self.allocated_resources.items():
            if isinstance(res_data, dict) and "id" in res_data:
                resource_ids.append(res_data["id"])
        
        if not resource_ids:
            # å‡å°‘æ—¥å¿—ï¼šç§»é™¤æ— èµ„æºé‡Šæ”¾æ—¥å¿—
            # logger.info(f"Worker [{worker_id}] has no resources to release.")
            return

        try:
            # [æ ¸å¿ƒä¿®æ”¹] è°ƒç”¨ MCP å·¥å…·è¿›è¡Œæ‰¹é‡é‡Šæ”¾
            self._call_tool_sync("release_batch_resources", {
                "worker_id": worker_id,
                "resource_ids": resource_ids
            })

            # æ¸…ç©ºæœ¬åœ°è®°å½•
            self.allocated_resources.clear()
            # å‡å°‘æ—¥å¿—ï¼šç§»é™¤é‡Šæ”¾å®Œæˆæ—¥å¿—
            # logger.info(f"Worker [{worker_id}] release completed.")

        except Exception as e:
            logger.error(f"Failed to release resources via MCP: {e}")

    def get_allocated_resource_id(self) -> str:
        return self.worker_id
    # =========================================================================
    # [æ–°å¢] ç¼ºå¤±çš„è¾…åŠ©åŠŸèƒ½å‡½æ•° (é€‚é…æ¡†æ¶è°ƒç”¨)
    # =========================================================================

    def get_task_output_dir(self, base_dir: str, task_id: str, model_name: str) -> str:
        """
        ç”Ÿæˆä»»åŠ¡ç‰¹å®šçš„è¾“å‡ºç›®å½•è·¯å¾„ã€‚
        
        Args:
            base_dir: åŸºç¡€è¾“å‡ºç›®å½• (å¦‚ 'results')
            task_id: ä»»åŠ¡ ID
            model_name: æ¨¡å‹åç§°
            
        Returns:
            å®Œæ•´çš„è¾“å‡ºç›®å½•è·¯å¾„ (ä¾‹å¦‚: results/gpt-4/task-001)
        """
        # å¯¹æ¨¡å‹åç§°è¿›è¡Œæ–‡ä»¶ç³»ç»Ÿå®‰å…¨å¤„ç†
        safe_model = "".join([c if c.isalnum() or c in "-_." else "_" for c in model_name])
        
        # è¿™é‡Œçš„ç­–ç•¥æ˜¯ï¼šå°†æ‰€æœ‰æ—¥å¿—å½’æ¡£åœ¨ä»¥ "æ¨¡å‹å" å‘½åçš„å­ç›®å½•ä¸‹
        # run_task ä¸­çš„ _save_conversation_log ä¼šåœ¨è¿™ä¸ªç›®å½•ä¸‹åˆ›å»º {task_id}.json
        path = os.path.join(base_dir, safe_model)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(path, exist_ok=True)
        return path

    def initialize_with_task_config(self, task_config: Dict[str, Any]) -> None:
        """
        æ¥å—ä»»åŠ¡çº§åˆ«çš„ç‰¹å®šé…ç½®ï¼ˆå¦‚åˆ†è¾¨ç‡è¦æ±‚ã€ç‰¹å®šç¯å¢ƒå‚æ•°ç­‰ï¼‰ã€‚
        æ¡†æ¶ä¼šåœ¨ run_task ä¹‹å‰è°ƒç”¨æ­¤æ–¹æ³•ã€‚
        """
        if not task_config:
            return

        # å‡å°‘æ—¥å¿—ï¼šç§»é™¤ä»»åŠ¡é…ç½®åº”ç”¨æ—¥å¿—
        # logger.info(f"[{self.worker_id}] Applying task specific config: {task_config}")
        # æ›´æ–°å®ä¾‹é…ç½®ï¼Œä»¥ä¾¿åç»­ allocate/setup é˜¶æ®µå¯ä»¥ä½¿ç”¨æ–°å‚æ•°
        self.config.update(task_config)

    def init(self):
        """
        Worker è¿›ç¨‹å¯åŠ¨åçš„å¯é€‰åˆå§‹åŒ–é’©å­ã€‚
        æ¡†æ¶åœ¨å®ä¾‹åŒ–ç¯å¢ƒåä¼šå°è¯•è°ƒç”¨æ­¤æ–¹æ³•ã€‚
        """
        # åœ¨ MCP æ¨¡å¼ä¸‹ï¼Œè¿æ¥å·²ç»åœ¨ env_start ä¸­å»ºç«‹ï¼Œæ­¤å¤„å¯ç•™ç©ºæˆ–åšé¢å¤–æ£€æŸ¥
        pass

    def cleanup(self, worker_id: Optional[str] = None):
        """
        æ¸…ç†èµ„æºçš„ç»Ÿä¸€å…¥å£ã€‚
        æ¡†æ¶åœ¨ Worker é€€å‡ºæˆ–æ”¶åˆ°åœæ­¢ä¿¡å·æ—¶ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚
        """
        wid = worker_id or self.worker_id
        # å‡å°‘æ—¥å¿—ï¼šç§»é™¤æ¸…ç†å¼€å§‹æ—¥å¿—
        # logger.info(f"[{wid}] Cleaning up environment resources...")
        try:
            # 1. é‡Šæ”¾è¿œç«¯èµ„æº
            self.release_resource(wid)
            # 2. å…³é—­ MCP è¿æ¥
            self.env_close()
        except Exception as e:
            logger.error(f"[{wid}] Cleanup failed: {e}")

    def _truncate_data(self, data: Any, max_len: int = 100) -> Any:
        """
        è¾…åŠ©å‡½æ•°ï¼šé€’å½’æˆªæ–­æ•°æ®ç»“æ„ä¸­çš„é•¿å­—ç¬¦ä¸²ï¼Œä»…ç”¨äºæ—¥å¿—å±•ç¤ºã€‚
        """
        if isinstance(data, dict):
            return {k: self._truncate_data(v, max_len) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._truncate_data(i, max_len) for i in data]
        elif isinstance(data, str):
            if len(data) > max_len:
                # ä¿ç•™å‰ max_len ä¸ªå­—ç¬¦ï¼Œå¹¶æç¤ºæ€»é•¿åº¦
                return f"{data[:max_len]}... [TRUNCATED, total_len={len(data)}]"
            return data
        else:
            return data

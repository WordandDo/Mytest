# -*- coding: utf-8 -*-
"""
Environment Base Class & Development Guide

=============================================================================
ã€å¼€å‘æŒ‡å— (Development Guide)ã€‘
=============================================================================

1. æ ¸å¿ƒæ¦‚å¿µ (Core Concept):
   Environment æ˜¯ Agent ä¸å¤–éƒ¨ä¸–ç•Œäº¤äº’çš„å®¹å™¨ã€‚å®ƒè´Ÿè´£ï¼š
   - æ³¨å†Œå’Œç®¡ç†å·¥å…· (Tools)
   - ç”Ÿæˆæ ‡å‡†åŒ–çš„ç³»ç»Ÿæç¤ºè¯ (System Prompts)
   - å®šä¹‰ Agent æ‰§è¡Œä»»åŠ¡çš„å…·ä½“é€»è¾‘ (run_task)
   - ç®¡ç†ç¯å¢ƒèµ„æº (å¦‚è™šæ‹Ÿæœºã€æµè§ˆå™¨ã€APIè¿æ¥)

2. ç»§æ‰¿è§„èŒƒ (Inheritance):
   æ–°å»ºç¯å¢ƒå¿…é¡»ç»§æ‰¿è‡ª `Environment` ç±»ï¼Œå¹¶å®ç°ä»¥ä¸‹æŠ½è±¡æ¥å£ï¼š
   
   (1) @property mode(self) -> str:
       å®šä¹‰ç¯å¢ƒçš„å”¯ä¸€æ ‡è¯†ç¬¦ (å¦‚ 'math', 'osworld', 'rag')ã€‚
       è¯¥æ ‡è¯†ç¬¦ç”¨äºæŸ¥æ‰¾ System Prompt å’Œé…ç½®æ–‡ä»¶ã€‚

   (2) _initialize_tools(self):
       åœ¨æ­¤æ–¹æ³•ä¸­å®ä¾‹åŒ–å¹¶æ³¨å†Œæ‰€éœ€å·¥å…·ã€‚
       å¿…é¡»ä½¿ç”¨ `self.register_tool(tool_instance)`ï¼Œä»¥ä¾¿æ¡†æ¶è‡ªåŠ¨ç”Ÿæˆ Schemaã€‚

   (3) run_task(self, task, agent_config, logger) -> Dict:
       å®šä¹‰ Agent çš„æ ¸å¿ƒæ‰§è¡Œå¾ªç¯ (Prompt -> LLM -> Tool -> Observation)ã€‚
       * å¿…é¡»è¿”å›åŒ…å« 'answer' å­—æ®µçš„å­—å…¸ï¼Œä»¥ä¾¿ Benchmark è¿›è¡Œè‡ªåŠ¨è¯„æµ‹ã€‚
       * å¿…é¡»ä½¿ç”¨ `self.execute_tool()` æ¥è°ƒç”¨å·¥å…·ï¼Œä¸¥ç¦ç›´æ¥è°ƒç”¨ tool.call()ã€‚

3. èµ„æºç®¡ç† (Resource Management) [å¯é€‰]:
   å¯¹äºéœ€è¦é‡å‹èµ„æº (å¦‚è™šæ‹Ÿæœºã€Docker) çš„ç¯å¢ƒï¼š
   - é‡å†™ `@classmethod setup_global_resources(config)`: åœ¨ä¸»è¿›ç¨‹åˆå§‹åŒ–èµ„æºæ± ã€‚
   - é‡å†™ `env_start()`: åœ¨ Worker è¿›ç¨‹å¼€å§‹æ—¶ç”³è¯·å…·ä½“èµ„æºã€‚
   - é‡å†™ `env_close()`: åœ¨ä»»åŠ¡ç»“æŸæˆ–è¿›ç¨‹é€€å‡ºæ—¶é‡Šæ”¾èµ„æºã€‚

4. æç¤ºè¯å®šåˆ¶ (Prompt Customization) [å¯é€‰]:
   å¦‚æœ System Prompt ä¸­åŒ…å«è‡ªå®šä¹‰å ä½ç¬¦ (å¦‚ {CLIENT_PASSWORD}):
   - é‡å†™ `_replace_prompt_placeholders(self, prompt)` æ–¹æ³•æ¥æ³¨å…¥åŠ¨æ€ä¿¡æ¯ã€‚

5. å…±äº«æ•°æ®ç»“æ„ (Shared Data Models):
   æ‰€æœ‰ç¯å¢ƒåœ¨è®°å½•/è¿”å›è§‚æµ‹ä¸è½¨è¿¹æ—¶ï¼Œåº”å¤ç”¨ `envs.data_models` ä¸­çš„
   `Observation`, `TrajectoryStep`, `TaskTrajectory` æ•°æ®ç±»ï¼Œä»è€Œä¿è¯ä¸
   data_synthesis ç®¡çº¿çš„æ•°æ®æ ¼å¼ä¸€è‡´ã€‚æœ¬æ–‡æ¡£é€šè¿‡å¯¼å…¥å¹¶å¯¼å‡ºè¿™äº›ç±»å‹ï¼Œ
   æ–¹ä¾¿å¼€å‘è€…ç›´æ¥å¤ç”¨ã€‚

=============================================================================
"""
import logging
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Union

from .data_models import Observation, TrajectoryStep, TaskTrajectory
from prompts.system_prompts import get_system_prompt as load_system_prompt
from tools.tool import Tool
from utils.resource_manager import ResourceManager
import openai
import os
import json

__all__ = [
    "Environment",
    "Observation",
    "TrajectoryStep",
    "TaskTrajectory",
]


class Environment(ABC):
    """
    Agent ç¯å¢ƒåŸºç±» (ç²¾ç®€ç‰ˆ)
    
    èŒè´£ï¼š
    1. å®šä¹‰ç¯å¢ƒæ¥å£è§„èŒƒ (Mode, Run Task)
    2. æä¾›åŸºç¡€å·¥å…·ç®¡ç† (Register, Execute, Schema)
    3. æä¾›èµ„æºç®¡ç†æ¥å£ (Setup Global Resources)
    """
    
    # ã€æ–°å¢ã€‘å®šä¹‰ç±»å±æ€§ï¼šé»˜è®¤ä¸éœ€è¦é‡å‹èµ„æº
    # å­ç±»å¦‚æœéœ€è¦ï¼ˆå¦‚ OSWorldï¼‰ï¼Œåªéœ€è¦†ç›–æ­¤å±æ€§ä¸º True
    has_heavy_resource = False 
    
    def __init__(self, 
                 model_name: str = "gpt-4.1-2025-04-14",
                 resource_manager: Optional['ResourceManager'] = None,
                 **kwargs):
        """
        åŸºç¡€åˆå§‹åŒ–ã€‚
        
        Args:
            model_name: é»˜è®¤æ¨¡å‹åç§°
            resource_manager: èµ„æºç®¡ç†å™¨å®ä¾‹ (ç”± setup_global_resources åˆ›å»º)
            **kwargs: å…¶ä»–é…ç½®å‚æ•° (ä¿å­˜è‡³ self.config)
        """
        self.model_name = model_name
        self.config = kwargs
        
        # å·¥å…·ç®¡ç†
        self.tools: Dict[str, Tool] = {}
        self.tool_schemas: List[Dict[str, Any]] = []
        self.tool_descriptions: str = ""
        
        # èµ„æºç®¡ç†
        if resource_manager is None:
            from utils.resource_manager import NoResourceManager
            self._resource_manager: ResourceManager = NoResourceManager()
        else:
            self._resource_manager = resource_manager
            
        # è‡ªåŠ¨è°ƒç”¨å­ç±»å·¥å…·åˆå§‹åŒ–
        self._initialize_tools()

    # =========================================================================
    # 1. æ ¸å¿ƒæŠ½è±¡æ¥å£ (å¼€å‘è€…å¿…é¡»å®ç°)
    # =========================================================================
    
    @property
    @abstractmethod
    def mode(self) -> str:
        """è¿”å›ç¯å¢ƒæ¨¡å¼åç§° (å¦‚ 'math', 'osworld')"""
        pass

    @abstractmethod
    def _initialize_tools(self):
        """åœ¨æ­¤æ–¹æ³•ä¸­æ³¨å†Œç¯å¢ƒæ‰€éœ€çš„å·¥å…·"""
        pass


    def run_task(self, task: Dict[str, Any], agent_config: Dict[str, Any], logger: logging.Logger) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ Agent ä»»åŠ¡å¾ªç¯
        
        å°è£…ä»ä»»åŠ¡åˆå§‹åŒ–åˆ°ç»“æœè¿”å›çš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
        - ä»»åŠ¡åˆå§‹åŒ–ï¼ˆenv_task_initï¼‰
        - Agent å¯¹è¯å¾ªç¯ï¼ˆLLM -> Tool -> Envï¼‰
        - è¯„ä¼°ï¼ˆå¦‚æœæ”¯æŒï¼‰
        - ä»»åŠ¡æ¸…ç†ï¼ˆenv_task_endï¼‰
        
        Args:
            task: ä»»åŠ¡å­—å…¸ï¼ŒåŒ…å« id, question, metadata ç­‰å­—æ®µ
            agent_config: Agent é…ç½®å­—å…¸ï¼ŒåŒ…å« model_name, max_turns, max_retries ç­‰
            logger: æ—¥å¿—è®°å½•å™¨
        
        Returns:
            åŒ…å« task_id, question, answer, messages, success ç­‰å­—æ®µçš„ç»“æœå­—å…¸
        """
        task_id = task.get("id", "unknown")
        question = task.get("question", "")
        
        # è·å– Agent é…ç½®å‚æ•°
        model_name = agent_config.get("model_name", "gpt-4.1-2025-04-14")
        max_turns = agent_config.get("max_turns", 3)
        max_retries = agent_config.get("max_retries", 3)

        # è·å–ä»»åŠ¡è¾“å‡ºç›®å½•ï¼ˆå¦‚æœç¯å¢ƒæ”¯æŒï¼‰
        task_output_dir = None
        if hasattr(self, "get_task_output_dir") and callable(self.get_task_output_dir):
            task_output_dir = self.get_task_output_dir(
                agent_config.get("output_dir", "results"),
                task_id,
                model_name
            )

        # æ‰§è¡Œå¯¹è¯ï¼Œè·å–å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
        messages = self._run_conversation(question, model_name, max_turns, max_retries, logger)
        
        # ä»æ¶ˆæ¯ä¸­æå–æœ€ç»ˆç­”æ¡ˆ
        final_answer = self._extract_final_answer(messages)

        # æ„å»ºä»»åŠ¡ç»“æœå­—å…¸
        result = {
            "task_id": task_id,
            "question": question,
            "answer": final_answer,
            "messages": messages,
            "success": True,
            "error": None,
        }

        # å¦‚æœä»»åŠ¡è¾“å‡ºç›®å½•å­˜åœ¨ï¼Œä¿å­˜å¯¹è¯æ—¥å¿—
        if task_output_dir:
            self._save_conversation_log(
                task_output_dir,
                task_id,
                question,
                model_name,
                messages,
                result
            )

        return result

    def _run_conversation(self, 
                         question: str, 
                         model_name: str, 
                         max_turns: int, 
                         max_retries: int, 
                         logger: logging.Logger
    ) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œ Agent å¯¹è¯å¾ªç¯
        
        Args:
            question: ä»»åŠ¡é—®é¢˜
            initial_obs: åˆå§‹è§‚å¯Ÿç»“æœ
            model_name: LLM æ¨¡å‹åç§°
            max_turns: æœ€å¤§å¯¹è¯è½®æ•°
            max_retries: æ¯æ¬¡è°ƒç”¨çš„æœ€å¤§é‡è¯•æ¬¡æ•°
            logger: æ—¥å¿—è®°å½•å™¨
        
        Returns:
            å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
        """
        system_prompt = self.get_system_prompt(question)
        messages: List[Dict[str, Any]] = [
            {"role": "system", "content": system_prompt},
        ]

        # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹ï¼ŒåŒ…å«é—®é¢˜æ–‡æœ¬
        user_content: List[Dict[str, Any]] = [{"type": "text", "text": f"Question: {question}\n"}]
        # å¦‚æœç¯å¢ƒæ”¯æŒæ ¼å¼åŒ–åˆå§‹è§‚å¯Ÿçš„åŠŸèƒ½ï¼Œåˆ™å°†åˆå§‹è§‚å¯Ÿæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
        
        # [æ–°å¢] æ³¨å…¥åˆå§‹è§‚å¯Ÿ (å¦‚æœæœ‰)
        # æ³¨æ„ï¼šéœ€è¦è®¿é—®å­ç±»çš„æˆå‘˜å˜é‡ï¼Œå»ºè®®ä½¿ç”¨ getattr å®‰å…¨è·å–
        initial_obs = getattr(self, "initial_observation", None)
        
        if initial_obs and isinstance(initial_obs, dict):
            # 1. æ·»åŠ æˆªå›¾ (å¦‚æœå­˜åœ¨)
            screenshot_b64 = initial_obs.get("screenshot")
            if screenshot_b64:
                user_content.append({
                    "type": "text", 
                    "text": "Here is the initial screen state of the computer:"
                })
                user_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{screenshot_b64}",
                        "detail": "high"
                    }
                })
            
            # 2. æ·»åŠ  Accessibility Tree (å¦‚æœå­˜åœ¨)
            a11y_tree = initial_obs.get("accessibility_tree")
            if a11y_tree:
                user_content.append({
                    "type": "text",
                    "text": f"Accessibility Tree:\n{a11y_tree}"
                })

        messages.append({"role": "user", "content": user_content})

        client = self._get_openai_client()
        turn_count = 0
        step_idx = 0

        # ä¸»å¯¹è¯å¾ªç¯ï¼šåœ¨æœ€å¤§è½®æ¬¡é™åˆ¶å†…è¿›è¡Œå¤šè½®å¯¹è¯
        while turn_count < max_turns:
            retry = 0
            # é‡è¯•å¾ªç¯ï¼šæ¯æ¬¡ API è°ƒç”¨å¤±è´¥åä¼šé‡è¯•ï¼Œç›´åˆ°è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
            while retry < max_retries:
                try:
                    # è°ƒç”¨ OpenAI API è·å– LLM å“åº”
                    # exit()
                    print(f"Messages: {messages}")
                    response = client.chat.completions.create(  # type: ignore[arg-type]
                        model=model_name,
                        messages=messages,  # type: ignore[arg-type]
                        tools=self.get_tool_schemas(),  # type: ignore[arg-type]
                    )
                    # éªŒè¯ API å“åº”æ˜¯å¦æœ‰æ•ˆ
                    if not hasattr(response, "choices") or not response.choices:
                        raise ValueError("OpenAI API returned empty response")

                    # æå–åŠ©æ‰‹æ¶ˆæ¯å¹¶æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
                    assistant_message = response.choices[0].message
                    print(f"Assistant message: {assistant_message}")
                    messages.append(assistant_message.model_dump())

                    # å¦‚æœ LLM è¿”å›äº†å·¥å…·è°ƒç”¨ï¼Œåˆ™æ‰§è¡Œå·¥å…·
                    if assistant_message.tool_calls:
                        print(f"Messages: {messages[-1]['content']}")
                        if messages[-1]['content'] == "":
                            tc = messages[-1].tool_calls[0].model_dump()['function']
                            messages[-1]['content'] = tc
                        for tool_call in assistant_message.tool_calls[:1]:
                            tool_name = tool_call.function.name
                            tool_args = json.loads(tool_call.function.arguments)
                            
                            print(f"Round {turn_count}: ğŸ”§ Using tool: {tool_name}")
                            print(f"Round {turn_count}:    Arguments: {tool_args}")
                            
                            # 1. æ‰§è¡Œå·¥å…· (ç°åœ¨ execute_tool å¯èƒ½è¿”å›å­—å…¸)
                            tool_output = self.execute_tool(tool_name, tool_args)
                            
                            # 2. è§£ææ ‡å‡†åŒ–è¾“å‡º (æ”¯æŒçº¯æ–‡æœ¬å’Œç»“æ„åŒ–æ•°æ®)
                            # æ ‡å‡†ç»“æ„: {"text": "...", "images": ["base64...", ...]}
                            if isinstance(tool_output, dict) and "images" in tool_output:
                                content_str = tool_output.get("text", "")
                                image_list = tool_output.get("images", [])
                            else:
                                # å…¼å®¹æ—§ä»£ç æˆ–çº¯æ–‡æœ¬è¿”å›
                                content_str = str(tool_output)
                                image_list = []

                            print(f"Round {turn_count}:    Result: {content_str[:100]}... (Images: {len(image_list)})")
                            
                            # 3. æ·»åŠ å¿…é¡»çš„ Tool Message (ç”¨äºé—­åˆå‡½æ•°è°ƒç”¨é“¾)
                            # æ³¨æ„ï¼šOpenAI è¦æ±‚ tool role çš„ content å¿…é¡»æ˜¯ string
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "name": tool_name,
                                "content": content_str 
                            })

                            # 4. [æ–°å¢] æ³¨å…¥ User Message (å¦‚æœæœ‰å›¾ç‰‡)
                            # åˆ©ç”¨ GPT-4 çš„ Vision èƒ½åŠ›ï¼Œå°†å›¾ç‰‡ä½œä¸ºæ–°çš„è§‚å¯Ÿä¼ å…¥
                            if image_list:
                                user_content_blocks = []
                                
                                # å¯é€‰ï¼šæ·»åŠ æ–‡æœ¬å¼•å¯¼
                                user_content_blocks.append({
                                    "type": "text", 
                                    "text": f"Observation from tool '{tool_name}' (Screenshots):"
                                })
                                
                                # æ·»åŠ æ‰€æœ‰å›¾ç‰‡
                                for img_b64 in image_list:
                                    user_content_blocks.append({
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:image/png;base64,{img_b64}",
                                            "detail": "high" # æˆ– "auto"
                                        }
                                    })
                                
                                messages.append({
                                    "role": "user",
                                    "content": user_content_blocks
                                })
                        
                    else:
                        logger.info(f"Turn {turn_count}: final answer produced")
                        # ã€ä¿®æ­£ã€‘æ‹¼å†™é”™è¯¯ messagess -> messages
                        return messages 
                except Exception as exc:
                    # API è°ƒç”¨æˆ–å·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œè¿›è¡Œé‡è¯•
                    retry += 1
                    logger.warning(f"Retry {retry}/{max_retries} due to error: {exc}")
                    # å¦‚æœè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
                    if retry >= max_retries:
                        raise
            turn_count += 1
        logger.warning("Max turns reached without final answer")
        return messages
    
    def _extract_final_answer(self, messages: List[Dict[str, Any]]) -> Optional[str]:
        """
        ä»å¯¹è¯å†å²ä¸­æå–æœ€ç»ˆç­”æ¡ˆï¼ˆé»˜è®¤å®ç°ï¼‰ã€‚
        
        é€»è¾‘ï¼š
        1. å€’åºéå†æ¶ˆæ¯åˆ—è¡¨ã€‚
        2. æ‰¾åˆ°æœ€åä¸€æ¡ç”± 'assistant' å‘å‡ºçš„æ¶ˆæ¯ã€‚
        3. è¿”å›è¯¥æ¶ˆæ¯çš„æ–‡æœ¬å†…å®¹ã€‚
        
        Args:
            messages: å®Œæ•´çš„å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            æå–åˆ°çš„æœ€ç»ˆç­”æ¡ˆå­—ç¬¦ä¸²ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› Noneã€‚
        """
        if not messages:
            return None
            
        # å€’åºæŸ¥æ‰¾ï¼Œè·å–æœ€æ–°çš„å›å¤
        for msg in reversed(messages):
            if msg.get("role") == "assistant":
                content = msg.get("content")
                
                # æƒ…å†µ1: å†…å®¹æ˜¯æ ‡å‡†å­—ç¬¦ä¸²
                if isinstance(content, str) and content.strip():
                    return content
                
                # æƒ…å†µ2: å†…å®¹å¯èƒ½æ˜¯ Noneï¼ˆä¾‹å¦‚ä»…æœ‰ tool_callsï¼‰
                # åœ¨ run_task é€»è¾‘ä¸­ï¼Œé€šå¸¸æ˜¯ tool_calls ä¸ºç©ºæ—¶æ‰è§†ä¸º final answerï¼Œ
                # æ­¤æ—¶ content åº”è¯¥æœ‰å€¼ã€‚ä½†ä¸ºäº†å¥å£®æ€§ï¼Œè¿™é‡Œåšä¸ªæ£€æŸ¥ã€‚
                if content is not None:
                    return str(content)
                    
        return None
    
    
    # =========================================================================
    # 2. èµ„æºç®¡ç†æ¥å£ (ä¸»è¿›ç¨‹è°ƒç”¨)
    # =========================================================================

    @classmethod
    def setup_global_resources(cls, config: Any) -> Optional['ResourceManager']:
        """
        ç±»æ–¹æ³•ï¼šåˆå§‹åŒ–å…¨å±€èµ„æº (å¦‚ VM æ± )ã€‚
        é»˜è®¤è¿”å›ç©ºç®¡ç†å™¨ï¼Œéœ€è¦é‡èµ„äº§çš„ç¯å¢ƒ(å¦‚ OSWorld)éœ€é‡å†™æ­¤æ–¹æ³•ã€‚
        """
        from utils.resource_manager import NoResourceManager, ResourceManager as BaseResourceManager

        manager: BaseResourceManager = NoResourceManager()
        return manager

    @property
    def resource_manager(self) -> 'ResourceManager':
        return self._resource_manager

    # =========================================================================
    # 3. å·¥å…·ç®¡ç†è®¾æ–½ (å·²å®ç°ï¼Œé€šå¸¸æ— éœ€ä¿®æ”¹)
    # =========================================================================

    def register_tool(self, tool: Tool):
        """æ³¨å†Œå·¥å…·å¹¶è‡ªåŠ¨æ›´æ–° Schema"""
        self.tools[tool.name] = tool
        self._update_tool_metadata()

    def list_tools(self) -> List[str]:
        """åˆ—å‡ºå½“å‰ç¯å¢ƒå¯ç”¨å·¥å…·åç§°"""
        return sorted(self.tools.keys())

    def get_tool(self, name: str) -> Optional[Tool]:
        return self.tools.get(name)

    def execute_tool(self, tool_name: str, params: Union[str, dict], **kwargs) -> Union[str, Dict[str, Any]]:
        """æ‰§è¡Œå·¥å…·çš„å®‰å…¨åŒ…è£…å™¨"""
        tool = self.get_tool(tool_name)
        if not tool:
            return f"Error: Tool '{tool_name}' not found"
        try:
            return tool.call(params, **kwargs)
        except Exception as e:
            return f"Error executing '{tool_name}': {str(e)}"

    def get_tool_schemas(self) -> List[Dict[str, Any]]:
        """è·å–ç”¨äº LLM API çš„å·¥å…·å®šä¹‰"""
        return self.tool_schemas

    def get_tool_descriptions(self) -> str:
        """è·å–ç”¨äº Prompt çš„å·¥å…·æè¿°æ–‡æœ¬"""
        if not self.tool_descriptions:
            return "- No tools registered. è¯·å…ˆé€šè¿‡ register_tool() æ³¨å†Œå·¥å…·ã€‚"
        return self.tool_descriptions

    def _update_tool_metadata(self):
        """(å†…éƒ¨) ç”Ÿæˆå·¥å…· Schema å’Œæè¿°"""
        self.tool_schemas = [self._tool_to_schema(t) for t in self.tools.values()]
        self.tool_descriptions = "\n".join([f"- {t.name}: {t.description}" for t in self.tools.values()])

    def _tool_to_schema(self, tool: Tool) -> Dict[str, Any]:
        """(å†…éƒ¨) å°† Tool è½¬æ¢ä¸º OpenAI Schema æ ¼å¼"""
        required_params = [param['name'] for param in tool.parameters if param.get('required', False)]
        properties = {}
        
        for param in tool.parameters:
            properties[param['name']] = {
                "type": param['type'],
                "description": param['description']
            }
            if param['type'] == 'array':
                properties[param['name']]['items'] = {
                    "type": param['array_type']
                }
        
        return {
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "parameters": {
                    "type": "object",
                    "properties": properties,
                    "required": required_params
                }
            }
        }

    # =========================================================================
    # 4. ç”Ÿå‘½å‘¨æœŸé’©å­ (å¯é€‰è¦†ç›–)
    # =========================================================================

    def get_action_space(self) -> Optional[str]:
        """
        è·å–å½“å‰ç¯å¢ƒçš„åŠ¨ä½œç©ºé—´æè¿°ï¼ˆé»˜è®¤ä»é…ç½®ä¸­æ¨æ–­ï¼Œå¯ç”±å­ç±»è¦†ç›–ï¼‰
        """
        mode_config = self.config.get(self.mode)
        if isinstance(mode_config, dict) and "action_space" in mode_config:
            return mode_config.get("action_space")
        return self.config.get("action_space")

    def get_system_prompt(
        self,
        task_question: Optional[str] = None,
        extra_context: Optional[str] = None,
        action_space: Optional[str] = None,
    ) -> str:
        """
        åŸºäº prompts/system_prompts.py ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼Œå¹¶è‡ªåŠ¨æ³¨å…¥å·¥å…·æè¿°ã€‚
        """
        resolved_action_space = action_space or self.get_action_space()
        if resolved_action_space is None:
            prompt_template = load_system_prompt(environment_mode=self.mode)
        else:
            prompt_template = load_system_prompt(
                environment_mode=self.mode,
                action_space=resolved_action_space
            )

        prompt_with_tools = prompt_template.replace(
            "{tool_descriptions}",
            self.get_tool_descriptions()
        )

        prompt_with_placeholders = self._replace_prompt_placeholders(prompt_with_tools)

        suffix_parts: List[str] = []
        if task_question:
            suffix_parts.append(f"You are asked to complete the following task: {task_question}")
        if extra_context:
            suffix_parts.append(extra_context)

        if suffix_parts:
            prompt_with_placeholders = "\n".join([prompt_with_placeholders, *suffix_parts])

        return prompt_with_placeholders

    def _replace_prompt_placeholders(self, prompt: str) -> str:
        """å­ç±»å¯è¦†ç›–æ­¤æ–¹æ³•ä»¥æ›¿æ¢è‡ªå®šä¹‰å ä½ç¬¦"""
        return prompt

    def env_start(self) -> None:
        """Benchmark å¼€å§‹æ—¶è°ƒç”¨ (å¯é€‰åˆå§‹åŒ–)"""
        pass

    def env_close(self) -> None:
        """Benchmark ç»“æŸæ—¶è°ƒç”¨ (å¯é€‰æ¸…ç†)"""
        pass

    # =========================================================================
    # 5. é…ç½®ç®¡ç†é’©å­ (å¯é€‰è¦†ç›–ï¼Œä¾›å­ç±»è°ƒç”¨ super())
    # =========================================================================

    def _initialize_config(self) -> None:
        """åˆå§‹åŒ–é…ç½® (å¯é€‰è¦†ç›–)"""
        pass

    def _validate_config(self) -> None:
        """éªŒè¯é…ç½® (å¯é€‰è¦†ç›–)"""
        pass

    def _get_openai_client(self) -> openai.OpenAI:
        """
        è·å– OpenAI å®¢æˆ·ç«¯å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
        å¦‚æœå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®ä¸­è¯»å–é…ç½®å¹¶åˆ›å»ºæ–°å®ä¾‹
        """
        if not hasattr(self, '_openai_client') or self._openai_client is None:
            import openai
            api_key = self.config.get("openai_api_key") or os.environ.get("OPENAI_API_KEY", "")
            base_url = self.config.get("openai_api_url") or os.environ.get("OPENAI_API_URL") or os.environ.get("OPENAI_API_BASE")
            
            openai.api_key = api_key
            # å¦‚æœé…ç½®äº†è‡ªå®šä¹‰ base_urlï¼Œåˆ™ä½¿ç”¨è‡ªå®šä¹‰ URLï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤ URL
            if base_url:
                openai.base_url = base_url
                self._openai_client = openai.OpenAI(api_key=api_key, base_url=base_url)
            else:
                self._openai_client = openai.OpenAI(api_key=api_key)
        return self._openai_client
# src/run_parallel_rollout.py
# -*- coding: utf-8 -*-
"""
å¹¶è¡Œ Rollout æ¡†æž¶ - MCP çº¯å‡€ç‰ˆ
å·²ç§»é™¤æ‰€æœ‰æœ¬åœ°é‡èµ„æºç®¡ç†å™¨ï¼ˆResource Managerï¼‰çš„é—ç•™é€»è¾‘ã€‚
å®Œå…¨ä¾èµ– MCP åè®®ä¸Žè¿œç¨‹çŽ¯å¢ƒï¼ˆGateway/Serverï¼‰è¿›è¡Œèµ„æºäº¤äº’ã€‚
"""
import time
import os
import sys
import json
import logging
import signal
from datetime import datetime
from multiprocessing import Manager, Process
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Optional dotenv support
try:
    from dotenv import load_dotenv
    HAS_DOTENV = True
except ImportError:
    HAS_DOTENV = False

from benchmark import Benchmark
from envs.factory import get_environment_class

# å¯¼å…¥è¶…æ—¶å¼‚å¸¸
from utils.task_timeout import TaskTimeoutError

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é¢„åŠ è½½çŽ¯å¢ƒå˜é‡
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
ENV_PATH = os.path.join(PROJECT_ROOT, ".env")
if HAS_DOTENV and os.path.exists(ENV_PATH):
    load_dotenv(ENV_PATH)
    logger.info(f"Loaded environment variables from {ENV_PATH}")


def _register_main_signal_handlers():
    """
    æ³¨å†Œä¸»è¿›ç¨‹ä¿¡å·å¤„ç†
    ä»…è´Ÿè´£æ—¥å¿—è®°å½•å’Œä¼˜é›…é€€å‡ºï¼Œä¸å†è´Ÿè´£æ¸…ç†å…¨å±€èµ„æºå¯¹è±¡ï¼ˆå·²ç§»é™¤ï¼‰ã€‚
    """
    def handle_signal(signum, frame):
        logger.info(f"Main process received signal {signum}. Exiting...")
        # åœ¨è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–å¿…è¦çš„è½»é‡çº§æ¸…ç†
        sys.exit(0)

    signal.signal(signal.SIGINT, handle_signal)
    signal.signal(signal.SIGTERM, handle_signal)


@dataclass
class ParallelRolloutConfig:
    """å¹¶è¡Œ Rollout é…ç½®"""
    num_rollouts: int = 5          # å¹¶è¡Œåº¦ï¼ˆWorker æ•°é‡ï¼‰
    env_mode: str = "http_mcp"     # é»˜è®¤ä¸º MCP æ¨¡å¼
    env_kwargs: Dict[str, Any] = field(default_factory=dict)
    agent_config_dict: Dict[str, Any] = field(default_factory=dict)
    output_dir: str = "results"


def run_parallel_rollout(
    config: ParallelRolloutConfig,
    benchmark: Benchmark
):
    """
    è¿è¡Œå¹¶è¡Œ Rollout æ¡†æž¶ (MCP çº¯å‡€ç‰ˆ)
    """
    # [æ–°å¢ž] 1. å¼€å§‹è®¡æ—¶
    benchmark_start_time = time.time()

    logger.info("=" * 60)
    logger.info("Starting Parallel Rollout Framework (MCP Native)")
    logger.info(f"Rollouts: {config.num_rollouts} | Env: {config.env_mode} | Items: {len(benchmark.get_items())}")
    logger.info("=" * 60)
    
    # 1. èŽ·å–çŽ¯å¢ƒç±»
    EnvClass = get_environment_class(config.env_mode)
    logger.info(f"Using environment class: {EnvClass.__name__}")
    
    # [å˜æ›´] ä¸å†è°ƒç”¨ setup_global_resources
    # MCP æ¨¡å¼ä¸‹ï¼Œèµ„æºç”± Gateway/Server ç®¡ç†ï¼ŒClient ç«¯æ— éœ€åˆå§‹åŒ–å…¨å±€æ± ã€‚

    _register_main_signal_handlers()
    
    # 2. åˆ›å»ºè·¨è¿›ç¨‹å…±äº«çš„æ•°æ®ç»“æž„
    with Manager() as manager:
        task_queue = manager.Queue()
        shared_results = manager.list()
        worker_instance_map = manager.dict()
        worker_instance_events = manager.list()
        
        # å°†æ‰€æœ‰åŸºå‡†æµ‹è¯•é¡¹æ”¾å…¥ä»»åŠ¡é˜Ÿåˆ—
        for item in benchmark.get_items():
            task_dict = {
                "id": item.id,
                "question": item.question,
                "answer": item.answer,
                "metadata": item.metadata or {}
            }
            task_queue.put(task_dict)

        # æ·»åŠ å“¨å…µå€¼ (Poison Pill)
        for _ in range(config.num_rollouts):
            task_queue.put(None)
        
        # 3. å¯åŠ¨ Worker è¿›ç¨‹
        env_class_name = EnvClass.__module__ + "." + EnvClass.__name__
        processes = []
        for i in range(config.num_rollouts):
            worker_id = f"worker-{i+1}"
            
            proc = Process(
                target=run_rollout_worker,
                args=(
                    worker_id,
                    task_queue,
                    env_class_name,
                    config.env_kwargs,
                    config.agent_config_dict,
                    config.output_dir,
                    config.num_rollouts,
                    shared_results,
                    worker_instance_map,
                    worker_instance_events,
                )
            )
            proc.start()
            processes.append(proc)
            logger.info(f"Started worker process: {worker_id}")
        
        # ç­‰å¾…æ‰€æœ‰ Worker è¿›ç¨‹æ‰§è¡Œå®Œæ¯•
        try:
            for proc in processes:
                proc.join()
        except KeyboardInterrupt:
            logger.info("Main process interrupted. Terminating workers...")
            for proc in processes:
                if proc.is_alive():
                    proc.terminate()
        
        # [æ–°å¢ž] 2. ç»“æŸè®¡æ—¶å¹¶è®¡ç®—æ—¶é•¿
        benchmark_end_time = time.time()
        total_duration_seconds = benchmark_end_time - benchmark_start_time
        
        # [æ–°å¢ž] 3. æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º (HH:MM:SS)
        m, s = divmod(total_duration_seconds, 60)
        h, m = divmod(m, 60)
        duration_str = f"{int(h):02d}:{int(m):02d}:{int(s):02d}"

        # 4. æ”¶é›†ç»“æžœå¹¶è¯„æµ‹
        results = list(shared_results)
        
        logger.info(f"All workers completed. Total results: {len(results)}")
        
        predictions = {
            result["task_id"]: result.get("answer", "")
            for result in results
            if result.get("success", False)
        }

        # æ”¯æŒå¤šä¸ªè¯„åˆ†æŒ‡æ ‡ï¼šå¯ä»¥æ˜¯å•ä¸ªæŒ‡æ ‡å­—ç¬¦ä¸²æˆ–æŒ‡æ ‡åˆ—è¡¨
        evaluation_config = config.agent_config_dict.get("evaluation_metric", "exact_match")
        if isinstance(evaluation_config, str):
            evaluation_metrics = [evaluation_config]
        else:
            evaluation_metrics = list(evaluation_config)

        # å¯¹æ¯ä¸ªæŒ‡æ ‡åˆ†åˆ«è¿›è¡Œè¯„æµ‹
        all_benchmark_results = {}  # {metric_name: [EvaluationResult]}
        metrics_statistics = {}     # {metric_name: {total, successful, failed, avg_score, ...}}

        logger.info(f"Evaluating with {len(evaluation_metrics)} metric(s): {', '.join(evaluation_metrics)}")

        for metric in evaluation_metrics:
            logger.info(f"  Computing metric: {metric}...")
            metric_results = benchmark.evaluate(
                predictions=predictions,
                metric=metric
            )
            all_benchmark_results[metric] = metric_results

            # è®¡ç®—è¯¥æŒ‡æ ‡çš„ç»Ÿè®¡ä¿¡æ¯
            total_items = len(metric_results)
            successful_items = len([r for r in metric_results if r.score > 0])
            failed_items = total_items - successful_items
            avg_score = sum(r.score for r in metric_results) / total_items if total_items > 0 else 0.0

            metrics_statistics[metric] = {
                "total_items": total_items,
                "successful_items": successful_items,
                "failed_items": failed_items,
                "average_score": avg_score,
                "success_rate": successful_items / total_items if total_items > 0 else 0.0
            }

        # è¾“å‡ºæ‰€æœ‰æŒ‡æ ‡çš„è¯„æµ‹ç»“æžœ
        logger.info("=" * 60)
        logger.info("Benchmark Evaluation Results")
        logger.info(f"  Metrics: {', '.join(evaluation_metrics)}")
        logger.info(f"  Total Tasks: {len(results)}")
        logger.info(f"  Successful Predictions: {len(predictions)}")
        logger.info("")
        for metric, stats in metrics_statistics.items():
            logger.info(f"  [{metric}]")
            logger.info(f"    Total Items: {stats['total_items']}")
            logger.info(f"    Successful: {stats['successful_items']}")
            logger.info(f"    Failed: {stats['failed_items']}")
            logger.info(f"    Average Score: {stats['average_score']:.4f}")
            logger.info(f"    Success Rate: {stats['success_rate']:.2%}")
        logger.info("=" * 60)

        # [æ–°å¢ž] 4. åœ¨æ—¥å¿—ä¸­è¾“å‡ºæ€»è€—æ—¶ï¼ˆæ›´æ˜¾çœ¼çš„æ ¼å¼ï¼‰
        logger.info("")
        logger.info("=" * 60)
        logger.info("â±ï¸  TOTAL EXECUTION TIME")
        logger.info(f"  Duration: {duration_str} ({total_duration_seconds:.2f}s)")
        logger.info(f"  Start: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(benchmark_start_time))}")
        logger.info(f"  End: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(benchmark_end_time))}")
        logger.info("=" * 60)
        
        # ä¿å­˜ç»“æžœ
        os.makedirs(config.output_dir, exist_ok=True)

        # ä¿å­˜ Trajectory
        trajectory_file = os.path.join(config.output_dir, "trajectory.jsonl")
        logger.info(f"Saving execution trajectories to {trajectory_file}...")
        with open(trajectory_file, "w", encoding="utf-8") as f:
            for res in results:
                json.dump(res, f, ensure_ascii=False)
                f.write("\n")

        # [æ–°å¢ž] ä¿å­˜è¯¦ç»†çš„è¯„åˆ†ç»“æžœï¼ˆåŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„åˆ†æ•°ï¼‰
        scores_file = os.path.join(config.output_dir, "evaluation_scores.json")
        logger.info(f"Saving evaluation scores to {scores_file}...")

        # æž„å»ºè¯¦ç»†çš„è¯„åˆ†æ•°æ®ï¼šæ¯ä¸ªä»»åŠ¡åŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„åˆ†æ•°
        # é¦–å…ˆèŽ·å–æ‰€æœ‰ä»»åŠ¡ID
        all_task_ids = set()
        for metric_results in all_benchmark_results.values():
            for eval_result in metric_results:
                # ä¿®å¤ 1: EvaluationResult ä½¿ç”¨ item_id è€Œä¸æ˜¯ task_id
                all_task_ids.add(eval_result.item_id)

        # ä¸ºæ¯ä¸ªä»»åŠ¡æž„å»ºè¯„åˆ†è®°å½•
        detailed_scores = []
        for task_id in sorted(all_task_ids):
            # èŽ·å–è¯¥ä»»åŠ¡åœ¨ç¬¬ä¸€ä¸ªæŒ‡æ ‡ä¸­çš„åŸºæœ¬ä¿¡æ¯ï¼ˆé¢„æµ‹ç­”æ¡ˆå’ŒçœŸå®žç­”æ¡ˆï¼‰
            first_metric = evaluation_metrics[0]
            # ä¿®å¤ 2: è¿‡æ»¤æ—¶ä½¿ç”¨ r.item_id
            first_result = next((r for r in all_benchmark_results[first_metric] if r.item_id == task_id), None)

            if first_result is None:
                continue

            score_record = {
                "task_id": task_id,
                # ä¿®å¤ 3: å±žæ€§åä¸º prediction å’Œ ground_truth
                "predicted_answer": first_result.prediction, 
                "ground_truth": first_result.ground_truth,
                "scores": {},  # å­˜å‚¨æ‰€æœ‰æŒ‡æ ‡çš„åˆ†æ•°
                "is_correct": {}  # å­˜å‚¨æ¯ä¸ªæŒ‡æ ‡æ˜¯å¦æ­£ç¡®
            }

            # æ”¶é›†è¯¥ä»»åŠ¡åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸‹çš„åˆ†æ•°
            for metric in evaluation_metrics:
                # ä¿®å¤ 4: è¿‡æ»¤æ—¶ä½¿ç”¨ r.item_id
                metric_result = next((r for r in all_benchmark_results[metric] if r.item_id == task_id), None)
                if metric_result:
                    score_record["scores"][metric] = metric_result.score
                    score_record["is_correct"][metric] = metric_result.score > 0

            detailed_scores.append(score_record)

        # ä¿å­˜è¯¦ç»†è¯„åˆ†
        with open(scores_file, "w", encoding="utf-8") as f:
            json.dump(detailed_scores, f, indent=2, ensure_ascii=False)

        # [æ–°å¢ž] ä¿å­˜æ±‡æ€»ç»Ÿè®¡ç»“æžœï¼ˆåŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„ç»Ÿè®¡ä¿¡æ¯ï¼‰
        summary_file = os.path.join(config.output_dir, "evaluation_summary.json")
        logger.info(f"Saving evaluation summary to {summary_file}...")

        summary_data = {
            "timestamp": datetime.now().isoformat(),
            "evaluation_metrics": evaluation_metrics,  # æ”¹ä¸ºåˆ—è¡¨
            "metrics_statistics": metrics_statistics,  # åŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„ç»Ÿè®¡ä¿¡æ¯
            "execution_time": {
                "total_seconds": total_duration_seconds,
                "formatted": duration_str,
                "start_time": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(benchmark_start_time)),
                "end_time": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(benchmark_end_time))
            },
            "configuration": {
                "num_rollouts": config.num_rollouts,
                "env_mode": config.env_mode,
                #"model_name": agent_config_dict.get("model_name", "N/A"),
                #"max_turns": agent_config_dict.get("max_turns", "N/A")
            },
            "tasks_summary": {
                "total_tasks": len(results),
                "successful_predictions": len(predictions),
                "failed_predictions": len(results) - len(predictions)
            }
        }

        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary_data, f, indent=2, ensure_ascii=False)

        # ä¿å­˜ Worker çŠ¶æ€æ˜ å°„ï¼ˆè°ƒè¯•ç”¨ï¼‰
        mapping_file = os.path.join(config.output_dir, "worker_instance_map.json")
        with open(mapping_file, "w", encoding="utf-8") as f:
            worker_instance_snapshot = {k: dict(v) if isinstance(v, dict) else v for k, v in worker_instance_map.items()}
            json.dump(worker_instance_snapshot, f, indent=2, ensure_ascii=False)

        logger.info("")
        logger.info("=" * 60)
        logger.info("ðŸ“Š Results saved:")
        logger.info(f"  - Trajectories: {trajectory_file}")
        logger.info(f"  - Detailed scores: {scores_file}")
        logger.info(f"  - Summary: {summary_file}")
        logger.info(f"  - Worker mapping: {mapping_file}")
        logger.info("=" * 60)

        return {
            "worker_results": results,
            "benchmark_evaluation": all_benchmark_results,  # çŽ°åœ¨åŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„ç»“æžœ
            "metrics_statistics": metrics_statistics,       # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            "total_duration": total_duration_seconds
        }


def get_active_resource_configs(environment, task_item):
    """
    æ ¹æ®çŽ¯å¢ƒå®žé™…å¯ç”¨çš„èµ„æºç±»åž‹ç­›é€‰ä»»åŠ¡ä¸­çš„èµ„æºé…ç½®
    """
    raw_configs = task_item.get("metadata", {}).get("resource_configs", {})
    active_types = getattr(environment, "active_resources", [])
    
    active_configs = {}
    for res_type in active_types:
        if res_type in raw_configs:
            active_configs[res_type] = raw_configs[res_type]
            
    return active_configs


def run_rollout_worker(
    worker_id: str,
    task_queue,
    env_class_name: str,
    env_kwargs: Dict[str, Any],
    agent_config_dict: Dict[str, Any],
    output_dir: str,
    parallel_degree: int, # [å˜æ›´] ç§»é™¤äº† global_resources å‚æ•°
    shared_results,
    worker_instance_map=None,
    worker_instance_events=None,
):
    """
    Rollout Worker è¿›ç¨‹å‡½æ•° (MCP çº¯å‡€ç‰ˆ)
    """
    logger = logging.getLogger(f"worker.{worker_id}")
    environment = None

    def worker_signal_handler(signum, frame):
        logger.info(f"Worker {worker_id} received signal {signum}. Cleaning up...")
        try:
            if environment:
                # å°è¯•è°ƒç”¨çŽ¯å¢ƒçš„ cleanup æˆ– env_close
                cleanup_fn = getattr(environment, "cleanup", None)
                if callable(cleanup_fn):
                    cleanup_fn(worker_id)
                else:
                    env_close = getattr(environment, "env_close", None)
                    if callable(env_close):
                        env_close()
        except Exception as e:
            logger.error(f"Error during signal cleanup: {e}")
        sys.exit(0)

    signal.signal(signal.SIGINT, worker_signal_handler)
    signal.signal(signal.SIGTERM, worker_signal_handler)

    try:
        # 1. åŠ¨æ€å¯¼å…¥çŽ¯å¢ƒç±»
        module_name, class_name = env_class_name.rsplit(".", 1)
        env_module = __import__(module_name, fromlist=[class_name])
        EnvClass = getattr(env_module, class_name)
        
        # 2. æ³¨å…¥ worker_id
        local_env_kwargs = env_kwargs.copy()
        local_env_kwargs["worker_id"] = worker_id

        # 3. åˆå§‹åŒ–çŽ¯å¢ƒå®žä¾‹
        # [å˜æ›´] å½»åº•ç§»é™¤ resource_manager å‚æ•°
        environment = EnvClass(
            parallel_degree=parallel_degree,
            **local_env_kwargs, 
        )
        
        # 4. å¯åŠ¨çŽ¯å¢ƒ (å»ºç«‹ MCP è¿žæŽ¥ç­‰)
        env_start = getattr(environment, "env_start", None)
        if callable(env_start):
            try:
                environment.env_start()
            except Exception as exc:
                logger.warning(f"Worker {worker_id} env_start() failed: {exc}")

        # è°ƒç”¨å¯é€‰çš„ init æ–¹æ³•
        init_fn = getattr(environment, "init", None)
        if callable(init_fn):
            init_fn()

        logger.info(f"Worker {worker_id} started")

        # 5. æ£€æŸ¥çŽ¯å¢ƒåŠŸèƒ½ç‰¹æ€§
        task_config_fn = getattr(environment, "initialize_with_task_config", None)
        env_supports_task_config = callable(task_config_fn)
        
        allocate_fn = getattr(environment, "allocate_resource", None)
        release_fn = getattr(environment, "release_resource", None)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¯ä»»åŠ¡èµ„æºåˆ†é… (MCP æ¨¡å¼ä¸‹çš„èµ„æºéš”ç¦»)
        env_has_heavy_resource = bool(getattr(environment, "has_heavy_resource", False) and callable(allocate_fn))

        # 6. å‡†å¤‡ Agent é…ç½®
        agent_config = dict(agent_config_dict)
        agent_config["output_dir"] = output_dir

        # 7. ä¸»ä»»åŠ¡å¾ªçŽ¯
        while True:
            try:
                task = task_queue.get()
                if task is None: # å“¨å…µå€¼
                    logger.info(f"Worker {worker_id} received sentinel. Stopping loop.")
                    break
            except Exception as e:
                logger.error(f"Worker {worker_id} error getting task: {e}")
                break

            task_id = task.get("id", "unknown")
            resource_allocated = False
            current_resource_id = None
            task_start_time = time.time()
            logger.info(f"â–¶ï¸ Worker {worker_id} START Task {task_id}")

            try:
                # è¡¥å…… metadata
                if "metadata" not in task or not isinstance(task.get("metadata"), dict):
                    task["metadata"] = task.get("metadata") or {}
                
                metadata = task.get("metadata", {})
                for key in ("config", "evaluator"):
                    if key not in task and key in metadata:
                        task[key] = metadata[key]

                # çŽ¯å¢ƒç‰¹å®šé…ç½®
                if env_supports_task_config:
                    task_env_config = (
                        task.get("env_config")
                        or task.get("metadata", {}).get("env_config")
                    )
                    if task_env_config:
                        task_config_fn(task_env_config)

                # [èµ„æºåˆ†é…]
                # åœ¨ MCP æ¨¡å¼ä¸‹ï¼Œè¿™é‡Œå®žé™…ä¸Šæ˜¯è°ƒç”¨ allocate_fn (å³ env.allocate_resource)
                # è¯¥æ–¹æ³•ä¼šå‘ Gateway/Server å‘é€è¯·æ±‚ï¼Œç”³è¯·å¦‚ VM/RAG ç­‰èµ„æºã€‚
                if env_has_heavy_resource:
                    logger.info(f"[worker {worker_id}] requesting resource via MCP...")
                    
                    # èŽ·å–éœ€è¦æ¿€æ´»çš„èµ„æºé…ç½®
                    active_resource_configs = get_active_resource_configs(environment, task)
                    
                    # è°ƒç”¨çŽ¯å¢ƒçš„åˆ†é…æ–¹æ³• (ä¸å†ä¾èµ–æœ¬åœ° manager)
                    if not allocate_fn(worker_id, active_resource_configs):
                        raise RuntimeError("Failed to allocate resource via MCP")
                    
                    resource_allocated = True
                    
                    get_allocated_fn = getattr(environment, "get_allocated_resource_id", None)
                    current_resource_id = get_allocated_fn() if callable(get_allocated_fn) else None
                    logger.info(f"[worker {worker_id}] acquired resource context: {current_resource_id}")
                    
                    # è®°å½•åˆ†é…çŠ¶æ€ç”¨äºŽè°ƒè¯•
                    if worker_instance_map is not None and current_resource_id:
                        worker_instance_map[worker_id] = {
                            "instance_id": current_resource_id,
                            "task_id": task_id,
                            "assigned_time": datetime.now().isoformat(),
                        }

                # 8. æ‰§è¡Œä»»åŠ¡ (Run Task)
                result = environment.run_task(task, agent_config, logger)

                if shared_results is not None:
                    shared_results.append(result)

                duration = time.time() - task_start_time
                status_icon = "âœ…" if result.get("success") else "âŒ"
                logger.info(f"{status_icon} Worker {worker_id} FINISH Task {task_id} in {duration:.1f}s")

            except TaskTimeoutError as e:
                logger.error(f"â° Task {task_id} timeout: {e}")
                if shared_results is not None:
                    shared_results.append({
                        "task_id": task_id,
                        "success": False,
                        "error": f"Timeout: {e}",
                        "messages": []
                    })
            except Exception as e:
                logger.error(f"Task {task_id} failed: {e}", exc_info=True)
                if shared_results is not None:
                    shared_results.append({
                        "task_id": task_id,
                        "success": False,
                        "error": str(e),
                        "messages": []
                    })
            finally:
                # [èµ„æºé‡Šæ”¾]
                # ä»»åŠ¡ç»“æŸï¼ˆæ— è®ºæˆåŠŸå¤±è´¥ï¼‰ï¼Œé‡Šæ”¾è¿œç«¯èµ„æº
                if env_has_heavy_resource and resource_allocated and callable(release_fn):
                    logger.info(f"[worker {worker_id}] releasing resource via MCP...")
                    release_fn(worker_id, reset=True)
                    
                    if worker_instance_map is not None:
                        worker_instance_map.pop(worker_id, None)

    finally:
        # Worker é€€å‡ºæ¸…ç†
        if worker_instance_map is not None:
            worker_instance_map.pop(worker_id, None)
        
        # å…³é—­çŽ¯å¢ƒè¿žæŽ¥
        env_close = getattr(environment, "env_close", None)
        if callable(env_close):
            env_close()
            
        logger.info(f"Worker {worker_id} stopped")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Run parallel rollout (MCP Native)")
    parser.add_argument("--data_path", type=str, required=True, help="Path to benchmark data file")
    parser.add_argument("--num_rollouts", type=int, default=5, help="Number of parallel workers")
    parser.add_argument("--env_mode", type=str, default="http_mcp", help="Environment mode")
    parser.add_argument("--output_dir", type=str, default="results", help="Output directory")
    
    # MCP ç›¸å…³é…ç½®
    parser.add_argument("--mcp_server_url", type=str, default="http://localhost:8080", help="MCP Server URL")
    parser.add_argument("--resource_api_url", type=str, default="http://localhost:8000", help="Resource API URL")
    parser.add_argument("--gateway_config_path", type=str, default="gateway_config.json", help="Path to gateway config file")
    
    # é¢å¤–é…ç½® (Agent)
    parser.add_argument("--model_name", type=str, default="gpt-4.1-2025-04-14", help="Agent model name")
    parser.add_argument("--max_turns", type=int, default=15, help="Max turns per task")
    parser.add_argument("--prompt_type", type=str, default="generic",
                        choices=["generic", "no_tool", "sparse", "hybrid"],
                        help="Prompt type for RAG environment: generic, no_tool, sparse, or hybrid")
    parser.add_argument(
        "--evaluation_metric",
        type=str,
        nargs='+',
        default=["exact_match"],
        help="Evaluation metric(s) to use. Can specify multiple: --evaluation_metric exact_match f1_score"
    )

    args = parser.parse_args()
    
    benchmark = Benchmark(data_path=args.data_path)
    
    # çŽ¯å¢ƒå‚æ•°ä¼ é€’ç»™ HttpMCPEnv
    env_kwargs = {
        "observation_type": "screenshot_a11y_tree",
        "mcp_server_url": args.mcp_server_url,
        "resource_api_url": args.resource_api_url,
        "gateway_config_path": args.gateway_config_path,
        "prompt_type": args.prompt_type,
    }
    
    config = ParallelRolloutConfig(
        num_rollouts=args.num_rollouts,
        env_mode=args.env_mode,
        output_dir=args.output_dir,
        env_kwargs=env_kwargs,
        agent_config_dict={
            "model_name": args.model_name,
            "evaluation_metric": args.evaluation_metric if len(args.evaluation_metric) > 1 else args.evaluation_metric[0],
            "max_turns": args.max_turns,
            "max_retries": 2
        }
    )
    
    run_parallel_rollout(config, benchmark)
    logger.info("Parallel rollout completed successfully")
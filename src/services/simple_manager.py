# src/services/simple_manager.py
import logging
import time
import threading
from typing import Dict, Any, Optional, List
from utils.instance_tracker import get_instance_tracker
from utils.resource_pools.base import ResourceStatus
from utils.resource_pools.factory import ResourcePoolFactory

logger = logging.getLogger(__name__)

class GenericResourceManager:
    def __init__(self, full_config: Dict[str, Any]):
        self.full_config = full_config
        self.pools: Dict[str, Any] = {} 
        self.tracker = get_instance_tracker()
        
        # [æ ¸å¿ƒç»„ä»¶] ä½¿ç”¨ Condition å®ç°å…¨å±€é”å’Œé€šçŸ¥æœºåˆ¶
        self.state_cond = threading.Condition()

    def initialize(self) -> bool:
        """æ ¹æ®é…ç½®åŠ¨æ€åˆå§‹åŒ–æ‰€æœ‰å¼€å¯çš„èµ„æºæ± """
        logger.info("Initializing All Resource Pools...")
        all_success = True
        
        resources_conf = self.full_config.get("resources", {})
        
        for res_type, res_conf in resources_conf.items():
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨
            if not res_conf.get("enabled", False):
                logger.info(f"Skipping disabled resource: {res_type}")
                continue

            logger.info(f"--> Init Pool: {res_type}")
            try:
                # 1. ä½¿ç”¨å·¥å‚åˆ›å»ºå®ä¾‹ (æ­¤æ—¶ config é‡Œå·²ç»æœ‰äº† action_space)
                pool_impl = ResourcePoolFactory.create_pool(
                    class_path=res_conf["implementation_class"],
                    config=res_conf["config"]
                )
                
                # 2. è°ƒç”¨åˆå§‹åŒ–æ–¹æ³• (max_workers å¯é€‰å†™å…¥ configï¼Œè¿™é‡Œæš‚å®šé»˜è®¤å€¼)
                # å‡è®¾æ‰€æœ‰ PoolImpl éƒ½ç»§æ‰¿è‡ª AbstractPoolManager å¹¶æœ‰ initialize_pool
                success = pool_impl.initialize_pool(max_workers=5)
                
                if success:
                    self.pools[res_type] = pool_impl
                    logger.info(f"âœ… Pool '{res_type}' initialized. Size: {pool_impl.num_items}")
                else:
                    logger.warning(f"âš ï¸ Pool '{res_type}' failed to initialize fully.")
                    all_success = False
                    
            except Exception as e:
                logger.error(f"âŒ Failed to init pool '{res_type}': {e}", exc_info=True)
                all_success = False

        return all_success

    def allocate_atomic(self, worker_id: str, resource_types: List[str], timeout: float = 600.0) -> Dict[str, Any]:
        """
        [å¤åˆæ–¹æ¡ˆå®ç°]
        1. Ordering: å¯¹è¯·æ±‚èµ„æºæ’åºï¼Œé˜²æ­¢æ­»é”ã€‚
        2. Global Lock: ä½¿ç”¨ Condition é”ä½æ•´ä¸ªæ£€æŸ¥è¿‡ç¨‹ã€‚
        3. Wait/Notify: èµ„æºä¸è¶³æ—¶æŒ‚èµ·ç­‰å¾…ã€‚
        """
        # [ç­–ç•¥1] å¼ºåˆ¶æ’åº (Resource Ordering)
        req_types = sorted(list(set(resource_types)))
        
        for r_type in req_types:
            if r_type not in self.pools:
                 raise RuntimeError(f"Resource type '{r_type}' not initialized.")

        logger.info(f"ğŸ”„ [AtomicAlloc] Worker={worker_id} Requesting (Sorted): {req_types}")
        
        start_time = time.time()
        
        # [ç­–ç•¥2] å…¨å±€åˆ†é…é” (Global Lock)
        with self.state_cond:
            while True:
                # --- æ£€æŸ¥é˜¶æ®µ ---
                all_available = True
                unavailable_resource = None
                
                for r_type in req_types:
                    pool = self.pools[r_type]
                    stats = pool.get_stats()
                    if stats['free'] <= 0:
                        all_available = False
                        unavailable_resource = r_type
                        break
                
                # --- åˆ†é…é˜¶æ®µ ---
                if all_available:
                    allocated_batch = {}
                    try:
                        for r_type in req_types:
                            pool = self.pools[r_type]
                            res = pool.allocate(worker_id, timeout=0.01) 
                            if not res:
                                raise RuntimeError(f"Unexpected allocation failure for {r_type}")
                            allocated_batch[r_type] = res
                            
                        res_ids = [r['id'] for r in allocated_batch.values()]
                        for r_type, res in allocated_batch.items():
                            self.tracker.record_instance_task(res['id'], worker_id)
                        
                        logger.info(f"âœ… [AtomicAlloc] Worker={worker_id} Acquired: {res_ids}")
                        return allocated_batch
                        
                    except Exception as e:
                        logger.error(f"Critical error during allocation phase: {e}")
                        for r_type, res in allocated_batch.items():
                            self.pools[r_type].release(res['id'], worker_id, reset=False)
                        raise e

                # --- ç­‰å¾…é˜¶æ®µ ---
                elapsed = time.time() - start_time
                if elapsed > timeout:
                    err_msg = f"Atomic allocation timeout for {req_types} after {elapsed:.1f}s. Missing: {unavailable_resource}"
                    logger.error(f"âŒ [AtomicTimeout] Worker={worker_id} {err_msg}")
                    raise RuntimeError(err_msg)
                
                logger.info(f"â³ [AtomicWait] Worker={worker_id} Waiting for {unavailable_resource}... (Elapsed: {elapsed:.1f}s)")
                self.state_cond.wait(timeout=5.0)

    def allocate(self, worker_id: str, timeout: float = 60.0, resource_type: str = None) -> Dict[str, Any]:
        """é€šç”¨ç”³è¯·èµ„æºé€»è¾‘ï¼ˆå•èµ„æºï¼‰"""
        if not resource_type:
             raise ValueError("resource_type must be specified")
        res_map = self.allocate_atomic(worker_id, [resource_type], timeout)
        return res_map[resource_type]

    def release(self, resource_id: str, worker_id: str) -> None:
        """é€šç”¨é‡Šæ”¾é€»è¾‘"""
        released = False
        target_pool = None
        
        # [ç­–ç•¥2 & 3] è·å–é”è¿›è¡Œé‡Šæ”¾ï¼Œå¹¶å‘é€é€šçŸ¥
        with self.state_cond:
            for name, pool in self.pools.items():
                if resource_id in pool.pool:
                    target_pool = name
                    if pool.release(resource_id, worker_id, reset=True):
                        self.tracker.record_instance_cleaned(resource_id)
                        released = True
                        break 
            
            if released:
                logger.info(f"â™»ï¸ [Released] Worker={worker_id} released {resource_id} from pool '{target_pool}'")
                # [ç­–ç•¥3] å”¤é†’æ‰€æœ‰ç­‰å¾…çš„ Worker
                self.state_cond.notify_all()
                logger.debug("ğŸ”” Notified all waiting workers.")
            else:
                logger.warning(f"âš ï¸ [ReleaseFail] Could not release {resource_id} (not found or not owned by {worker_id})")

    def release_batch(self, resources: Dict[str, Any], worker_id: str) -> None:
        """æ‰¹é‡é‡Šæ”¾ç”± allocate_atomic åˆ†é…çš„èµ„æº"""
        for r_type, res in resources.items():
            if isinstance(res, dict) and 'id' in res:
                self.release(res['id'], worker_id)

    def get_status(self) -> Dict[str, Any]:
        """åŠ¨æ€èšåˆçŠ¶æ€ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.state_cond:
            return {name: pool.get_stats() for name, pool in self.pools.items()}
    
    # [æ–°å¢] èšåˆè§‚æµ‹æ•°æ®çš„æ–¹æ³•
    def get_initial_observations(self, worker_id: str) -> Dict[str, Any]:
        """
        éå†æ‰€æœ‰ Poolï¼Œæ”¶é›†è¯¥ Worker åä¸‹æ‰€æœ‰èµ„æºçš„ Observationã€‚
        """
        results = {}
        # self.pools æ˜¯æ ¹æ® deployment_config.json åˆå§‹åŒ–ç”Ÿæˆçš„
        for res_type, pool in self.pools.items():
            found_entry = None
            
            # 1. æŸ¥æ‰¾ Worker æ‹¥æœ‰çš„èµ„æº ID
            with pool.pool_lock:
                for entry in pool.pool.values():
                    if entry.allocated_to == worker_id:
                        found_entry = entry
                        break
            
            # 2. è·å–è§‚æµ‹æ•°æ® (å¦‚æœæ²¡æ‰¾åˆ°èµ„æºï¼Œé»˜è®¤ä¸º None)
            obs = None
            if found_entry:
                try:
                    obs = pool.get_observation(found_entry.resource_id)
                except Exception as e:
                    logger.error(f"Error getting observation for {res_type}: {e}")
            
            results[res_type] = obs
            
        return results

    # [ä¿®æ”¹] top_k ç±»å‹æ”¹ä¸º Optional[int] = None
    def query_rag(self, resource_id: str, worker_id: str, query: str, top_k: Optional[int] = None) -> str:
        # RAG ç‰¹æœ‰æ–¹æ³•çš„ç‰¹æ®Šå¤„ç†
        rag_pool = self.pools.get("rag")
        if not rag_pool:
            raise RuntimeError("RAG Pool not initialized")
        return rag_pool.process_query(resource_id, worker_id, query, top_k)
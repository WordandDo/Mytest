# src/services/simple_manager.py
import logging
import time
import random
from typing import Dict, Any, Optional, List
from utils.instance_tracker import get_instance_tracker
from utils.resource_pools.base import ResourceStatus
from utils.resource_pools.factory import ResourcePoolFactory

logger = logging.getLogger(__name__)

class GenericResourceManager:  # [å»ºè®®é‡å‘½åç±»ï¼Œæˆ–ä¿ç•™åŸå]
    def __init__(self, full_config: Dict[str, Any]):
        self.full_config = full_config
        # [ä¿®æ”¹] ç»Ÿä¸€å­˜å‚¨æ‰€æœ‰ Pool: {"vm": pool_obj, "rag": pool_obj}
        self.pools: Dict[str, Any] = {} 
        self.tracker = get_instance_tracker()

    def initialize(self) -> bool:
        """æ ¹æ®é…ç½®åŠ¨æ€åˆå§‹åŒ–æ‰€æœ‰å¼€å¯çš„èµ„æºæ± """
        logger.info("Initializing All Resource Pools...")
        all_success = True
        
        resources_conf = self.full_config.get("resources", {})
        
        for res_type, res_conf in resources_conf.items():
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨
            if not res_conf.get("enabled", False):
                logger.info(f"Skipping disabled resource: {res_type}")
                continue

            logger.info(f"--> Init Pool: {res_type}")
            try:
                # 1. ä½¿ç”¨å·¥å‚åˆ›å»ºå®ä¾‹
                pool_impl = ResourcePoolFactory.create_pool(
                    class_path=res_conf["implementation_class"],
                    config=res_conf["config"]
                )
                
                # 2. è°ƒç”¨åˆå§‹åŒ–æ–¹æ³• (max_workers å¯é€‰å†™å…¥ configï¼Œè¿™é‡Œæš‚å®šé»˜è®¤å€¼)
                # å‡è®¾æ‰€æœ‰ PoolImpl éƒ½ç»§æ‰¿è‡ª AbstractPoolManager å¹¶æœ‰ initialize_pool
                success = pool_impl.initialize_pool(max_workers=5)
                
                if success:
                    self.pools[res_type] = pool_impl
                    logger.info(f"âœ… Pool '{res_type}' initialized. Size: {pool_impl.num_items}")
                else:
                    logger.warning(f"âš ï¸ Pool '{res_type}' failed to initialize fully.")
                    all_success = False
                    
            except Exception as e:
                logger.error(f"âŒ Failed to init pool '{res_type}': {e}", exc_info=True)
                all_success = False

        return all_success

    def allocate_atomic(self, worker_id: str, resource_types: List[str], timeout: float = 600.0) -> Dict[str, Any]:
        """
        åŸå­åŒ–ç”³è¯·å¤šç§èµ„æºã€‚è¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥å¹¶é‡è¯•ã€‚
        """
        req_types = list(set(resource_types))
        for r_type in req_types:
            if r_type not in self.pools:
                 raise RuntimeError(f"Resource type '{r_type}' not initialized.")

        logger.info(f"ğŸ”„ [AtomicAlloc] Worker={worker_id} Start requesting: {req_types}")
        
        start_time = time.time()
        attempt_count = 0
        
        while True:
            attempt_count += 1
            allocated_batch = {}
            success = True

            for r_type in req_types:
                pool = self.pools[r_type]
                try:
                    # å°è¯•å¿«é€Ÿè·å–ï¼Œä¸ç­‰å¾… (timeout=0.1 é¿å…é•¿æ—¶é—´é˜»å¡)
                    resource = pool.allocate(worker_id, timeout=0.1)
                    if resource:
                        allocated_batch[r_type] = resource
                    else:
                        success = False
                        # [Log] æ‹¿å•ä¸ªèµ„æºå¤±è´¥
                        logger.warning(f"âš ï¸ [AtomicAlloc] Worker={worker_id} failed to get '{r_type}' in attempt #{attempt_count}")
                        break
                except Exception as e:
                    logger.error(f"Error checking {r_type}: {e}")
                    success = False
                    break
            
            if success:
                # [Log] å…¨éƒ¨æˆåŠŸ
                res_ids = [r['id'] for r in allocated_batch.values()]
                for r_type, res in allocated_batch.items():
                    self.tracker.record_instance_task(res['id'], worker_id)
                logger.info(f"âœ… [AtomicAlloc] Worker={worker_id} Success. IDs={res_ids}")
                return allocated_batch
            else:
                # å¤±è´¥å›æ»š
                if allocated_batch:
                    acquired_keys = list(allocated_batch.keys())
                    logger.warning(f"âª [AtomicRollback] Worker={worker_id} rolling back: {acquired_keys}")
                    for r_type, res in allocated_batch.items():
                        pool = self.pools[r_type]
                        pool.release(res['id'], worker_id, reset=False)
                
                # è¶…æ—¶æ£€æŸ¥
                elapsed = time.time() - start_time
                if elapsed > timeout:
                    err_msg = f"Atomic allocation timeout for {req_types} after {elapsed:.1f}s"
                    logger.error(f"âŒ [AtomicTimeout] Worker={worker_id} {err_msg}")
                    raise RuntimeError(err_msg)
                
                # éšæœºé¿é€€
                sleep_time = random.uniform(2.0, 5.0) # [è°ƒæ•´] ç¨å¾®å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œå‡å°‘æ—¥å¿—åˆ·å±
                logger.info(f"â³ [AtomicWait] Worker={worker_id} Waiting {sleep_time:.1f}s before retry... (Elapsed: {elapsed:.1f}s)")
                time.sleep(sleep_time)

    def allocate(self, worker_id: str, timeout: float = 60.0, resource_type: str = "vm") -> Dict[str, Any]:
        """é€šç”¨ç”³è¯·èµ„æºé€»è¾‘ï¼ˆå•èµ„æºï¼Œå…¼å®¹æ—§æ¥å£ï¼‰"""
        res_map = self.allocate_atomic(worker_id, [resource_type], timeout)
        return res_map[resource_type]

    def release(self, resource_id: str, worker_id: str) -> None:
        """é€šç”¨é‡Šæ”¾é€»è¾‘"""
        released = False
        target_pool = None
        
        for name, pool in self.pools.items():
            if resource_id in pool.pool:
                target_pool = name
                if pool.release(resource_id, worker_id, reset=True):
                    self.tracker.record_instance_cleaned(resource_id)
                    released = True
                    break 
        
        if released:
            logger.info(f"â™»ï¸ [Released] Worker={worker_id} released {resource_id} from pool '{target_pool}'")
        else:
            logger.warning(f"âš ï¸ [ReleaseFail] Could not release {resource_id} (not found or not owned by {worker_id})")

    def release_batch(self, resources: Dict[str, Any], worker_id: str) -> None:
        """æ‰¹é‡é‡Šæ”¾ç”± allocate_atomic åˆ†é…çš„èµ„æº"""
        for r_type, res in resources.items():
            if isinstance(res, dict) and 'id' in res:
                self.release(res['id'], worker_id)

    def get_status(self) -> Dict[str, Any]:
        """åŠ¨æ€èšåˆçŠ¶æ€"""
        return {name: pool.get_stats() for name, pool in self.pools.items()}
    
    # [æ–°å¢] èšåˆè§‚æµ‹æ•°æ®çš„æ–¹æ³•
    def get_initial_observations(self, worker_id: str) -> Dict[str, Any]:
        """
        éå†æ‰€æœ‰ Poolï¼Œæ”¶é›†è¯¥ Worker åä¸‹æ‰€æœ‰èµ„æºçš„ Observationã€‚
        """
        results = {}
        # self.pools æ˜¯æ ¹æ® deployment_config.json åˆå§‹åŒ–ç”Ÿæˆçš„
        for res_type, pool in self.pools.items():
            found_entry = None
            
            # 1. æŸ¥æ‰¾ Worker æ‹¥æœ‰çš„èµ„æº ID
            with pool.pool_lock:
                for entry in pool.pool.values():
                    if entry.allocated_to == worker_id:
                        found_entry = entry
                        break
            
            # 2. è·å–è§‚æµ‹æ•°æ® (å¦‚æœæ²¡æ‰¾åˆ°èµ„æºï¼Œé»˜è®¤ä¸º None)
            obs = None
            if found_entry:
                try:
                    obs = pool.get_observation(found_entry.resource_id)
                except Exception as e:
                    logger.error(f"Error getting observation for {res_type}: {e}")
            
            results[res_type] = obs
            
        return results

    # [ä¿®æ”¹] top_k ç±»å‹æ”¹ä¸º Optional[int] = None
    def query_rag(self, resource_id: str, worker_id: str, query: str, top_k: Optional[int] = None) -> str:
        # RAG ç‰¹æœ‰æ–¹æ³•çš„ç‰¹æ®Šå¤„ç†
        rag_pool = self.pools.get("rag")
        if not rag_pool:
            raise RuntimeError("RAG Pool not initialized")
        return rag_pool.process_query(resource_id, worker_id, query, top_k)
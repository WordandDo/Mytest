# src/services/simple_manager.py
# é€šç”¨èµ„æºç®¡ç†å™¨å®ç°ï¼Œè´Ÿè´£å…·ä½“èµ„æºçš„åˆ†é…ã€é‡Šæ”¾å’Œç®¡ç†é€»è¾‘
# é‡‡ç”¨å·¥å‚æ¨¡å¼å’Œé…ç½®é©±åŠ¨çš„æ–¹å¼ï¼Œæ”¯æŒåŠ¨æ€åŠ è½½å’Œç®¡ç†å„ç§èµ„æºç±»å‹

import logging
import time
import threading
from typing import Dict, Any, Optional, List
from utils.instance_tracker import get_instance_tracker  # å®ä¾‹è·Ÿè¸ªå™¨ï¼Œç”¨äºè·Ÿè¸ªèµ„æºå®ä¾‹çš„åˆ†é…å’Œé‡Šæ”¾
from utils.resource_pools.base import ResourceStatus  # èµ„æºçŠ¶æ€æšä¸¾
from utils.resource_pools.factory import ResourcePoolFactory  # èµ„æºæ± å·¥å‚ï¼Œç”¨äºåŠ¨æ€åˆ›å»ºèµ„æºæ± å®ä¾‹

logger = logging.getLogger(__name__)

class GenericResourceManager:
    """
    é€šç”¨èµ„æºç®¡ç†å™¨
    
    è´Ÿè´£ç®¡ç†å„ç§èµ„æºæ± çš„åˆå§‹åŒ–ã€åˆ†é…ã€é‡Šæ”¾å’ŒçŠ¶æ€ç›‘æ§ç­‰åŠŸèƒ½ã€‚
    é‡‡ç”¨å·¥å‚æ¨¡å¼å’Œé…ç½®é©±åŠ¨ï¼Œæ”¯æŒåŠ¨æ€æ‰©å±•æ–°çš„èµ„æºç±»å‹ã€‚
    """
    
    def __init__(self, full_config: Dict[str, Any]):
        """
        åˆå§‹åŒ–èµ„æºç®¡ç†å™¨
        
        Args:
            full_config: å®Œæ•´çš„é…ç½®å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰èµ„æºç±»å‹çš„é…ç½®ä¿¡æ¯
        """
        self.full_config = full_config
        self.pools: Dict[str, Any] = {}  # å­˜å‚¨å·²åˆå§‹åŒ–çš„èµ„æºæ± å®ä¾‹
        self.tracker = get_instance_tracker()  # è·å–å®ä¾‹è·Ÿè¸ªå™¨å®ä¾‹
        
        # [æ ¸å¿ƒç»„ä»¶] ä½¿ç”¨ Condition å®ç°å…¨å±€é”å’Œé€šçŸ¥æœºåˆ¶
        # ç”¨äºç¡®ä¿èµ„æºåˆ†é…çš„åŸå­æ€§å’Œçº¿ç¨‹å®‰å…¨ï¼Œé˜²æ­¢æ­»é”å’Œèµ„æºç«äº‰
        self.state_cond = threading.Condition()

    def initialize(self) -> bool:
        """
        æ ¹æ®é…ç½®åŠ¨æ€åˆå§‹åŒ–æ‰€æœ‰å¼€å¯çš„èµ„æºæ± 
        
        éå†é…ç½®ä¸­çš„æ‰€æœ‰èµ„æºç±»å‹ï¼Œå¯¹å¯ç”¨çš„èµ„æºç±»å‹åˆ›å»ºå¯¹åº”çš„èµ„æºæ± å®ä¾‹ã€‚
        
        Returns:
            åˆå§‹åŒ–æ˜¯å¦å…¨éƒ¨æˆåŠŸ
        """
        logger.info("Initializing All Resource Pools...")
        all_success = True
        
        # è·å–èµ„æºé…ç½®éƒ¨åˆ†
        resources_conf = self.full_config.get("resources", {})
        
        # éå†æ¯ç§èµ„æºé…ç½®
        for res_type, res_conf in resources_conf.items():
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯¥èµ„æºç±»å‹
            if not res_conf.get("enabled", False):
                logger.info(f"Skipping disabled resource: {res_type}")
                continue

            logger.info(f"--> Init Pool: {res_type}")
            try:
                # 1. ä½¿ç”¨å·¥å‚åˆ›å»ºå®ä¾‹ (æ­¤æ—¶ config é‡Œå·²ç»æœ‰äº† action_space)
                # é€šè¿‡èµ„æºæ± å·¥å‚åŠ¨æ€åˆ›å»ºèµ„æºæ± å®ä¾‹
                pool_impl = ResourcePoolFactory.create_pool(
                    class_path=res_conf["implementation_class"],  # èµ„æºæ± å®ç°ç±»è·¯å¾„
                    config=res_conf["config"]  # èµ„æºæ± é…ç½®
                )
                
                # 2. è°ƒç”¨åˆå§‹åŒ–æ–¹æ³• (max_workers å¯é€‰å†™å…¥ configï¼Œè¿™é‡Œæš‚å®šé»˜è®¤å€¼)
                # å‡è®¾æ‰€æœ‰ PoolImpl éƒ½ç»§æ‰¿è‡ª AbstractPoolManager å¹¶æœ‰ initialize_pool
                success = pool_impl.initialize_pool(max_workers=5)
                
                if success:
                    # åˆå§‹åŒ–æˆåŠŸï¼Œå°†èµ„æºæ± å®ä¾‹ä¿å­˜åˆ°poolså­—å…¸ä¸­
                    self.pools[res_type] = pool_impl
                    logger.info(f"âœ… Pool '{res_type}' initialized. Size: {pool_impl.num_items}")
                else:
                    # åˆå§‹åŒ–å¤±è´¥
                    logger.warning(f"âš ï¸ Pool '{res_type}' failed to initialize fully.")
                    all_success = False
                    
            except Exception as e:
                # æ•è·åˆå§‹åŒ–è¿‡ç¨‹ä¸­çš„å¼‚å¸¸
                logger.error(f"âŒ Failed to init pool '{res_type}': {e}", exc_info=True)
                all_success = False

        return all_success

    def allocate_atomic(self, worker_id: str, resource_types: List[str], timeout: float = 600.0) -> Dict[str, Any]:
        """
        åŸå­æ€§åœ°åˆ†é…å¤šä¸ªèµ„æº
        
        é‡‡ç”¨å¤åˆæ–¹æ¡ˆå®ç°èµ„æºåˆ†é…ï¼Œç¡®ä¿åˆ†é…è¿‡ç¨‹çš„åŸå­æ€§å’Œçº¿ç¨‹å®‰å…¨ï¼š
        1. Ordering: å¯¹è¯·æ±‚èµ„æºæ’åºï¼Œé˜²æ­¢æ­»é”ã€‚
        2. Global Lock: ä½¿ç”¨ Condition é”ä½æ•´ä¸ªæ£€æŸ¥è¿‡ç¨‹ã€‚
        3. Wait/Notify: èµ„æºä¸è¶³æ—¶æŒ‚èµ·ç­‰å¾…ã€‚
        
        Args:
            worker_id: å·¥ä½œèŠ‚ç‚¹ID
            resource_types: éœ€è¦åˆ†é…çš„èµ„æºç±»å‹åˆ—è¡¨
            timeout: åˆ†é…è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            åˆ†é…æˆåŠŸçš„èµ„æºä¿¡æ¯å­—å…¸
            
        Raises:
            RuntimeError: èµ„æºåˆ†é…å¤±è´¥æˆ–è¶…æ—¶
        """
        # [ç­–ç•¥1] å¼ºåˆ¶æ’åº (Resource Ordering)
        # å¯¹è¯·æ±‚çš„èµ„æºç±»å‹è¿›è¡Œæ’åºï¼Œç¡®ä¿æ‰€æœ‰çº¿ç¨‹æŒ‰ç…§ç›¸åŒé¡ºåºç”³è¯·èµ„æºï¼Œé˜²æ­¢æ­»é”
        req_types = sorted(list(set(resource_types)))
        
        # æ£€æŸ¥è¯·æ±‚çš„èµ„æºç±»å‹æ˜¯å¦éƒ½å·²åˆå§‹åŒ–
        for r_type in req_types:
            if r_type not in self.pools:
                 raise RuntimeError(f"Resource type '{r_type}' not initialized.")

        logger.info(f"ğŸ”„ [AtomicAlloc] Worker={worker_id} Requesting (Sorted): {req_types}")
        
        start_time = time.time()
        
        # [ç­–ç•¥2] å…¨å±€åˆ†é…é” (Global Lock)
        # ä½¿ç”¨withè¯­å¥ç¡®ä¿é”çš„æ­£ç¡®è·å–å’Œé‡Šæ”¾
        with self.state_cond:
            while True:
                # --- æ£€æŸ¥é˜¶æ®µ ---
                # æ£€æŸ¥æ‰€æœ‰è¯·æ±‚çš„èµ„æºæ˜¯å¦éƒ½æœ‰ç©ºé—²å®ä¾‹
                all_available = True
                unavailable_resource = None
                
                for r_type in req_types:
                    pool = self.pools[r_type]
                    stats = pool.get_stats()
                    if stats['free'] <= 0:
                        all_available = False
                        unavailable_resource = r_type
                        break
                
                # --- åˆ†é…é˜¶æ®µ ---
                if all_available:
                    # æ‰€æœ‰èµ„æºéƒ½æœ‰ç©ºé—²å®ä¾‹ï¼Œå¼€å§‹åˆ†é…
                    allocated_batch = {}
                    try:
                        # ä¾æ¬¡åˆ†é…æ¯ç§èµ„æº
                        for r_type in req_types:
                            pool = self.pools[r_type]
                            res = pool.allocate(worker_id, timeout=0.01) 
                            if not res:
                                raise RuntimeError(f"Unexpected allocation failure for {r_type}")
                            allocated_batch[r_type] = res
                            
                        # è®°å½•åˆ†é…çš„èµ„æºIDå¹¶è·Ÿè¸ªå®ä¾‹
                        res_ids = [r['id'] for r in allocated_batch.values()]
                        for r_type, res in allocated_batch.items():
                            self.tracker.record_instance_task(res['id'], worker_id)
                        
                        logger.info(f"âœ… [AtomicAlloc] Worker={worker_id} Acquired: {res_ids}")
                        return allocated_batch
                        
                    except Exception as e:
                        # åˆ†é…è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼Œå›æ»šå·²åˆ†é…çš„èµ„æº
                        logger.error(f"Critical error during allocation phase: {e}")
                        for r_type, res in allocated_batch.items():
                            # ä»…é‡Šæ”¾é”ï¼Œä¸é‡ç½®èµ„æºçŠ¶æ€
                            self.pools[r_type].release(res['id'], worker_id, reset=False)
                        raise e

                # --- ç­‰å¾…é˜¶æ®µ ---
                # è®¡ç®—å·²ç­‰å¾…æ—¶é—´
                elapsed = time.time() - start_time
                if elapsed > timeout:
                    # ç­‰å¾…è¶…æ—¶ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    err_msg = f"Atomic allocation timeout for {req_types} after {elapsed:.1f}s. Missing: {unavailable_resource}"
                    logger.error(f"âŒ [AtomicTimeout] Worker={worker_id} {err_msg}")
                    raise RuntimeError(err_msg)
                
                # è®°å½•ç­‰å¾…ä¿¡æ¯å¹¶æŒ‚èµ·çº¿ç¨‹
                logger.info(f"â³ [AtomicWait] Worker={worker_id} Waiting for {unavailable_resource}... (Elapsed: {elapsed:.1f}s)")
                # ç­‰å¾…å…¶ä»–çº¿ç¨‹é‡Šæ”¾èµ„æºï¼Œè¶…æ—¶æ—¶é—´ä¸º5ç§’
                self.state_cond.wait(timeout=5.0)

    def allocate(self, worker_id: str, timeout: float = 60.0, resource_type: str = None) -> Dict[str, Any]:
        """
        åˆ†é…å•ä¸ªèµ„æº
        
        Args:
            worker_id: å·¥ä½œèŠ‚ç‚¹ID
            timeout: åˆ†é…è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            resource_type: èµ„æºç±»å‹
            
        Returns:
            åˆ†é…æˆåŠŸçš„èµ„æºä¿¡æ¯
            
        Raises:
            ValueError: æœªæŒ‡å®šèµ„æºç±»å‹
        """
        # æ£€æŸ¥èµ„æºç±»å‹æ˜¯å¦æŒ‡å®š
        if not resource_type:
             raise ValueError("resource_type must be specified")
        # è°ƒç”¨åŸå­åˆ†é…æ–¹æ³•åˆ†é…èµ„æº
        res_map = self.allocate_atomic(worker_id, [resource_type], timeout)
        return res_map[resource_type]

    def release(self, resource_id: str, worker_id: str) -> None:
        """
        é‡Šæ”¾èµ„æº
        
        Args:
            resource_id: èµ„æºID
            worker_id: å·¥ä½œèŠ‚ç‚¹ID
        """
        released = False
        target_pool = None
        
        # [ç­–ç•¥2 & 3] è·å–é”è¿›è¡Œé‡Šæ”¾ï¼Œå¹¶å‘é€é€šçŸ¥
        # ä½¿ç”¨withè¯­å¥ç¡®ä¿é”çš„æ­£ç¡®è·å–å’Œé‡Šæ”¾
        with self.state_cond:
            # æŸ¥æ‰¾èµ„æºæ‰€å±çš„èµ„æºæ± 
            for name, pool in self.pools.items():
                if resource_id in pool.pool:
                    target_pool = name
                    # è°ƒç”¨èµ„æºæ± çš„é‡Šæ”¾æ–¹æ³•
                    if pool.release(resource_id, worker_id, reset=True):
                        # é‡Šæ”¾æˆåŠŸï¼Œè®°å½•æ¸…ç†äº‹ä»¶
                        self.tracker.record_instance_cleaned(resource_id)
                        released = True
                        break 
            
            if released:
                # é‡Šæ”¾æˆåŠŸï¼Œè®°å½•æ—¥å¿—å¹¶é€šçŸ¥å…¶ä»–ç­‰å¾…çš„çº¿ç¨‹
                logger.info(f"â™»ï¸ [Released] Worker={worker_id} released {resource_id} from pool '{target_pool}'")
                # [ç­–ç•¥3] å”¤é†’æ‰€æœ‰ç­‰å¾…çš„ Worker
                self.state_cond.notify_all()
                logger.debug("ğŸ”” Notified all waiting workers.")
            else:
                # é‡Šæ”¾å¤±è´¥ï¼Œè®°å½•è­¦å‘Šæ—¥å¿—
                logger.warning(f"âš ï¸ [ReleaseFail] Could not release {resource_id} (not found or not owned by {worker_id})")

    def release_batch(self, resources: Dict[str, Any], worker_id: str) -> None:
        """
        æ‰¹é‡é‡Šæ”¾èµ„æº
        
        Args:
            resources: èµ„æºä¿¡æ¯å­—å…¸
            worker_id: å·¥ä½œèŠ‚ç‚¹ID
        """
        # éå†èµ„æºå­—å…¸ï¼Œé€ä¸€é‡Šæ”¾æ¯ä¸ªèµ„æº
        for r_type, res in resources.items():
            if isinstance(res, dict) and 'id' in res:
                self.release(res['id'], worker_id)

    def get_status(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰èµ„æºæ± çš„çŠ¶æ€ä¿¡æ¯
        
        Returns:
            å„èµ„æºæ± çš„çŠ¶æ€ä¿¡æ¯å­—å…¸
        """
        # ä½¿ç”¨å…¨å±€é”ç¡®ä¿çŠ¶æ€è·å–çš„åŸå­æ€§
        with self.state_cond:
            return {name: pool.get_stats() for name, pool in self.pools.items()}
    
    # [æ–°å¢] èšåˆè§‚æµ‹æ•°æ®çš„æ–¹æ³•
    def get_initial_observations(self, worker_id: str) -> Dict[str, Any]:
        """
        éå†æ‰€æœ‰ Poolï¼Œæ”¶é›†è¯¥ Worker åä¸‹æ‰€æœ‰èµ„æºçš„ Observationã€‚
        
        Args:
            worker_id: å·¥ä½œèŠ‚ç‚¹ID
            
        Returns:
            å„èµ„æºç±»å‹çš„è§‚æµ‹æ•°æ®å­—å…¸
        """
        results = {}
        # self.pools æ˜¯æ ¹æ® deployment_config.json åˆå§‹åŒ–ç”Ÿæˆçš„
        for res_type, pool in self.pools.items():
            found_entry = None
            
            # 1. æŸ¥æ‰¾ Worker æ‹¥æœ‰çš„èµ„æº ID
            # ä½¿ç”¨èµ„æºæ± çš„é”ç¡®ä¿çº¿ç¨‹å®‰å…¨
            with pool.pool_lock:
                for entry in pool.pool.values():
                    if entry.allocated_to == worker_id:
                        found_entry = entry
                        break
            
            # 2. è·å–è§‚æµ‹æ•°æ® (å¦‚æœæ²¡æ‰¾åˆ°èµ„æºï¼Œé»˜è®¤ä¸º None)
            obs = None
            if found_entry:
                try:
                    # è°ƒç”¨èµ„æºæ± çš„è§‚æµ‹æ–¹æ³•è·å–æ•°æ®
                    obs = pool.get_observation(found_entry.resource_id)
                except Exception as e:
                    logger.error(f"Error getting observation for {res_type}: {e}")
            
            results[res_type] = obs
            
        return results

    # [ä¿®æ”¹] top_k ç±»å‹æ”¹ä¸º Optional[int] = None
    def query_rag(self, resource_id: str, worker_id: str, query: str, top_k: Optional[int] = None) -> str:
        """
        RAGæŸ¥è¯¢æ–¹æ³•
        
        Args:
            resource_id: èµ„æºID
            worker_id: å·¥ä½œèŠ‚ç‚¹ID
            query: æŸ¥è¯¢å†…å®¹
            top_k: è¿”å›ç»“æœæ•°é‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æŸ¥è¯¢ç»“æœæ–‡æœ¬
            
        Raises:
            RuntimeError: RAGèµ„æºæ± æœªåˆå§‹åŒ–
        """
        # RAG ç‰¹æœ‰æ–¹æ³•çš„ç‰¹æ®Šå¤„ç†
        rag_pool = self.pools.get("rag")
        if not rag_pool:
            raise RuntimeError("RAG Pool not initialized")
        # è°ƒç”¨RAGèµ„æºæ± çš„æŸ¥è¯¢æ–¹æ³•
        return rag_pool.process_query(resource_id, worker_id, query, top_k)
"""
æ•°æ®åˆæˆä¸»Pipeline

æ•´åˆtrajectoryé‡‡æ ·ã€é€‰æ‹©å’ŒQAåˆæˆçš„å®Œæ•´æµç¨‹
"""

import json
import os
import bdb
import hashlib
from typing import List, Dict, Set

import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from envs import (
    Environment,
    MathEnvironment,
    PythonEnvironment,
    RAGEnvironment,
    WebEnvironment,
    OSWorldEnvironment
)
from models import TrajectoryNode, Trajectory, SynthesizedQA
from synthesis_config import SynthesisConfig
from trajectory_sampler import GenericTrajectorySampler
from trajectory_selector import GenericTrajectorySelector
from qa_synthesizer import GenericQASynthesizer


class GenericDataSynthesis:
    """
    é€šç”¨æ•°æ®åˆæˆä¸»ç±» - æ”¯æŒæ‰€æœ‰ç¯å¢ƒå’Œå·¥å…·
    """
    
    def __init__(self, config: SynthesisConfig, output_dir: str = "synthesis_results"):
        """
        åˆå§‹åŒ–é€šç”¨æ•°æ®åˆæˆç³»ç»Ÿ
        
        Args:
            config: åˆæˆé…ç½®
            output_dir: è¾“å‡ºç›®å½•
        """
        self.config = config
        self.output_dir = output_dir
        
        # éªŒè¯é…ç½®
        errors = config.validate()
        if errors:
            raise ValueError(f"é…ç½®é”™è¯¯: {', '.join(errors)}")
        
        # åˆ›å»ºç¯å¢ƒ
        print(f"åˆå§‹åŒ– {config.environment_mode.upper()} Environment...")
        self.environment = self._create_environment()
        
        # åˆ›å»ºä¸‰ä¸ªç»„ä»¶
        self.sampler = GenericTrajectorySampler(
            environment=self.environment,
            config=config
        )
        
        self.selector = GenericTrajectorySelector(config=config)
        
        self.synthesizer = GenericQASynthesizer(config=config)
        
        # å­˜å‚¨ç»“æœ
        self.trajectory_tree: Dict[str, TrajectoryNode] = {}
        self.selected_trajectories: List[Trajectory] = []
        self.synthesized_qas: List[SynthesizedQA] = []
        
        # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆåœ¨runæ—¶åˆ›å»ºï¼‰
        self.qa_file_path = None
        self.traj_file_path = None
        
        # å·²å¤„ç†çš„source_idé›†åˆ
        self.processed_source_ids: Set[str] = set()
    
    def _create_environment(self) -> Environment:
        """æ ¹æ®é…ç½®åˆ›å»ºç›¸åº”çš„ç¯å¢ƒ"""
        mode = self.config.environment_mode.lower()
        kwargs = self.config.environment_kwargs.copy()
        kwargs['model_name'] = self.config.model_name
        
        if mode == "web":
            return WebEnvironment(**kwargs)
        elif mode == "math":
            return MathEnvironment(**kwargs)
        elif mode == "python" or mode == "py":
            return PythonEnvironment(**kwargs)
        elif mode == "rag":
            if 'rag_index' not in kwargs:
                raise ValueError("RAGç¯å¢ƒéœ€è¦æä¾›rag_indexå‚æ•°")
            return RAGEnvironment(**kwargs)
        elif mode == "osworld" or mode == "gui":
            # OSWorld/GUIç¯å¢ƒéœ€è¦VMé…ç½®
            required_params = ['path_to_vm']
            missing = [p for p in required_params if p not in kwargs]
            if missing:
                raise ValueError(f"OSWorldç¯å¢ƒéœ€è¦æä¾›ä»¥ä¸‹å‚æ•°: {', '.join(missing)}")
            from envs import OSWorldEnvironment
            return OSWorldEnvironment(**kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç¯å¢ƒæ¨¡å¼: {mode}")
    
    def _initialize_output_files(self):
        """åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶è·¯å¾„å¹¶åˆ›å»ºè¾“å‡ºç›®å½•"""
        os.makedirs(self.output_dir, exist_ok=True)
        
        # è®¾ç½®QAè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå›ºå®šæ–‡ä»¶åï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
        self.qa_file_path = os.path.join(
            self.output_dir, 
            f"synthesized_qa_{self.config.environment_mode}.jsonl"
        )
        
        # è®¾ç½®trajectoriesè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå›ºå®šæ–‡ä»¶åï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
        self.traj_file_path = os.path.join(
            self.output_dir, 
            f"trajectories_{self.config.environment_mode}.jsonl"
        )
        
        print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {self.qa_file_path}")
        
        # åŠ è½½å·²å¤„ç†çš„source_id
        self._load_processed_source_ids()
    
    def _generate_source_id(self, seed_data: str, seed_idx: int) -> str:
        """
        ç”Ÿæˆsourceçš„å”¯ä¸€æ ‡è¯†
        æ ¼å¼: src_{index}_{hash}
        """
        # ä½¿ç”¨seedå†…å®¹çš„hashæ¥ä¿è¯å”¯ä¸€æ€§
        content_hash = hashlib.md5(seed_data.encode('utf-8')).hexdigest()[:8]
        return f"src_{seed_idx:04d}_{content_hash}"
    
    def _load_processed_source_ids(self):
        """ä»å·²æœ‰çš„è¾“å‡ºæ–‡ä»¶ä¸­åŠ è½½å·²å¤„ç†çš„source_id"""
        self.processed_source_ids.clear()
        
        # ä»QAæ–‡ä»¶ä¸­è¯»å–å·²å¤„ç†çš„source_id
        if os.path.exists(self.qa_file_path):
            try:
                with open(self.qa_file_path, "r", encoding="utf-8") as f:
                    for line in f:
                        if line.strip():
                            qa_dict = json.loads(line)
                            if "source_id" in qa_dict:
                                self.processed_source_ids.add(qa_dict["source_id"])
                
                if self.processed_source_ids:
                    print(f"ğŸ”„ å‘ç° {len(self.processed_source_ids)} ä¸ªå·²å¤„ç†çš„sourceï¼Œå°†è·³è¿‡è¿™äº›seed")
            except Exception as e:
                print(f"âš ï¸  è¯»å–å·²å¤„ç†è®°å½•æ—¶å‡ºé”™: {e}")
                self.processed_source_ids.clear()
    
    def _save_qa_immediately(self, qa: SynthesizedQA):
        """ç«‹å³å°†å•ä¸ªQAå¯¹è¿½åŠ ä¿å­˜åˆ°æ–‡ä»¶"""
        with open(self.qa_file_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(qa.to_dict(), ensure_ascii=False) + "\n")
    
    def _save_trajectories_immediately(self, trajectories: List[Trajectory]):
        """ç«‹å³å°†trajectoriesè¿½åŠ ä¿å­˜åˆ°æ–‡ä»¶"""
        with open(self.traj_file_path, "a", encoding="utf-8") as f:
            for traj in trajectories:
                f.write(json.dumps(traj.to_dict(), ensure_ascii=False) + "\n")
    
    def run(self, seeds: List[str]) -> List[SynthesizedQA]:
        """
        è¿è¡Œå®Œæ•´çš„æ•°æ®åˆæˆpipeline
        
        Args:
            seeds: Seedæ•°æ®åˆ—è¡¨ï¼ˆå¯ä»¥æ˜¯ä»»æ„ç±»å‹ï¼šentity/problem/text/urlç­‰ï¼‰
            
        Returns:
            åˆæˆçš„QAå¯¹åˆ—è¡¨
        """
        # æ ¹æ®é…ç½®é™åˆ¶å¤„ç†çš„seedæ•°é‡
        if self.config.number_of_seed is not None:
            seeds = seeds[:self.config.number_of_seed]
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ é€šç”¨Agentæ•°æ®åˆæˆ Pipeline å¯åŠ¨")
        print(f"{'='*80}")
        print(f"ç¯å¢ƒæ¨¡å¼: {self.config.environment_mode}")
        print(f"Seedè¯´æ˜: {self.config.seed_description or '(æœªæŒ‡å®š)'}")
        print(f"å¯ç”¨å·¥å…·: {[t['name'] for t in self.sampler.available_tools]}")
        print(f"æ€»Seedæ•°é‡: {len(seeds)}")
        print(f"æ¨¡å‹: {self.config.model_name}")
        print(f"{'='*80}\n")
        
        # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶
        self._initialize_output_files()
        
        all_qas = []
        skipped_count = 0
        
        for seed_idx, seed_data in enumerate(seeds, 1):
            # ä¸ºæ¯ä¸ªseedç”Ÿæˆå”¯ä¸€çš„source_id
            source_id = self._generate_source_id(seed_data, seed_idx)
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if source_id in self.processed_source_ids:
                skipped_count += 1
                print(f"\nâ­ï¸  è·³è¿‡ Seed {seed_idx}/{len(seeds)} (å·²å¤„ç†: {source_id})")
                continue
            
            print(f"\n\n{'#'*80}")
            print(f"å¤„ç† Seed {seed_idx}/{len(seeds)}")
            print(f"Source ID: {source_id}")
            print(f"å†…å®¹: {seed_data}")
            print(f"{'#'*80}\n")
            
            try:
                # Step 1: Trajectory Sampling
                print(f"\nğŸ“Š æ­¥éª¤ 1/3: Trajectory Sampling")
                self.trajectory_tree = self.sampler.sample_trajectory_tree(seed_data)
                
                # Step 2: Trajectory Selection
                print(f"\nğŸ¯ æ­¥éª¤ 2/3: Trajectory Selection")
                self.selected_trajectories = self.selector.select_trajectories(
                    nodes=self.trajectory_tree,
                    root_id=self.sampler.root_id,
                    seed_data=seed_data,
                    source_id=source_id,
                    max_selected_traj=self.config.max_selected_traj
                )
                
                # Step 3: QA Synthesis
                print(f"\nâœ¨ æ­¥éª¤ 3/3: QA Synthesis")
                for qa_idx, trajectory in enumerate(self.selected_trajectories):
                    qa = self.synthesizer.synthesize_qa(trajectory, qa_idx)
                    if qa:
                        all_qas.append(qa)
                        self.synthesized_qas.append(qa)
                        # ç«‹å³ä¿å­˜ç”Ÿæˆçš„QAå¯¹
                        self._save_qa_immediately(qa)
                
                # ç«‹å³ä¿å­˜è¯¥seedçš„æ‰€æœ‰trajectories
                if self.selected_trajectories:
                    self._save_trajectories_immediately(self.selected_trajectories)
                
                print(f"\nâœ… Seed {seed_idx} å®Œæˆ! ç”Ÿæˆäº† {len([qa for qa in all_qas if qa.source_id == source_id])} ä¸ªQAå¯¹")
                
            except Exception as e:
                if isinstance(e, bdb.BdbQuit):
                    raise e
                print(f"\nâŒ Seed {seed_idx} å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
                continue
        
        print(f"\n\n{'='*80}")
        print(f"ğŸ‰ æ•°æ®åˆæˆå®Œæˆ!")
        print(f"{'='*80}")
        print(f"æ€»Seedæ•°é‡: {len(seeds)} ä¸ª")
        print(f"å·²è·³è¿‡: {skipped_count} ä¸ª")
        print(f"æ–°å¤„ç†: {len(seeds) - skipped_count} ä¸ª")
        print(f"æˆåŠŸç”Ÿæˆ: {len(all_qas)} ä¸ªQAå¯¹")
        print(f"{'='*80}\n")
        
        return all_qas
    
    def save_results(self):
        """æ˜¾ç¤ºç»“æœä¿å­˜ä½ç½®ï¼ˆQAå¯¹å’Œtrajectorieså·²å®æ—¶ä¿å­˜ï¼‰"""
        if not self.qa_file_path:
            print("âš ï¸  è­¦å‘Š: æ²¡æœ‰è¿è¡Œè¿‡pipelineï¼Œæ— æ³•ä¿å­˜ç»“æœ")
            return
        
        print(f"ğŸ’¾ QAå¯¹å·²ä¿å­˜åˆ°: {self.qa_file_path}")
        print(f"ğŸ’¾ Trajectorieså·²ä¿å­˜åˆ°: {self.traj_file_path}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="é€šç”¨Agentæ•°æ®åˆæˆç³»ç»Ÿ")
    
    parser.add_argument("--config", type=str, required=True,
                       help="é…ç½®æ–‡ä»¶è·¯å¾„ (.json æˆ– .yaml)")
    parser.add_argument("--seeds", type=str, required=True,
                       help="Seedæ•°æ®JSONæ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒä»»æ„ç±»å‹çš„seedï¼šentity/problem/text/urlç­‰ï¼‰")
    parser.add_argument("--output-dir", type=str, default="synthesis_results",
                       help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    print(f"åŠ è½½é…ç½®æ–‡ä»¶: {args.config}")
    if args.config.endswith('.json'):
        config = SynthesisConfig.from_json(args.config)
    elif args.config.endswith('.yaml') or args.config.endswith('.yml'):
        config = SynthesisConfig.from_yaml(args.config)
    else:
        raise ValueError("é…ç½®æ–‡ä»¶å¿…é¡»æ˜¯ .json æˆ– .yaml æ ¼å¼")
    
    # è¯»å–seedæ•°æ®ï¼ˆç®€å•å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
    print(f"è¯»å– seed æ•°æ®æ–‡ä»¶: {args.seeds}")
    with open(args.seeds, "r", encoding="utf-8") as f:
        seeds = json.load(f)
        if not isinstance(seeds, list):
            raise ValueError("Seedæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šå¿…é¡»æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¾‹å¦‚: [\"seed1\", \"seed2\", \"seed3\"]")
        if not all(isinstance(s, str) for s in seeds):
            raise ValueError("Seedæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šæ‰€æœ‰seedå¿…é¡»æ˜¯å­—ç¬¦ä¸²")
    
    print(f"åŠ è½½äº† {len(seeds)} ä¸ª seed æ•°æ®")
    
    # åˆ›å»ºæ•°æ®åˆæˆç³»ç»Ÿ
    synthesizer = GenericDataSynthesis(config=config, output_dir=args.output_dir)
    
    # è¿è¡Œåˆæˆpipeline
    qas = synthesizer.run(seeds)
    
    # ä¿å­˜ç»“æœï¼ˆtrajectorieså’Œç»Ÿè®¡ä¿¡æ¯ï¼ŒQAå¯¹å·²å®æ—¶ä¿å­˜ï¼‰
    synthesizer.save_results()
    
    print(f"\nâœ… å…¨éƒ¨å®Œæˆ! å…±ç”Ÿæˆ {len(qas)} ä¸ªQAå¯¹")


if __name__ == "__main__":
    main()


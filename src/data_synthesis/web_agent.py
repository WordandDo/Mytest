"""
Web Agent Data Synthesis - ä½¿ç”¨Web Agentç”Ÿæˆè®­ç»ƒæ•°æ®

è¯¥æ¨¡å—å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„æ•°æ®åˆæˆpipelineï¼ŒåŒ…å«ä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š
1. Trajectory Sampling: ä»seedå®ä½“å¼€å§‹ï¼Œè¿­ä»£ç”ŸæˆåŠ¨ä½œå’Œè§‚å¯Ÿï¼Œå½¢æˆtrajectory tree
2. Trajectory Selection: ä»trajectory treeä¸­é€‰æ‹©å®Œæ•´çš„é“¾è·¯
3. QA Synthesis: åŸºäºé€‰æ‹©çš„trajectoryåˆæˆé—®ç­”å¯¹
"""

import openai
import json
import os
import random
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime
import sys
import pdb
import bdb

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from envs import WebEnvironment


@dataclass
class TrajectoryNode:
    """Trajectory treeä¸­çš„å•ä¸ªèŠ‚ç‚¹ï¼Œè¡¨ç¤ºä¸€ä¸ªçŠ¶æ€"""
    node_id: str
    observation: str  # å½“å‰è§‚å¯Ÿåˆ°çš„ä¿¡æ¯
    intent: str  # äº§ç”Ÿè¿™ä¸ªèŠ‚ç‚¹çš„æ„å›¾
    action: Optional[Dict[str, Any]] = None  # äº§ç”Ÿè¿™ä¸ªèŠ‚ç‚¹çš„åŠ¨ä½œ
    parent_id: Optional[str] = None
    children_ids: List[str] = field(default_factory=list)
    depth: int = 0
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return asdict(self)


@dataclass
class Trajectory:
    """å®Œæ•´çš„trajectoryé“¾è·¯"""
    trajectory_id: str
    nodes: List[TrajectoryNode]
    seed_entity: str
    total_depth: int
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "trajectory_id": self.trajectory_id,
            "seed_entity": self.seed_entity,
            "total_depth": self.total_depth,
            "nodes": [node.to_dict() for node in self.nodes]
        }


@dataclass
class SynthesizedQA:
    """åˆæˆçš„é—®ç­”å¯¹"""
    question: str
    answer: str
    trajectory_id: str
    reasoning_steps: List[Dict[str, str]]  # åŒ…å«æ¯ä¸€æ­¥çš„action, intent, observation
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return asdict(self)


class TrajectorySampler:
    """
    Trajectoryé‡‡æ ·å™¨ï¼Œè´Ÿè´£ä»seedå®ä½“ç”Ÿæˆtrajectory tree
    """
    
    def __init__(self, 
                 environment: WebEnvironment,
                 model_name: str = "gpt-4.1-2025-04-14",
                 max_depth: int = 5,
                 branching_factor: int = 2,
                 max_retries: int = 3,
                 depth_threshold: int = 3):
        """
        åˆå§‹åŒ–Trajectoryé‡‡æ ·å™¨
        
        Args:
            environment: Webç¯å¢ƒå®ä¾‹
            model_name: LLMæ¨¡å‹åç§°
            max_depth: æœ€å¤§é‡‡æ ·æ·±åº¦
            branching_factor: æ¯ä¸ªèŠ‚ç‚¹çš„åˆ†æ”¯æ•°ï¼ˆé‡‡æ ·æ¬¡æ•°ï¼‰
            max_retries: APIè°ƒç”¨æœ€å¤§é‡è¯•æ¬¡æ•°
            depth_threshold: æ·±åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤æ·±åº¦æ—¶branching_factoré™ä¸º1
        """
        self.environment = environment
        self.model_name = model_name
        self.max_depth = max_depth
        self.branching_factor = branching_factor
        self.max_retries = max_retries
        self.depth_threshold = depth_threshold
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = openai.OpenAI(
            api_key=os.environ.get("OPENAI_API_KEY", ""),
            base_url=os.environ.get("OPENAI_API_URL", os.environ.get("OPENAI_API_BASE", ""))
        )
        
        # Trajectory treeå­˜å‚¨
        self.nodes: Dict[str, TrajectoryNode] = {}
        self.root_id: Optional[str] = None
        
    def sample_trajectory_tree(self, seed_entity: str) -> Dict[str, TrajectoryNode]:
        """
        ä»seedå®ä½“å¼€å§‹é‡‡æ ·trajectory tree
        
        Args:
            seed_entity: èµ·å§‹å®ä½“ï¼ˆå¦‚äººåã€åœ°åã€æ¦‚å¿µç­‰ï¼‰
            
        Returns:
            å®Œæ•´çš„trajectory tree (node_id -> TrajectoryNode)
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹é‡‡æ · Trajectory Tree")
        print(f"Seedå®ä½“: {seed_entity}")
        print(f"æœ€å¤§æ·±åº¦: {self.max_depth}, åˆ†æ”¯å› å­: {self.branching_factor}")
        print(f"{'='*60}\n")
        
        # åˆ›å»ºæ ¹èŠ‚ç‚¹
        root_id = f"node_0_0"
        root_node = TrajectoryNode(
            node_id=root_id,
            observation=f"èµ·å§‹å®ä½“: {seed_entity}",
            intent="å¼€å§‹æ¢ç´¢å®ä½“ç›¸å…³ä¿¡æ¯",
            action=None,
            parent_id=None,
            depth=0
        )
        
        self.nodes[root_id] = root_node
        self.root_id = root_id
        
        # BFSæ‰©å±•tree
        self._expand_tree(root_id, seed_entity)
        
        print(f"\nâœ… Trajectory Treeé‡‡æ ·å®Œæˆ!")
        print(f"   æ€»èŠ‚ç‚¹æ•°: {len(self.nodes)}")
        print(f"   æœ€å¤§æ·±åº¦: {max(node.depth for node in self.nodes.values())}")
        
        return self.nodes
    
    def _expand_tree(self, node_id: str, seed_entity: str):
        """
        é€’å½’æ‰©å±•trajectory tree
        
        Args:
            node_id: å½“å‰èŠ‚ç‚¹ID
            seed_entity: åŸå§‹å®ä½“
        """
        current_node = self.nodes[node_id]
        
        # æ£€æŸ¥æ·±åº¦é™åˆ¶
        if current_node.depth >= self.max_depth:
            return
        
        print(f"\nğŸŒ³ æ‰©å±•èŠ‚ç‚¹ {node_id} (æ·±åº¦: {current_node.depth})")
        
        # æ ¹æ®æ·±åº¦åŠ¨æ€è°ƒæ•´åˆ†æ”¯å› å­
        if current_node.depth >= self.depth_threshold:
            current_branching_factor = 1
            print(f"   âš ï¸  æ·±åº¦ {current_node.depth} >= é˜ˆå€¼ {self.depth_threshold}ï¼Œåˆ†æ”¯å› å­é™ä¸º 1")
        else:
            current_branching_factor = self.branching_factor
        
        # å¯¹å½“å‰èŠ‚ç‚¹è¿›è¡Œbranching_factoræ¬¡é‡‡æ ·
        for branch_idx in range(current_branching_factor):
            try:
                # ç”Ÿæˆä¸‹ä¸€æ­¥çš„actionå’Œintent
                action, intent = self._generate_next_action(current_node, seed_entity)
                
                if action is None:
                    print(f"   åˆ†æ”¯ {branch_idx + 1}: æ— æ³•ç”Ÿæˆæœ‰æ•ˆåŠ¨ä½œï¼Œè·³è¿‡")
                    continue
                
                # æ‰§è¡Œactionè·å–observation
                observation = self._execute_action(action)

                
                # åˆ›å»ºæ–°èŠ‚ç‚¹
                child_id = f"node_{current_node.depth + 1}_{len(self.nodes)}"
                child_node = TrajectoryNode(
                    node_id=child_id,
                    observation=observation,
                    intent=intent,
                    action=action,
                    parent_id=node_id,
                    depth=current_node.depth + 1
                )
                
                self.nodes[child_id] = child_node
                current_node.children_ids.append(child_id)
                
                print(f"   âœ“ åˆ†æ”¯ {branch_idx + 1}: åˆ›å»ºèŠ‚ç‚¹ {child_id}")
                print(f"     Intent: {intent}")
                print(f"     Action: {action.get('tool_name', 'unknown')}")
                print(f"     Observation: {observation[:100]}...")
                
                # é€’å½’æ‰©å±•å­èŠ‚ç‚¹
                self._expand_tree(child_id, seed_entity)
                
            except Exception as e:
                if isinstance(e, bdb.BdbQuit):
                    raise e
                print(f"   âœ— åˆ†æ”¯ {branch_idx + 1} å¤±è´¥: {str(e)}")
                continue
    
    def _generate_next_action(self, 
                              current_node: TrajectoryNode, 
                              seed_entity: str) -> Tuple[Optional[Dict[str, Any]], str]:
        """
        åŸºäºå½“å‰çŠ¶æ€ç”Ÿæˆä¸‹ä¸€æ­¥çš„actionå’Œintent
        
        Args:
            current_node: å½“å‰èŠ‚ç‚¹
            seed_entity: åŸå§‹å®ä½“
            
        Returns:
            (action_dict, intent_string)
        """
        # æ„å»ºå†å²è½¨è¿¹
        history = self._build_history(current_node)
        
        # æ„å»ºprompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªWeb Agentï¼Œæ­£åœ¨æ¢ç´¢å…³äºå®ä½“"{seed_entity}"çš„ç›¸å…³ä¿¡æ¯ã€‚

ç›®æ ‡: å›´ç»•å®ä½“"{seed_entity}"æ”¶é›†**å…·ä½“çš„ã€å¯éªŒè¯çš„ã€å¤šç»´åº¦çš„ç‰¹å¾ä¿¡æ¯**ï¼Œç‰¹åˆ«å…³æ³¨èƒ½å¤Ÿæ”¯æŒ**multi-hopæ¨ç†**çš„å…³ç³»é“¾ä¿¡æ¯ï¼š

**å…³é”®ç‰¹å¾ç»´åº¦ï¼ˆä¼˜å…ˆæ”¶é›†å…³ç³»é“¾ä¿¡æ¯ï¼‰**:

**é«˜ä¼˜å…ˆçº§ - å…³ç³»é“¾ä¿¡æ¯ï¼ˆç”¨äºmulti-hopæ¨ç†ï¼‰**:
- äººç‰©å…³ç³»: åˆ›å§‹äººã€é¢†å¯¼è€…ã€æ ¸å¿ƒå›¢é˜Ÿæˆå‘˜åŠå…¶èƒŒæ™¯
  * è¿™äº›äººä¹‹å‰åˆ›ç«‹/å‚ä¸è¿‡ä»€ä¹ˆå…¶ä»–ç»„ç»‡ï¼Ÿ
  * ä»–ä»¬æœ‰ä»€ä¹ˆç‹¬ç‰¹çš„ç»å†æˆ–æˆå°±ï¼Ÿ
- ç»„ç»‡å…³ç³»: åˆä½œä¼™ä¼´ã€æŠ•èµ„æ–¹ã€æ¯å…¬å¸ã€å­å…¬å¸
  * ä¸å“ªäº›çŸ¥åç»„ç»‡æœ‰å…³è”ï¼Ÿ
  * è¿™äº›å…³è”æ˜¯å¦‚ä½•å½¢æˆçš„ï¼Ÿ
- æ—¶é—´å…³ç³»: å‰èº«ã€æ¼”å˜å†å²ã€é‡è¦è½¬æŠ˜ç‚¹
  * ä»ä»€ä¹ˆç»„ç»‡/æ¦‚å¿µæ¼”å˜è€Œæ¥ï¼Ÿ
  * ç»å†äº†å“ªäº›é‡å¤§å˜åŒ–ï¼Ÿ
- å› æœå…³ç³»: æˆç«‹/å‘å±•çš„åŸå› ã€å½±å“ã€è¡ç”Ÿæˆæœ
  * ä¸ºä»€ä¹ˆè¢«åˆ›ç«‹ï¼Ÿè§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ
  * äº§ç”Ÿäº†ä»€ä¹ˆé‡è¦å½±å“æˆ–è¡ç”Ÿå®ä½“ï¼Ÿ

**ä¸­ä¼˜å…ˆçº§ - å¯é‡åŒ–ç‰¹å¾**:
- æ—¶é—´ä¿¡æ¯: æˆç«‹/è¯ç”Ÿæ—¶é—´ã€é‡è¦æ—¶é—´èŠ‚ç‚¹ã€æ—¶æœŸèŒƒå›´
- åœ°ç†ä¿¡æ¯: ä½ç½®ã€æ€»éƒ¨ã€èµ·æºåœ°ï¼ˆåŒ…æ‹¬è¿™äº›åœ°ç‚¹çš„åˆ«ç§°/ç‰¹å¾ï¼‰
- è§„æ¨¡/æ•°é‡ä¿¡æ¯: è§„æ¨¡ã€æ•°é‡ã€å‘˜å·¥æ•°ã€äº§å“æ•°ç­‰å¯é‡åŒ–çš„æ•°æ®

**æ ‡å‡†ä¼˜å…ˆçº§ - æè¿°æ€§ç‰¹å¾**:
- äº§å“/ä½œå“: å…·ä½“çš„äº§å“ã€é¡¹ç›®ã€ä½œå“åç§°åŠå…¶ç‰¹ç‚¹
- ç‰¹å¾æè¿°: ç‹¬ç‰¹çš„ç‰¹ç‚¹ã€é£æ ¼ã€æ ‡å¿—æ€§å…ƒç´ 
- é¢†åŸŸ/ç±»åˆ«: æ‰€å±è¡Œä¸šã€é¢†åŸŸã€åˆ†ç±»

å½“å‰å†å²è½¨è¿¹:
{history}

å½“å‰è§‚å¯Ÿ:
{current_node.observation}

è¯·åŸºäºå½“å‰çŠ¶æ€å’Œå·²æ¢ç´¢çš„ä¿¡æ¯ï¼Œé€‰æ‹©ä¸€ä¸ª**å°šæœªå……åˆ†æ¢ç´¢çš„ç»´åº¦**ï¼Œç”Ÿæˆä¸‹ä¸€æ­¥çš„åŠ¨ä½œå’Œæ„å›¾ã€‚

**æ¢ç´¢ç­–ç•¥ï¼ˆæ”¯æŒmulti-hopæ¨ç†ï¼‰**:
- **ä¼˜å…ˆæ¢ç´¢å…³ç³»é“¾ä¿¡æ¯**: äººç‰©èƒŒæ™¯ã€ç»„ç»‡å…³è”ã€å‰èº«æ¼”å˜ã€å› æœè”ç³»
- å¯»æ‰¾å¯ä»¥å½¢æˆæ¨ç†é“¾çš„ä¿¡æ¯ï¼š
  * ä¾‹å¦‚ï¼šåˆ›å§‹äºº â†’ åˆ›å§‹äººçš„å…¶ä»–å…¬å¸ â†’ é‚£äº›å…¬å¸çš„ç‰¹å¾
  * ä¾‹å¦‚ï¼šæŠ•èµ„æ–¹ â†’ æŠ•èµ„æ–¹çš„ç‰¹ç‚¹ â†’ æŠ•èµ„ç­–ç•¥
  * ä¾‹å¦‚ï¼šäº§å“ â†’ äº§å“çš„ç”¨æˆ·è§„æ¨¡ â†’ å¢é•¿é€Ÿåº¦è®°å½•
- æ”¶é›†ä¸­é—´å®ä½“çš„ä¿¡æ¯ï¼ˆå¯ä½œä¸ºæ¨ç†æ¡¥æ¢ï¼‰
- é¿å…é‡å¤å·²æœ‰ä¿¡æ¯ï¼Œé€‰æ‹©æ–°çš„å…³ç³»è§’åº¦
- æ‰€æœ‰ä¿¡æ¯å¿…é¡»æ˜¯å…·ä½“çš„ã€å¯éªŒè¯çš„

å¯ç”¨å·¥å…·:
1. web_search: æœç´¢ç½‘ç»œä¿¡æ¯
   - å‚æ•°: queries (array of strings)
   - é€‚ç”¨äºï¼šè·å–æ¦‚è¿°ä¿¡æ¯ã€æŸ¥æ‰¾ç›¸å…³ç½‘é¡µé“¾æ¥ã€æœç´¢ç‰¹å®šç»´åº¦çš„ä¿¡æ¯
   
2. web_visit: è®¿é—®ç½‘é¡µå¹¶æå–å†…å®¹
   - å‚æ•°: urls (array of strings), goal (string)
   - é€‚ç”¨äºï¼šæ·±å…¥äº†è§£ç‰¹å®šç½‘é¡µçš„è¯¦ç»†å†…å®¹ã€æå–å…·ä½“æ•°æ®

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«:
1. intent: æ‰§è¡Œè¿™ä¸ªåŠ¨ä½œçš„æ„å›¾å’Œç†ç”±ï¼ˆè¯´æ˜æ¢ç´¢å“ªä¸ªç»´åº¦ï¼Œä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªç»´åº¦ï¼‰
2. action: åŠ¨ä½œè¯¦æƒ…
   - tool_name: å·¥å…·åç§° (web_search æˆ– web_visit)
   - parameters: å·¥å…·å‚æ•°

è¿”å›æ ¼å¼:
{{
    "intent": "æ„å›¾æè¿°",
    "action": {{
        "tool_name": "å·¥å…·åç§°",
        "parameters": {{å‚æ•°}}
    }}
}}
"""
        
        retry = 0
        while retry < self.max_retries:
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7 + retry * 0.1,  # é‡è¯•æ—¶å¢åŠ æ¸©åº¦
                    response_format={"type": "json_object"}
                )
                
                result = json.loads(response.choices[0].message.content)
                intent = result.get("intent", "")
                action = result.get("action", {})
                
                # éªŒè¯actionæ ¼å¼
                if self._validate_action(action):
                    return action, intent
                
                retry += 1
                
            except Exception as e:
                print(f"      è­¦å‘Š: ç”ŸæˆåŠ¨ä½œå¤±è´¥ (å°è¯• {retry + 1}): {str(e)}")
                retry += 1
        
        return None, ""
    
    def _validate_action(self, action: Dict[str, Any]) -> bool:
        """éªŒè¯actionæ ¼å¼æ˜¯å¦æ­£ç¡®"""
        if not isinstance(action, dict):
            return False
        
        tool_name = action.get("tool_name", "")
        parameters = action.get("parameters", {})
        
        if tool_name not in ["web_search", "web_visit"]:
            return False
        
        if tool_name == "web_search":
            return "queries" in parameters and isinstance(parameters["queries"], list)
        
        if tool_name == "web_visit":
            return ("urls" in parameters and isinstance(parameters["urls"], list) and
                    "goal" in parameters and isinstance(parameters["goal"], str))
        
        return False
    
    def _execute_action(self, action: Dict[str, Any]) -> str:
        """
        æ‰§è¡ŒåŠ¨ä½œå¹¶è¿”å›observation
        
        Args:
            action: åŠ¨ä½œå­—å…¸
            
        Returns:
            æ‰§è¡Œç»“æœ(observation)
        """
        tool_name = action["tool_name"]
        parameters = action["parameters"]
        
        try:
            result = self.environment.execute_tool(tool_name, parameters)
            return result
        except Exception as e:
            return f"[Error] æ‰§è¡ŒåŠ¨ä½œå¤±è´¥: {str(e)}"
    
    def _build_history(self, node: TrajectoryNode) -> str:
        """æ„å»ºä»æ ¹åˆ°å½“å‰èŠ‚ç‚¹çš„å†å²è½¨è¿¹"""
        path = []
        current = node
        
        while current.parent_id is not None:
            path.append(current)
            current = self.nodes[current.parent_id]
        
        path.reverse()
        
        if not path:
            return "æ— å†å²è½¨è¿¹"
        
        history_str = ""
        for i, n in enumerate(path, 1):
            history_str += f"\næ­¥éª¤ {i}:\n"
            history_str += f"  æ„å›¾: {n.intent}\n"
            if n.action:
                history_str += f"  åŠ¨ä½œ: {n.action.get('tool_name', 'unknown')}\n"
            history_str += f"  è§‚å¯Ÿ: {n.observation[:200]}...\n"
        
        return history_str


class TrajectorySelector:
    """
    Trajectoryé€‰æ‹©å™¨ï¼Œä»treeä¸­é€‰æ‹©é«˜è´¨é‡çš„é“¾è·¯
    """
    
    def __init__(self, 
                 model_name: str = "gpt-4.1-2025-04-14",
                 max_trajectories: int = 5,
                 min_depth: int = 2):
        """
        åˆå§‹åŒ–é€‰æ‹©å™¨
        
        Args:
            model_name: LLMæ¨¡å‹åç§°
            max_trajectories: æœ€å¤šé€‰æ‹©çš„trajectoryæ•°é‡
            min_depth: æœ€å°æ·±åº¦è¦æ±‚
        """
        self.model_name = model_name
        self.max_trajectories = max_trajectories
        self.min_depth = min_depth
        
        self.client = openai.OpenAI(
            api_key=os.environ.get("OPENAI_API_KEY", ""),
            base_url=os.environ.get("OPENAI_API_URL", os.environ.get("OPENAI_API_BASE", ""))
        )
    
    def select_trajectories(self, 
                           nodes: Dict[str, TrajectoryNode],
                           root_id: str,
                           seed_entity: str) -> List[Trajectory]:
        """
        ä»trajectory treeä¸­é€‰æ‹©é«˜è´¨é‡çš„å®Œæ•´é“¾è·¯
        
        Args:
            nodes: æ‰€æœ‰èŠ‚ç‚¹å­—å…¸
            root_id: æ ¹èŠ‚ç‚¹ID
            seed_entity: åŸå§‹å®ä½“
            
        Returns:
            é€‰æ‹©çš„trajectoryåˆ—è¡¨
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹é€‰æ‹© Trajectories")
        print(f"{'='*60}\n")
        
        # 1. æ‰¾åˆ°æ‰€æœ‰å¶å­èŠ‚ç‚¹
        leaf_nodes = [node for node in nodes.values() if not node.children_ids]
        print(f"æ‰¾åˆ° {len(leaf_nodes)} ä¸ªå¶å­èŠ‚ç‚¹")
        
        # 2. ç­›é€‰æ»¡è¶³æœ€å°æ·±åº¦çš„å¶å­èŠ‚ç‚¹
        valid_leaves = [node for node in leaf_nodes if node.depth >= self.min_depth]
        print(f"æ»¡è¶³æœ€å°æ·±åº¦({self.min_depth})çš„å¶å­èŠ‚ç‚¹: {len(valid_leaves)}")
        
        if not valid_leaves:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³æ·±åº¦è¦æ±‚çš„trajectory")
            return []
        
        # 3. ä»æ¯ä¸ªå¶å­èŠ‚ç‚¹å›æº¯åˆ°æ ¹èŠ‚ç‚¹ï¼Œæ„å»ºå®Œæ•´è·¯å¾„
        candidate_paths = []
        for leaf in valid_leaves:
            path = self._build_path_to_root(leaf, nodes, root_id)
            if path:
                candidate_paths.append(path)
        
        print(f"æ„å»ºäº† {len(candidate_paths)} æ¡å€™é€‰è·¯å¾„")
        
        # 4. è¯„åˆ†å¹¶é€‰æ‹©æœ€å¥½çš„trajectories
        selected = self._score_and_select(candidate_paths, seed_entity)
        
        print(f"\nâœ… é€‰æ‹©äº† {len(selected)} æ¡trajectories")
        
        return selected
    
    def _build_path_to_root(self, 
                           leaf: TrajectoryNode,
                           nodes: Dict[str, TrajectoryNode],
                           root_id: str) -> List[TrajectoryNode]:
        """ä»å¶å­èŠ‚ç‚¹å›æº¯åˆ°æ ¹èŠ‚ç‚¹"""
        path = []
        current = leaf
        
        while current.node_id != root_id:
            path.append(current)
            if current.parent_id is None:
                break
            current = nodes[current.parent_id]
        
        path.reverse()
        return path
    
    def _score_and_select(self, 
                         paths: List[List[TrajectoryNode]],
                         seed_entity: str) -> List[Trajectory]:
        """è¯„åˆ†å¹¶é€‰æ‹©æœ€å¥½çš„è·¯å¾„"""
        scored_paths = []
        
        for idx, path in enumerate(paths):
            score = self._score_path(path, seed_entity)
            scored_paths.append((score, idx, path))
        
        # æŒ‰åˆ†æ•°æ’åº
        scored_paths.sort(reverse=True, key=lambda x: x[0])
        
        # é€‰æ‹©top-k
        selected_trajectories = []
        for rank, (score, idx, path) in enumerate(scored_paths[:self.max_trajectories], 1):
            trajectory = Trajectory(
                trajectory_id=f"traj_{idx}",
                nodes=path,
                seed_entity=seed_entity,
                total_depth=len(path)
            )
            selected_trajectories.append(trajectory)
            print(f"  é€‰æ‹© Trajectory {rank}: æ·±åº¦={len(path)}, åˆ†æ•°={score:.2f}")
        
        return selected_trajectories
    
    def _score_path(self, path: List[TrajectoryNode], seed_entity: str) -> float:
        """
        ä¸ºè·¯å¾„æ‰“åˆ†
        
        è¯„åˆ†æ ‡å‡†:
        1. æ·±åº¦ (è¶Šæ·±è¶Šå¥½ï¼Œä½†æœ‰è¾¹é™…é€’å‡)
        2. ä¿¡æ¯é‡ (observationçš„å¹³å‡é•¿åº¦)
        3. å¤šæ ·æ€§ (ä½¿ç”¨ä¸åŒå·¥å…·)
        """
        # æ·±åº¦å¾—åˆ† (è¾¹é™…é€’å‡)
        depth_score = min(len(path) / 5.0, 1.0) * 40
        
        # ä¿¡æ¯é‡å¾—åˆ†
        avg_obs_length = sum(len(node.observation) for node in path) / len(path) if path else 0
        info_score = min(avg_obs_length / 1000, 1.0) * 30
        
        # å¤šæ ·æ€§å¾—åˆ†
        tool_names = set()
        for node in path:
            if node.action:
                tool_names.add(node.action.get("tool_name", ""))
        diversity_score = len(tool_names) / 2.0 * 30
        
        total_score = depth_score + info_score + diversity_score
        return total_score


class QASynthesizer:
    """
    QAåˆæˆå™¨ï¼ŒåŸºäºtrajectoryç”Ÿæˆé—®ç­”å¯¹
    """
    
    def __init__(self, model_name: str = "gpt-4.1-2025-04-14"):
        """åˆå§‹åŒ–QAåˆæˆå™¨"""
        self.model_name = model_name
        
        self.client = openai.OpenAI(
            api_key=os.environ.get("OPENAI_API_KEY", ""),
            base_url=os.environ.get("OPENAI_API_URL", os.environ.get("OPENAI_API_BASE", ""))
        )
    
    def synthesize_qa(self, trajectory: Trajectory) -> Optional[SynthesizedQA]:
        """
        åŸºäºtrajectoryåˆæˆé—®ç­”å¯¹
        
        Args:
            trajectory: é€‰ä¸­çš„trajectory
            
        Returns:
            åˆæˆçš„QAå¯¹
        """
        print(f"\nğŸ”§ åˆæˆQAå¯¹ - Trajectory: {trajectory.trajectory_id}")
        
        # æ„å»ºtrajectoryæè¿°
        traj_description = self._format_trajectory(trajectory)
        
        # ç”Ÿæˆé—®ç­”å¯¹
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆæˆä¸“å®¶ã€‚åŸºäºä»¥ä¸‹Web Agentå›´ç»•ç‰¹å®šå®ä½“çš„æ¢ç´¢è½¨è¿¹ï¼Œè¯·åˆæˆä¸€ä¸ªéœ€è¦**multi-hopæ¨ç†**çš„è°œé¢˜å¼é—®ç­”å¯¹ã€‚

æ¢ç´¢çš„æ ¸å¿ƒå®ä½“: {trajectory.seed_entity}

å®Œæ•´æ¢ç´¢è½¨è¿¹:
{traj_description}

è¯·åŸºäºè¿™æ¡å›´ç»•"{trajectory.seed_entity}"çš„æ¢ç´¢è½¨è¿¹åˆæˆä¸€ä¸ª**éœ€è¦multi-hopæ¨ç†çš„è°œé¢˜å¼é—®ç­”å¯¹**:

## 1. **é—®é¢˜(Question)è¦æ±‚ - Multi-hopæ¨ç†è®¾è®¡**:

### ä»€ä¹ˆæ˜¯Multi-hopæ¨ç†ï¼Ÿ
éœ€è¦é€šè¿‡**å¤šä¸ªé€»è¾‘è·³è·ƒ**æ‰èƒ½å¾—åˆ°ç­”æ¡ˆï¼Œæ¯ä¸€æ­¥éƒ½åŸºäºå‰ä¸€æ­¥çš„ç»“æœã€‚

### Multi-hopé—®é¢˜è®¾è®¡ç­–ç•¥ï¼š

**ç­–ç•¥A - å…³ç³»é“¾æ¨ç†**ï¼š
é€šè¿‡ä¸­é—´å®ä½“å»ºç«‹è¿æ¥
- ä¾‹å¦‚ï¼š"Please identify the organization co-founded by the entrepreneur who also founded Tesla and SpaceX, which released a viral AI chatbot in late 2022."
- æ¨ç†è·¯å¾„ï¼šæ‰¾åˆ°"founded Tesla and SpaceX"çš„äºº â†’ Elon Musk â†’ æ‰¾Elon Musk co-foundedçš„AIç»„ç»‡ â†’ OpenAI

**ç­–ç•¥B - å±æ€§æ¨ç†é“¾**ï¼š
é€šè¿‡å±æ€§ç»„åˆé€æ­¥ç¼©å°èŒƒå›´
- ä¾‹å¦‚ï¼š"What is the technology developed by the company located in the city known as the tech capital of the West Coast, founded by someone who previously led a startup accelerator?"
- æ¨ç†è·¯å¾„ï¼šWest Coast tech capital â†’ San Francisco â†’ startup accelerator leader â†’ Sam Altman â†’ Sam Altmanåˆ›ç«‹çš„å…¬å¸ â†’ OpenAI

**ç­–ç•¥C - æ—¶é—´åºåˆ—æ¨ç†**ï¼š
é€šè¿‡æ—¶é—´é¡ºåºçš„äº‹ä»¶é“¾
- ä¾‹å¦‚ï¼š"Please identify the entity that emerged from a non-profit founded in the mid-2010s, underwent a structural change to include a capped-profit model, and then launched a product that broke user growth records in early 2023."
- æ¨ç†è·¯å¾„ï¼šmid-2010séè¥åˆ© â†’ ç»“æ„è½¬å˜ â†’ capped-profit â†’ 2023çˆ†æ¬¾äº§å“ â†’ OpenAI

**ç­–ç•¥D - å› æœæ¨ç†é“¾**ï¼š
é€šè¿‡å› æœå…³ç³»è¿æ¥
- ä¾‹å¦‚ï¼š"What is the result of concerns about AI safety by tech leaders, which led to the founding of a research lab in San Francisco, that later developed the technology behind a chatbot used by millions?"
- æ¨ç†è·¯å¾„ï¼šAI safety concerns â†’ research labæˆç«‹ â†’ å¼€å‘æŠ€æœ¯ â†’ chatbot â†’ OpenAI

### é—®é¢˜å…·ä½“è¦æ±‚ï¼š
- **å¿…é¡»åŒ…å«è‡³å°‘2ä¸ªæ¨ç†è·³è·ƒï¼ˆhopï¼‰**
- ä¸è¦ç›´æ¥æåˆ°å®ä½“åç§°"{trajectory.seed_entity}"
- ä½¿ç”¨3-5ä¸ªç›¸äº’å…³è”çš„çº¦æŸæ¡ä»¶
- çº¦æŸæ¡ä»¶åº”è¯¥å½¢æˆé€»è¾‘é“¾ï¼Œä¸æ˜¯ç‹¬ç«‹çš„
- å°†å…·ä½“ä¿¡æ¯æ¨¡ç³ŠåŒ–ï¼š
  * æ—¶é—´ï¼š"2015å¹´" â†’ "mid-2010s"
  * äººåï¼š"Sam Altman" â†’ "a former president of Y Combinator"
  * åœ°ç‚¹ï¼š"San Francisco" â†’ "a major West Coast tech hub"
  * äº§å“ï¼š"ChatGPT" â†’ "a conversational AI that reached 100M users in record time"
- ä½¿ç”¨"Please identify..."ã€"What is..."æˆ–"Which [entity]..."å¼€å¤´

## 2. **ç­”æ¡ˆ(Answer)è¦æ±‚**:
   - **å¿…é¡»ç®€çŸ­**ï¼šåªå†™å®ä½“åç§°æœ¬èº«
   - ä¸è¦è§£é‡Šï¼Œä¸è¦é¢å¤–æè¿°
   - æ ¼å¼ï¼šç›´æ¥å†™å®ä½“åï¼ˆå¦‚ï¼š"OpenAI"ã€"Elon Musk"ã€"Quantum Computing"ï¼‰

## 3. **æ¨ç†æ­¥éª¤(Reasoning Steps)**:
   - æ˜ç¡®æ ‡æ³¨æ¯ä¸ªæ¨ç†è·³è·ƒï¼ˆhopï¼‰
   - æè¿°å¦‚ä½•ä»ä¸€ä¸ªçº¿ç´¢æ¨å¯¼åˆ°ä¸‹ä¸€ä¸ª
   - å±•ç¤ºå¤šæ­¥æ¢ç´¢å’ŒéªŒè¯çš„å®Œæ•´è¿‡ç¨‹

## Multi-hopç¤ºä¾‹ï¼š

**ç¤ºä¾‹1 - å…³ç³»é“¾ï¼ˆ2-hopï¼‰**:
Question: "Please identify the AI research organization co-founded by the entrepreneur who previously co-founded the online payment company that merged with Confinity, and which later released a conversational AI tool that gained over 100 million users within two months."
Answer: "OpenAI"
- Hop 1: online payment company merged with Confinity â†’ PayPal â†’ co-founder â†’ Elon Musk
- Hop 2: Elon Musk co-founded AI organization â†’ released chatbot with 100M users â†’ OpenAI

**ç¤ºä¾‹2 - å±æ€§é“¾ï¼ˆ3-hopï¼‰**:
Question: "What is the company founded in the city home to the Golden Gate Bridge, by someone who previously led a prominent startup accelerator, which developed the technology that powers a chat interface launched in late 2022?"
Answer: "OpenAI"
- Hop 1: Golden Gate Bridge city â†’ San Francisco
- Hop 2: led startup accelerator in SF â†’ Sam Altman
- Hop 3: Sam Altman founded company â†’ chat interface 2022 â†’ OpenAI

è¿”å›JSONæ ¼å¼:
{{
    "question": "Please identify/What is... [åŒ…å«multi-hopæ¨ç†é“¾çš„æè¿°]",
    "answer": "{trajectory.seed_entity}",
    "reasoning_steps": [
        {{
            "step": 1,
            "hop": "Hop 1: ä»çº¿ç´¢Aæ¨å¯¼åˆ°ä¸­é—´å®ä½“B",
            "intent": "æ­¥éª¤æ„å›¾",
            "action": "é‡‡å–çš„åŠ¨ä½œ",
            "observation": "è§‚å¯Ÿåˆ°çš„ä¿¡æ¯æ‘˜è¦"
        }},
        {{
            "step": 2,
            "hop": "Hop 2: ä»ä¸­é—´å®ä½“Bæ¨å¯¼åˆ°ç›®æ ‡ç­”æ¡ˆ",
            "intent": "æ­¥éª¤æ„å›¾",
            "action": "é‡‡å–çš„åŠ¨ä½œ",
            "observation": "è§‚å¯Ÿåˆ°çš„ä¿¡æ¯æ‘˜è¦"
        }},
        ...
    ]
}}

**å…³é”®è¦æ±‚**: 
- é—®é¢˜å¿…é¡»éœ€è¦è‡³å°‘2ä¸ªæ¨ç†è·³è·ƒï¼ˆä¸èƒ½ç›´æ¥æ¨å¯¼ï¼‰
- ç­”æ¡ˆå¿…é¡»ç®€çŸ­ï¼Œåªå†™å®ä½“åç§°
- æ¨ç†è·¯å¾„å¿…é¡»æ¸…æ™°ï¼Œæ¯ä¸ªhopéƒ½æœ‰æ˜ç¡®çš„é€»è¾‘
- æ‰€æœ‰ä¿¡æ¯å¿…é¡»åŸºäºè½¨è¿¹ä¸­çš„çœŸå®æ•°æ®
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            qa = SynthesizedQA(
                question=result.get("question", ""),
                answer=result.get("answer", ""),
                trajectory_id=trajectory.trajectory_id,
                reasoning_steps=result.get("reasoning_steps", []),
                metadata={
                    "seed_entity": trajectory.seed_entity,
                    "trajectory_depth": trajectory.total_depth,
                    "synthesis_date": datetime.now().isoformat()
                }
            )
            
            print(f"  âœ“ æˆåŠŸåˆæˆQAå¯¹")
            print(f"    é—®é¢˜: {qa.question[:100]}...")
            print(f"    ç­”æ¡ˆ: {qa.answer[:100]}...")
            
            return qa
            
        except Exception as e:
            print(f"  âœ— åˆæˆå¤±è´¥: {str(e)}")
            return None
    
    def _format_trajectory(self, trajectory: Trajectory) -> str:
        """æ ¼å¼åŒ–trajectoryä¸ºå¯è¯»æ–‡æœ¬"""
        formatted = ""
        
        for i, node in enumerate(trajectory.nodes, 1):
            formatted += f"\næ­¥éª¤ {i}:\n"
            formatted += f"  æ„å›¾: {node.intent}\n"
            
            if node.action:
                formatted += f"  åŠ¨ä½œ: {node.action.get('tool_name', 'unknown')}\n"
                formatted += f"  å‚æ•°: {json.dumps(node.action.get('parameters', {}), ensure_ascii=False)}\n"
            
            obs_preview = node.observation[:500] + "..." if len(node.observation) > 500 else node.observation
            formatted += f"  è§‚å¯Ÿ: {obs_preview}\n"
        
        return formatted


class WebAgentDataSynthesis:
    """
    Web Agentæ•°æ®åˆæˆä¸»ç±»
    
    æ•´åˆä¸‰ä¸ªæ­¥éª¤:
    1. Trajectory Sampling
    2. Trajectory Selection
    3. QA Synthesis
    """
    
    def __init__(self,
                 model_name: str = "gpt-4.1-2025-04-14",
                 max_depth: int = 5,
                 branching_factor: int = 2,
                 max_trajectories: int = 5,
                 min_depth: int = 2,
                 depth_threshold: int = 3,
                 **env_kwargs):
        """
        åˆå§‹åŒ–æ•°æ®åˆæˆç³»ç»Ÿ
        
        Args:
            model_name: LLMæ¨¡å‹åç§°
            max_depth: Trajectoryæœ€å¤§æ·±åº¦
            branching_factor: æ¯ä¸ªèŠ‚ç‚¹çš„åˆ†æ”¯å› å­
            max_trajectories: æœ€å¤šé€‰æ‹©çš„trajectoryæ•°é‡
            min_depth: Trajectoryæœ€å°æ·±åº¦
            depth_threshold: æ·±åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤æ·±åº¦æ—¶branching_factoré™ä¸º1
            **env_kwargs: WebEnvironmentçš„é¢å¤–é…ç½®
        """
        self.model_name = model_name
        
        # åˆ›å»ºWebç¯å¢ƒ
        print("åˆå§‹åŒ– Web Environment...")
        self.environment = WebEnvironment(model_name=model_name, **env_kwargs)
        
        # åˆ›å»ºä¸‰ä¸ªç»„ä»¶
        self.sampler = TrajectorySampler(
            environment=self.environment,
            model_name=model_name,
            max_depth=max_depth,
            branching_factor=branching_factor,
            depth_threshold=depth_threshold
        )
        
        self.selector = TrajectorySelector(
            model_name=model_name,
            max_trajectories=max_trajectories,
            min_depth=min_depth
        )
        
        self.synthesizer = QASynthesizer(model_name=model_name)
        
        # å­˜å‚¨ç»“æœ
        self.trajectory_tree: Dict[str, TrajectoryNode] = {}
        self.selected_trajectories: List[Trajectory] = []
        self.synthesized_qas: List[SynthesizedQA] = []
    
    def run(self, seed_entities: List[str]) -> List[SynthesizedQA]:
        """
        è¿è¡Œå®Œæ•´çš„æ•°æ®åˆæˆpipeline
        
        Args:
            seed_entities: Seedå®ä½“åˆ—è¡¨
            
        Returns:
            åˆæˆçš„QAå¯¹åˆ—è¡¨
        """
        print(f"\n{'='*80}")
        print(f"ğŸš€ Web Agent æ•°æ®åˆæˆ Pipeline å¯åŠ¨")
        print(f"{'='*80}")
        print(f"æ€»Seedå®ä½“æ•°: {len(seed_entities)}")
        print(f"æ¨¡å‹: {self.model_name}")
        print(f"{'='*80}\n")
        
        all_qas = []
        
        for entity_idx, seed_entity in enumerate(seed_entities, 1):
            print(f"\n\n{'#'*80}")
            print(f"å¤„ç† Seed å®ä½“ {entity_idx}/{len(seed_entities)}: {seed_entity}")
            print(f"{'#'*80}\n")
            
            try:
                # Step 1: Trajectory Sampling
                print(f"\nğŸ“Š æ­¥éª¤ 1/3: Trajectory Sampling")
                self.trajectory_tree = self.sampler.sample_trajectory_tree(seed_entity)

                
                # Step 2: Trajectory Selection
                print(f"\nğŸ¯ æ­¥éª¤ 2/3: Trajectory Selection")
                self.selected_trajectories = self.selector.select_trajectories(
                    nodes=self.trajectory_tree,
                    root_id=self.sampler.root_id,
                    seed_entity=seed_entity
                )
                
                # Step 3: QA Synthesis
                print(f"\nâœ¨ æ­¥éª¤ 3/3: QA Synthesis")
                for trajectory in self.selected_trajectories:
                    qa = self.synthesizer.synthesize_qa(trajectory)
                    if qa:
                        all_qas.append(qa)
                        self.synthesized_qas.append(qa)
                
                print(f"\nâœ… Seedå®ä½“ {entity_idx} å®Œæˆ! ç”Ÿæˆäº† {len(self.selected_trajectories)} ä¸ªQAå¯¹")
                
            except Exception as e:
                if isinstance(e, bdb.BdbQuit):
                    raise e
                print(f"\nâŒ Seedå®ä½“ {entity_idx} å¤±è´¥: {str(e)}")
                continue
        
        print(f"\n\n{'='*80}")
        print(f"ğŸ‰ æ•°æ®åˆæˆå®Œæˆ!")
        print(f"{'='*80}")
        print(f"æ€»å…±å¤„ç†: {len(seed_entities)} ä¸ªSeedå®ä½“")
        print(f"æˆåŠŸç”Ÿæˆ: {len(all_qas)} ä¸ªQAå¯¹")
        print(f"{'='*80}\n")
        
        return all_qas
    
    def save_results(self, output_dir: str = "synthesis_results"):
        """
        ä¿å­˜æ‰€æœ‰ç»“æœ
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜QAå¯¹
        qa_file = os.path.join(output_dir, f"synthesized_qa_{timestamp}.jsonl")
        with open(qa_file, "w", encoding="utf-8") as f:
            for qa in self.synthesized_qas:
                f.write(json.dumps(qa.to_dict(), ensure_ascii=False) + "\n")
        
        print(f"ğŸ’¾ QAå¯¹å·²ä¿å­˜åˆ°: {qa_file}")
        
        # ä¿å­˜trajectories
        traj_file = os.path.join(output_dir, f"trajectories_{timestamp}.json")
        with open(traj_file, "w", encoding="utf-8") as f:
            trajectories_data = [traj.to_dict() for traj in self.selected_trajectories]
            json.dump(trajectories_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ Trajectorieså·²ä¿å­˜åˆ°: {traj_file}")
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_file = os.path.join(output_dir, f"statistics_{timestamp}.json")
        stats = {
            "total_qas": len(self.synthesized_qas),
            "total_trajectories": len(self.selected_trajectories),
            "total_nodes": len(self.trajectory_tree),
            "avg_trajectory_depth": sum(t.total_depth for t in self.selected_trajectories) / len(self.selected_trajectories) if self.selected_trajectories else 0,
            "model_name": self.model_name,
            "timestamp": timestamp
        }
        
        with open(stats_file, "w", encoding="utf-8") as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ•°æ®åˆæˆç³»ç»Ÿ"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Web Agent æ•°æ®åˆæˆç³»ç»Ÿ")
    
    parser.add_argument("--seed-entities", type=str, required=True,
                       help="Seedå®ä½“JSONæ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«å®ä½“åˆ—è¡¨")
    parser.add_argument("--model", type=str, default="gpt-4.1-2025-04-14",
                       help="LLMæ¨¡å‹åç§°")
    parser.add_argument("--max-depth", type=int, default=5,
                       help="Trajectoryæœ€å¤§æ·±åº¦")
    parser.add_argument("--branching-factor", type=int, default=2,
                       help="æ¯ä¸ªèŠ‚ç‚¹çš„åˆ†æ”¯å› å­")
    parser.add_argument("--max-trajectories", type=int, default=5,
                       help="æ¯ä¸ªseedå®ä½“æœ€å¤šé€‰æ‹©çš„trajectoryæ•°é‡")
    parser.add_argument("--min-depth", type=int, default=2,
                       help="Trajectoryæœ€å°æ·±åº¦")
    parser.add_argument("--depth-threshold", type=int, default=3,
                       help="æ·±åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤æ·±åº¦æ—¶branching_factoré™ä¸º1")
    parser.add_argument("--output-dir", type=str, default="synthesis_results",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--web-search-top-k", type=int, default=3,
                       help="Webæœç´¢è¿”å›ç»“æœæ•°")
    
    args = parser.parse_args()
    
    # è¯»å–seedå®ä½“
    print(f"è¯»å– seed å®ä½“æ–‡ä»¶: {args.seed_entities}")
    with open(args.seed_entities, "r", encoding="utf-8") as f:
        data = json.load(f)
        if isinstance(data, list):
            seed_entities = data
        elif isinstance(data, dict) and "entities" in data:
            seed_entities = data["entities"]
        else:
            raise ValueError("Seedå®ä½“æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºå®ä½“åˆ—è¡¨æˆ–åŒ…å«'entities'å­—æ®µçš„å­—å…¸")
    
    print(f"åŠ è½½äº† {len(seed_entities)} ä¸ªseedå®ä½“")
    
    # åˆ›å»ºæ•°æ®åˆæˆç³»ç»Ÿ
    synthesizer = WebAgentDataSynthesis(
        model_name=args.model,
        max_depth=args.max_depth,
        branching_factor=args.branching_factor,
        max_trajectories=args.max_trajectories,
        min_depth=args.min_depth,
        depth_threshold=args.depth_threshold,
        web_search_top_k=args.web_search_top_k
    )
    
    # è¿è¡Œåˆæˆpipeline
    qas = synthesizer.run(seed_entities)
    
    # ä¿å­˜ç»“æœ
    synthesizer.save_results(output_dir=args.output_dir)
    
    print(f"\nâœ… å…¨éƒ¨å®Œæˆ! å…±ç”Ÿæˆ {len(qas)} ä¸ªQAå¯¹")


if __name__ == "__main__":
    main()


# AgentFlow 代码架构分析与新环境/Benchmark开发指南

## 一、整体架构概述

[run_osworld.py](../src/run_osworld.py) 文件是 AgentFlow 的主执行脚本,采用了**模块化、可扩展的架构设计**,主要包含以下核心组件:

### 1.1 核心类结构

```
AgentRunner (主控制器)
    ├── Environment (环境抽象层)
    │   ├── MathEnvironment
    │   ├── PythonEnvironment
    │   ├── RAGEnvironment
    │   ├── WebEnvironment
    │   └── OSWorldEnvironment
    ├── Benchmark (数据集抽象层)
    └── Tool (工具抽象层)
```

### 1.2 执行流程

```
1. 初始化阶段 (main → AgentRunner.__init__)
   - 加载配置 (AgentConfig)
   - 验证 OpenAI API 配置

2. 环境设置 (setup_environment)
   - 根据 mode 选择环境类
   - 初始化工具集 (_initialize_tools)
   - 生成工具元数据 (schemas + descriptions)

3. 基准加载 (load_benchmark)
   - 从 JSON/JSONL 加载数据
   - 解析任务项 (BenchmarkItem)

4. 任务执行循环 (run_benchmark → run_single_task)
   - 环境启动 (env_start)
   - 对每个任务:
     a. 初始化 (env_task_init) → 获取初始观察
     b. 执行对话 (_run_conversation)
        - 构建系统提示词
        - 多轮工具调用
        - 收集轨迹数据
     c. 提取最终答案
     d. 评估 (evaluate)
     e. 保存轨迹 (env_task_end)
   - 环境关闭 (env_close)

5. 结果评估与保存
   - 使用 Benchmark.evaluate() 评估
   - 保存结果到 JSONL
```

---

## 二、Environment 类设计详解

### 2.1 Environment 抽象基类 ([envs/enviroment.py](../src/envs/enviroment.py))

**核心职责**:
- **工具管理**: 注册、卸载、执行工具
- **配置管理**: API密钥、模型设置等
- **提示词生成**: 根据模式和动作空间生成系统提示词
- **任务生命周期**: 初始化、执行、评估、清理

**关键方法**:

| 方法 | 用途 | 是否必须重写 |
|------|------|------------|
| `mode` (property) | 返回环境模式名 | ✅ 必须 |
| `_initialize_tools()` | 初始化工具集 | ✅ 必须 |
| `get_action_space()` | 返回动作空间 (可选) | ❌ 可选 |
| `get_system_prompt(question)` | 生成系统提示词 | ❌ 可选 |
| `_replace_prompt_placeholders(prompt)` | 替换提示词占位符 | ❌ 可选 |
| `env_task_init(task)` | 任务初始化,返回初始观察 | ❌ 可选 |
| `env_task_end(task_id, output_dir, final_answer)` | 任务结束,保存轨迹 | ❌ 可选 |
| `format_initial_observation_for_message(obs)` | 格式化初始观察 | ❌ 可选 |
| `env_start()` | 环境启动 (全局初始化) | ❌ 可选 |
| `env_close()` | 环境关闭 (全局清理) | ❌ 可选 |
| `has_internal_evaluation()` | 是否有内部评估器 | ❌ 可选 |
| `get_task_output_dir(...)` | 获取任务输出目录 | ❌ 可选 |

### 2.2 简单环境示例: MathEnvironment

```python
class MathEnvironment(Environment):
    @property
    def mode(self) -> str:
        return "math"

    def _initialize_tools(self):
        self.register_tool(CalculatorTool())
```

**特点**: 只需实现 `mode` 和 `_initialize_tools`,其余使用默认实现。

### 2.3 复杂环境示例: OSWorldEnvironment

**额外实现的方法**:
- `get_action_space()`: 返回 "computer_13" 或 "pyautogui"
- `_replace_prompt_placeholders()`: 替换 `{CLIENT_PASSWORD}` 占位符
- `env_task_init(task)`:
  - 重置虚拟机到快照
  - 开始录屏
  - 返回初始截图和可访问性树
- `env_task_end()`:
  - 停止录屏并保存视频
  - 运行评估器获取分数
  - 保存轨迹数据
- `format_initial_observation_for_message()`: 将截图(base64)和文本转为 OpenAI 消息格式
- `has_internal_evaluation()`: 返回 `True` (使用环境评估器而非 LLM 输出)
- `get_task_output_dir()`: 创建每个任务的专属目录

---

## 三、Benchmark 类设计详解

### 3.1 Benchmark 抽象基类 ([benchmark/benchmark.py](../src/benchmark/benchmark.py))

**核心职责**:
- 数据加载 (JSON/JSONL)
- 解析任务项
- 评估预测结果
- 计算评估指标

**关键数据结构**:

```python
@dataclass
class BenchmarkItem:
    id: str                        # 任务ID
    question: str                  # 任务问题
    answer: str                    # 标准答案
    metadata: Optional[Dict]       # 额外元数据 (OSWorld的config/evaluator等)

@dataclass
class EvaluationResult:
    item_id: str
    question: str
    ground_truth: str
    prediction: str
    score: float
    metric_name: str
    details: Optional[Dict]
```

### 3.2 关键方法

| 方法 | 用途 | 是否必须重写 |
|------|------|------------|
| `load_data(data_path)` | 加载数据 | ❌ 默认支持JSON/JSONL |
| `_parse_item(data, line_num)` | 解析单个数据项 | ❌ 可选重写 (默认解析id/question/answer) |
| `evaluate(predictions, metric)` | 评估预测结果 | ❌ 已实现多种指标 |
| `_compute_metric(gt, pred, metric)` | 计算单个指标 | ❌ 可选新增指标 |

### 3.3 支持的评估指标

- `exact_match`: 精确匹配
- `f1_score`: 基于词重叠的F1分数
- `similarity`: 字符串相似度 (difflib)
- `contains_answer`: 包含答案检查
- `numeric_match`: 数值匹配
- `llm_judgement`: LLM 判断

---

## 四、新环境开发指南

### 4.1 开发步骤

#### 步骤1: 创建环境类文件

在 `src/envs/` 目录下创建新文件,如 `my_new_environment.py`:

```python
# -*- coding: utf-8 -*-
"""
My New Environment - 环境描述
"""
import os
import sys
from typing import Dict, Any, Optional, List

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from envs.enviroment import Environment
from envs.data_models import Observation
from tools import MyCustomTool  # 导入自定义工具

class MyNewEnvironment(Environment):
    """新环境的详细描述"""

    def __init__(self, **kwargs):
        """
        初始化环境

        Args:
            **kwargs: 配置参数,例如:
                - api_key: API密钥
                - custom_param: 自定义参数
        """
        # 1. 初始化环境专属资源 (在super().__init__之前)
        self._my_resource = None

        # 2. 调用父类初始化 (会自动调用_initialize_tools)
        super().__init__(**kwargs)

    @property
    def mode(self) -> str:
        """返回环境模式名 (必须实现)"""
        return "my_new_env"

    def _initialize_tools(self):
        """初始化工具集 (必须实现)"""
        # 注册工具
        self.register_tool(MyCustomTool(
            config=self.config  # 传递配置
        ))

        # 可以注册多个工具
        # self.register_tool(AnotherTool())
```

#### 步骤2: 可选 - 实现高级功能

**2.1 如果需要初始观察 (如OSWorld的截图)**:

```python
def env_task_init(self, task: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """
    任务初始化,返回初始观察

    Args:
        task: 任务字典,包含 'id', 'question', 'metadata'

    Returns:
        初始观察字典: {'text': str, 'image': base64_str}
        或 None (如果不需要初始观察)
    """
    # 1. 重置环境状态
    self._reset_environment(task)

    # 2. 获取初始状态
    screenshot = self._capture_screenshot()  # 假设方法
    state_text = self._get_state_text()      # 假设方法

    # 3. 返回标准格式
    return {
        'text': state_text,
        'image': self._encode_to_base64(screenshot)
    }

def format_initial_observation_for_message(
    self,
    initial_obs: Optional[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """
    格式化初始观察为 OpenAI 消息格式

    Returns:
        [
            {"type": "text", "text": "..."},
            {"type": "image_url", "image_url": {"url": "data:image/png;base64,...", ...}}
        ]
    """
    if not initial_obs:
        return []

    content_parts = []

    # 添加文本观察
    if initial_obs.get('text'):
        content_parts.append({
            "type": "text",
            "text": f"Initial state:\n{initial_obs['text']}"
        })

    # 添加图像观察
    if initial_obs.get('image'):
        content_parts.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/png;base64,{initial_obs['image']}",
                "detail": "high"
            }
        })

    return content_parts
```

**2.2 如果有内部评估器 (如OSWorld的evaluator)**:

```python
def has_internal_evaluation(self) -> bool:
    """标记此环境有内部评估能力"""
    return True

def evaluate(self) -> float:
    """
    运行内部评估器 (必须实现此方法!)

    ⚠️ 重要提示:
    - Environment 基类中没有定义 evaluate() 方法
    - 如果 has_internal_evaluation() 返回 True, 必须实现此方法
    - run_osworld.py 会调用 self.environment.evaluate()

    Returns:
        评估分数 (0.0 到 1.0)

    Example (OSWorld 实现):
        def evaluate(self) -> float:
            if not self._desktop_env:
                raise ValueError("DesktopEnv not initialized")
            score = self._desktop_env.evaluate()
            return float(score)
    """
    # 运行你的评估逻辑
    score = self._run_evaluator()
    return score

def env_task_end(
    self,
    task_id: str,
    task_output_dir: Optional[str] = None,
    final_answer: Optional[str] = None
) -> Optional[Dict[str, Any]]:
    """
    任务结束处理

    ⚠️ 注意:
    - 不需要在这里调用 evaluate()
    - run_osworld.py 会在 finally 块中自动调用
    - 这里只需要做清理工作 (如停止录屏、保存轨迹等)

    Returns:
        可选返回值 (通常为 None 即可)
    """
    # 停止录屏、保存轨迹等清理工作
    if task_output_dir:
        self._save_recordings(task_output_dir)

    return None  # 返回 None 即可,评估由 run_osworld.py 处理
```

**2.3 如果需要自定义提示词**:

```python
def _replace_prompt_placeholders(self, prompt: str) -> str:
    """
    替换环境特定的占位符

    Args:
        prompt: 包含占位符的提示词模板

    Returns:
        替换后的提示词
    """
    # 替换自定义占位符
    if "{MY_API_KEY}" in prompt:
        api_key = self.config.get("my_api_key", "")
        prompt = prompt.replace("{MY_API_KEY}", api_key)

    return prompt
```

**2.4 如果需要环境级别的启动/关闭**:

```python
def env_start(self) -> None:
    """
    环境启动 (在所有任务执行前调用一次)
    用于初始化全局资源 (如虚拟机、数据库连接等)
    """
    print("Initializing global resources...")
    self._my_resource = self._create_resource()

def env_close(self) -> None:
    """
    环境关闭 (在所有任务执行后调用一次)
    用于清理全局资源
    """
    print("Cleaning up global resources...")
    if self._my_resource:
        self._my_resource.close()
        self._my_resource = None
```

#### 步骤3: 注册环境到主脚本

修改 `src/run_osworld.py`:

```python
# 1. 添加导入
from envs.my_new_environment import MyNewEnvironment

# 2. 在 setup_environment 方法中添加分支 (约第101-128行)
def setup_environment(self, mode: str, **kwargs) -> Environment:
    if mode == "my_new_env":
        self.environment = MyNewEnvironment(**kwargs)
    # ... 其他环境 ...
```

#### 步骤4: 添加命令行参数 (可选)

修改 `src/run_osworld.py` 的 `main()` 函数 (约第960-1028行):

```python
# 1. 添加 mode 选项
parser.add_argument("--mode", type=str,
                   choices=["math", "py", "rag", "web", "osworld", "my_new_env"],
                   required=True)

# 2. 添加环境专属参数
parser.add_argument("--my-custom-param", type=str,
                   help="自定义参数描述")

# 3. 在 env_kwargs 中添加参数传递
elif args.mode == "my_new_env":
    env_kwargs.update({
        "my_custom_param": args.my_custom_param,
    })
```

### 4.2 简单环境 vs 复杂环境

**简单环境 (如 Math/RAG)**:
- 只需重写 `mode` 和 `_initialize_tools`
- 使用默认的任务流程 (无初始观察,LLM输出作为答案)

**复杂环境 (如 OSWorld)**:
- 需要初始观察: 重写 `env_task_init` + `format_initial_observation_for_message`
- 需要内部评估: 重写 `has_internal_evaluation` + `evaluate` + `env_task_end`
- 需要全局资源: 重写 `env_start` + `env_close`
- 需要任务目录: 重写 `get_task_output_dir`

---

## 五、新 Benchmark 开发指南

### 5.1 使用默认 Benchmark 类

**如果你的数据格式符合标准**:

```json
// JSONL 格式 (每行一个JSON对象)
{"id": "task_1", "question": "...", "answer": "..."}
{"id": "task_2", "question": "...", "answer": "..."}

// 或 JSON 格式
[
  {"id": "task_1", "question": "...", "answer": "..."},
  {"id": "task_2", "question": "...", "answer": "..."}
]
```

**直接使用**:

```python
benchmark = create_benchmark(
    data_path="path/to/your/data.jsonl",
    name="My Benchmark",
    description="Description"
)
```

### 5.2 自定义数据解析

**如果数据格式不标准,重写 `_parse_item`**:

```python
from benchmark import Benchmark, BenchmarkItem

class MyCustomBenchmark(Benchmark):
    def _parse_item(self, data: Dict[str, Any], line_num: int) -> BenchmarkItem:
        """
        自定义数据解析逻辑

        Args:
            data: 原始数据字典
            line_num: 行号 (用于错误提示)

        Returns:
            BenchmarkItem 对象
        """
        # 1. 提取必需字段
        item_id = data.get('custom_id_field', f'item_{line_num}')
        question = data.get('task_description', '')
        answer = data.get('ground_truth', '')

        # 2. 提取元数据 (除了id/question/answer的所有字段)
        metadata = {
            k: v for k, v in data.items()
            if k not in ['custom_id_field', 'task_description', 'ground_truth']
        }

        # 3. 返回 BenchmarkItem
        return BenchmarkItem(
            id=item_id,
            question=question,
            answer=answer,
            metadata=metadata
        )
```

### 5.3 自定义评估指标

**添加新的评估指标**:

```python
class MyCustomBenchmark(Benchmark):
    def _get_metric_function(self, metric: str):
        """添加自定义指标"""
        # 1. 先尝试父类指标
        if metric in ['exact_match', 'f1_score', ...]:
            return super()._get_metric_function(metric)

        # 2. 添加自定义指标
        custom_metrics = {
            'my_custom_metric': self._my_custom_metric,
        }

        if metric not in custom_metrics:
            raise ValueError(f"Unknown metric: {metric}")

        return custom_metrics[metric]

    def _my_custom_metric(self, ground_truth: str, prediction: str, **kwargs) -> float:
        """
        自定义评估逻辑

        Returns:
            分数 (0.0 到 1.0)
        """
        # 实现你的评估逻辑
        score = ...
        return score
```

### 5.4 OSWorld 特殊情况

**OSWorld 的特殊性**:
1. **评估在环境中完成**: `OSWorldEnvironment.evaluate()` 返回分数
2. **分数作为答案**: `env_task_end` 返回 `{"answer": str(score)}`
3. **Benchmark 接收分数**: `predictions[task_id] = str(score)`
4. **最终评估**: Benchmark 使用 `exact_match` 比较分数字符串

**数据格式示例** (OSWorld):

```json
{
  "id": "task_123",
  "question": "Open Firefox and navigate to...",
  "answer": "",
  "metadata": {
    "config": {"vm_path": "...", "snapshot": "..."},
    "evaluator": {"func": "check_url", "expected": "..."}
  }
}
```

---

## 六、工具 (Tool) 开发指南

### 6.1 Tool 抽象基类

所有工具必须继承 `Tool` 类并实现以下方法:

```python
from envs.enviroment import Tool
from typing import List, Dict, Any, Union
import json

class MyCustomTool(Tool):
    """工具描述"""

    def __init__(self, **kwargs):
        """
        初始化工具

        Args:
            **kwargs: 配置参数
        """
        self.config = kwargs

    @property
    def name(self) -> str:
        """工具名称 (必须实现)"""
        return "my_custom_tool"

    @property
    def description(self) -> str:
        """工具描述 (必须实现)"""
        return "This tool does something useful"

    @property
    def parameters(self) -> List[Dict[str, Any]]:
        """
        工具参数 schema (必须实现)

        Returns:
            参数列表,每个参数包含:
            - name: 参数名
            - type: 参数类型 ('string', 'number', 'boolean', 'array', 'object')
            - description: 参数描述
            - required: 是否必需
            - array_type: 如果type='array',指定元素类型
        """
        return [
            {
                "name": "input_text",
                "type": "string",
                "description": "输入文本",
                "required": True
            },
            {
                "name": "options",
                "type": "array",
                "array_type": "string",
                "description": "选项列表",
                "required": False
            }
        ]

    def call(self, params: Union[str, dict], **kwargs) -> str:
        """
        执行工具 (必须实现)

        Args:
            params: 参数字典或JSON字符串
            **kwargs: 额外参数

        Returns:
            JSON字符串,格式: {"status": "success", "response": "...", "observation": {...}}
        """
        # 1. 解析参数
        if isinstance(params, str):
            params = json.loads(params)

        # 2. 执行逻辑
        try:
            result = self._execute_logic(params)

            # 3. 返回标准格式
            return json.dumps({
                "status": "success",
                "response": result,
                "observation": {}  # 可选: 如果有观察数据 (如截图)
            })
        except Exception as e:
            return json.dumps({
                "status": "error",
                "response": str(e),
                "observation": {}
            })

    def _execute_logic(self, params: dict) -> str:
        """实际执行逻辑"""
        input_text = params.get("input_text", "")
        options = params.get("options", [])

        # 你的业务逻辑
        result = f"Processed: {input_text}"
        return result
```

### 6.2 Tool 返回格式

**标准返回格式** (JSON字符串):

```json
{
  "status": "success" | "error",
  "response": "执行结果文本",
  "observation": {
    "text": "可访问性树或状态文本",
    "image": "base64编码的截图"
  }
}
```

**observation 的处理流程**:
1. Tool 返回 observation 字典
2. `_run_conversation` 解析并转换为 `Observation` 对象
3. 添加到 `TrajectoryStep.observations` 列表
4. 格式化为 OpenAI 消息格式添加到对话历史

---

## 七、轨迹数据模型

### 7.1 数据模型定义 ([envs/data_models.py](../src/envs/data_models.py))

```python
@dataclass
class Observation:
    """单个观察 (文本或图像)"""
    type: str                    # "text" 或 "image"
    content: Union[str, bytes]   # 内容
    timestamp: str               # 时间戳
    metadata: Dict[str, Any]     # 元数据 (如图片路径、尺寸等)

@dataclass
class TrajectoryStep:
    """单步轨迹"""
    step_id: int                 # 步骤编号
    action: str                  # 工具名称
    action_input: Dict[str, Any] # 工具参数
    observations: List[Observation]  # 观察列表
    thought: str                 # LLM 思考过程
    result: str                  # 执行结果
    status: str                  # "success" 或 "error"
    timestamp: str               # 时间戳

@dataclass
class TaskTrajectory:
    """任务完整轨迹"""
    task_id: str
    question: str
    steps: List[TrajectoryStep]  # 步骤列表
    final_answer: str            # 最终答案
    success: bool                # 是否成功
    total_steps: int             # 总步数
    start_time: str              # 开始时间
    end_time: str                # 结束时间
    metadata: Dict[str, Any]     # 元数据 (如token数、耗时等)
```

### 7.2 轨迹保存

**保存的文件**:
1. `trajectory.json`: 简化的动作轨迹 (用于分析)
2. `conversation.json`: 完整的LLM对话历史
3. `trajectory.txt`: 人类可读的摘要

---

## 八、run_single_task 返回值详解

### 8.1 无内部评估环境 (Math/RAG/Web)

**成功情况**:
```python
result = {
    "task_id": "task_001",
    "question": "What is 2+2?",
    "answer": "The answer is 4.",  # ⭐ LLM的最终文本回答
    "messages": [...],              # 完整对话历史
    "success": True,
    "error": None
}
```

**答案提取逻辑**:
- 从对话历史中找到**最后一个没有工具调用的 assistant 消息**
- 返回该消息的 `content` 字段

**失败情况**:
```python
result = {
    "task_id": "task_001",
    "question": "What is 2+2?",
    "answer": "",                   # ⭐ 空字符串
    "messages": [],
    "success": False,
    "error": "Exception message"
}
```

### 8.2 有内部评估环境 (OSWorld)

**成功情况**:
```python
result = {
    "task_id": "task_123",
    "question": "Open Firefox...",
    "answer": "0.85",               # ⭐ 环境评估分数的字符串
    "evaluation_score": 0.85,       # 数值分数
    "messages": [...],
    "success": True,
    "error": None
}
```

**评估流程** (在 finally 块中):
1. 检查 `has_internal_evaluation()` 返回 `True`
2. 调用 `environment.evaluate()` 获取分数
3. **覆盖** `result["answer"]` 为分数字符串
4. 添加 `result["evaluation_score"]` 字段

### 8.3 对比表

| 字段 | 无内部评估 | 有内部评估 |
|------|-----------|-----------|
| `"answer"` | LLM 最终回答文本 | 评估分数字符串 (如 `"0.85"`) |
| `"evaluation_score"` | 不存在 | 数值分数 (如 `0.85`) |
| 评估方式 | Benchmark 比较答案 | Environment 内部评估器 |

---

## 九、最佳实践与注意事项

### 9.1 环境设计原则

1. **单一职责**: 每个环境只负责一类任务 (如 Math 只做数学计算)
2. **配置化**: 通过 `__init__(**kwargs)` 接收配置,存储在 `self.config`
3. **工具解耦**: 工具应独立于环境,可复用
4. **错误处理**: 工具执行失败应返回 error 状态,而非抛出异常
5. **资源管理**: 使用 `env_start`/`env_close` 管理全局资源

### 9.2 Benchmark 设计原则

1. **元数据灵活性**: 使用 `metadata` 字段存储额外信息 (如 OSWorld 的 config/evaluator)
2. **答案标准化**: `answer` 字段始终为字符串 (即使是数值)
3. **评估解耦**: 评估逻辑独立于数据加载
4. **多指标支持**: 支持多种评估指标,方便对比

### 9.3 常见陷阱

❌ **错误示例**:
```python
# 直接修改 run_osworld.py 的核心逻辑
def run_single_task(self, task):
    if self.environment.mode == "my_env":
        # 特殊处理 ❌ 这破坏了抽象
        ...
```

✅ **正确示例**:
```python
# 在 MyNewEnvironment 中重写方法
class MyNewEnvironment(Environment):
    def env_task_init(self, task):
        # 自定义初始化逻辑 ✅ 符合开闭原则
        ...
```

### 9.4 调试技巧

1. **启用详细日志**: 在工具中添加 `print()` 语句
2. **单任务测试**: 使用单条数据的 JSONL 文件测试
3. **检查轨迹文件**: 查看 `trajectory.json` 确认工具调用
4. **验证观察格式**: 确保 `observation` 字典格式正确

---

## 十、快速开始模板

### 10.1 最小化新环境模板

```python
# my_minimal_env.py
from envs.enviroment import Environment
from tools import SomeTool

class MyMinimalEnvironment(Environment):
    @property
    def mode(self) -> str:
        return "my_minimal"

    def _initialize_tools(self):
        self.register_tool(SomeTool())
```

**使用方式**:
```bash
python src/run_osworld.py \
  --mode my_minimal \
  --data data/my_benchmark.jsonl \
  --output-dir results
```

### 10.2 完整新环境模板

```python
# my_full_env.py
from envs.enviroment import Environment
from envs.data_models import Observation
from typing import Dict, Any, Optional, List
import os

class MyFullEnvironment(Environment):
    def __init__(self, **kwargs):
        self._resource = None
        super().__init__(**kwargs)

    @property
    def mode(self) -> str:
        return "my_full"

    def _initialize_tools(self):
        self.register_tool(MyTool(config=self.config))

    def env_start(self):
        """全局初始化"""
        self._resource = self._create_resource()

    def env_close(self):
        """全局清理"""
        if self._resource:
            self._resource.close()

    def env_task_init(self, task: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """任务初始化,返回初始观察"""
        state = self._get_initial_state()
        return {
            'text': state['description'],
            'image': state['screenshot_base64']
        }

    def format_initial_observation_for_message(self, initial_obs):
        """格式化初始观察"""
        content_parts = []
        if initial_obs.get('text'):
            content_parts.append({
                "type": "text",
                "text": initial_obs['text']
            })
        if initial_obs.get('image'):
            content_parts.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{initial_obs['image']}",
                    "detail": "high"
                }
            })
        return content_parts

    def has_internal_evaluation(self) -> bool:
        return True

    def evaluate(self) -> float:
        """内部评估"""
        return self._run_evaluator()

    def env_task_end(self, task_id, task_output_dir, final_answer):
        """任务结束"""
        score = self.evaluate()
        if task_output_dir:
            with open(os.path.join(task_output_dir, "result.txt"), "w") as f:
                f.write(f"{score}\n")
        return {"answer": str(score)}

    def get_task_output_dir(self, base_dir, task_id, model_name):
        """创建任务目录"""
        task_dir = os.path.join(base_dir, f"{task_id}_{model_name}")
        os.makedirs(task_dir, exist_ok=True)
        return task_dir
```

### 10.3 自定义 Benchmark 模板

```python
# my_custom_benchmark.py
from benchmark import Benchmark, BenchmarkItem
from typing import Dict, Any

class MyCustomBenchmark(Benchmark):
    def _parse_item(self, data: Dict[str, Any], line_num: int) -> BenchmarkItem:
        """自定义解析逻辑"""
        return BenchmarkItem(
            id=data.get('custom_id', f'item_{line_num}'),
            question=data.get('task', ''),
            answer=data.get('expected', ''),
            metadata={k: v for k, v in data.items()
                     if k not in ['custom_id', 'task', 'expected']}
        )

    def _my_custom_metric(self, gt: str, pred: str, **kwargs) -> float:
        """自定义评估指标"""
        # 实现你的评估逻辑
        return score

    def _get_metric_function(self, metric: str):
        if metric == 'my_custom_metric':
            return self._my_custom_metric
        return super()._get_metric_function(metric)
```

---

## 十一、重要实现细节与常见问题

### 11.1 ⚠️ evaluate() 方法必须显式实现

**问题**: Environment 基类中**没有定义** `evaluate()` 方法!

**影响**: 如果你的环境设置了 `has_internal_evaluation() = True`, 但没有实现 `evaluate()` 方法, 运行时会报错:

```python
AttributeError: 'MyNewEnvironment' object has no attribute 'evaluate'
```

**正确做法**:

```python
class MyNewEnvironment(Environment):
    def has_internal_evaluation(self) -> bool:
        """标记有内部评估"""
        return True

    def evaluate(self) -> float:
        """⚠️ 必须实现此方法!"""
        # 实现你的评估逻辑
        score = self._run_my_evaluator()
        return float(score)
```

**参考实现** (OSWorldEnvironment):

```python
# src/envs/osworld_environment.py:754-765
def evaluate(self) -> float:
    """
    Evaluate current state against task goal.

    Returns:
        Score (float) indicating task completion success
    """
    if not self._desktop_env:
        raise ValueError("DesktopEnv not initialized")

    score = self._desktop_env.evaluate()
    return float(score)
```

**调用位置** (run_osworld.py:262):

```python
# finally 块中
if self.environment.has_internal_evaluation():
    try:
        print(f"   Evaluating task using environment's internal evaluator...")
        evaluation_score = self.environment.evaluate()  # ⚠️ 这里调用
        print(f"   Evaluation score: {evaluation_score:.2f}")
```

### 11.2 评估流程详解

**有内部评估的环境 (如 OSWorld)**:

```
run_single_task()
├─ try:
│  └─ result = {"answer": final_answer, ...}  # LLM 回答
│
└─ finally:
   ├─ if has_internal_evaluation():  ✅ 返回 True
   │  ├─ evaluation_score = environment.evaluate()  # 调用评估器
   │  ├─ result["evaluation_score"] = evaluation_score
   │  └─ result["answer"] = str(evaluation_score)  # ⚠️ 覆盖 LLM 回答
   │
   ├─ environment.env_task_end(...)  # 清理工作
   └─ return result  # answer 现在是评估分数
```

**无内部评估的环境 (如 Math/RAG/Web)**:

```
run_single_task()
├─ try:
│  └─ result = {"answer": final_answer, ...}  # LLM 回答
│
└─ finally:
   ├─ if has_internal_evaluation():  ❌ 返回 False (跳过)
   ├─ environment.env_task_end(...)  # 清理工作
   └─ return result  # answer 仍是 LLM 回答
```

### 11.3 env_task_end() 的职责

**常见误解**: 在 `env_task_end()` 中调用 `evaluate()` 并返回分数

```python
# ❌ 错误做法
def env_task_end(self, task_id, task_output_dir, final_answer):
    score = self.evaluate()  # ❌ 不需要在这里调用
    return {"answer": str(score)}
```

**正确做法**: `env_task_end()` 只负责清理工作

```python
# ✅ 正确做法
def env_task_end(self, task_id, task_output_dir, final_answer):
    # 1. 停止录屏
    if hasattr(self, '_recording'):
        self._stop_recording(task_output_dir)

    # 2. 保存轨迹
    if task_output_dir:
        self._save_trajectory(task_output_dir)

    # 3. 清理资源
    self._cleanup_task_resources()

    return None  # 返回 None 即可
```

**原因**: `run_osworld.py` 会在 finally 块中自动调用 `evaluate()`, 无需重复调用。

### 11.4 Environment 基类中与评估相关的方法

| 方法 | 基类中是否定义 | 默认返回值 | 说明 |
|------|--------------|----------|------|
| `has_internal_evaluation()` | ✅ 是 | `False` | 标记是否有内部评估 |
| `evaluate()` | ❌ **否** | - | **必须在子类中实现!** |
| `evaluate_task()` | ✅ 是 (已废弃) | `0.0` | 遗留方法,不要使用 |
| `env_task_end()` | ✅ 是 | `{"answer": final_answer}` | 任务结束清理 |

**结论**: 如果 `has_internal_evaluation()` 返回 `True`, **必须手动实现** `evaluate()` 方法!

### 11.5 检查清单

在开发新环境时,如果需要内部评估,请确保:

- [ ] `has_internal_evaluation()` 返回 `True`
- [ ] **实现了** `evaluate()` 方法 (返回 float 分数)
- [ ] `env_task_end()` 只做清理,不调用 `evaluate()`
- [ ] 测试评估器是否正常工作

---

## 十二、总结

AgentFlow 采用了**基于抽象的可扩展架构**:

1. **Environment**: 封装工具和环境逻辑
2. **Benchmark**: 封装数据和评估逻辑
3. **AgentRunner**: 协调环境和数据集,执行任务

**开发新环境的核心步骤**:
1. 继承 `Environment` 类
2. 实现 `mode` 和 `_initialize_tools`
3. 根据需要重写高级方法 (初始观察、内部评估等)
4. 注册到 `run_osworld.py`

**开发新 Benchmark 的核心步骤**:
1. 准备标准格式数据 (JSON/JSONL)
2. 如需自定义解析,继承 `Benchmark` 并重写 `_parse_item`
3. 如需新指标,重写 `_get_metric_function`

这种设计实现了**高内聚、低耦合**,使得添加新环境和数据集非常简单,无需修改核心执行逻辑。

---

## 附录: 文件结构

```
AgentFlow/
├── src/
│   ├── run_osworld.py          # 主执行脚本
│   ├── envs/
│   │   ├── enviroment.py       # Environment 抽象基类
│   │   ├── data_models.py      # 轨迹数据模型
│   │   ├── math_environment.py
│   │   ├── python_environment.py
│   │   ├── rag_environment.py
│   │   ├── web_environment.py
│   │   └── osworld_environment.py
│   ├── benchmark/
│   │   ├── benchmark.py        # Benchmark 抽象基类
│   │   └── __init__.py
│   ├── tools/
│   │   ├── tool.py             # Tool 抽象基类
│   │   ├── calculator.py
│   │   ├── python_interpreter.py
│   │   ├── rag_tools.py
│   │   ├── web_search.py
│   │   └── osworld_tools.py
│   └── prompts/
│       ├── system_prompts.py   # 系统提示词模板
│       └── __init__.py
└── data/
    ├── math_demo.jsonl
    ├── rag_demo.jsonl
    └── osworld_tasks.json
```
